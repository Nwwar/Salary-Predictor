2023-05-27 23:29:30,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-27 23:29:30,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-27 23:29:30,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-27 23:29:30,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-27 23:29:31,654:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-27 23:34:14,839:INFO:PyCaret RegressionExperiment
2023-05-27 23:34:14,839:INFO:Logging name: reg-default-name
2023-05-27 23:34:14,839:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-27 23:34:14,839:INFO:version 3.0.2
2023-05-27 23:34:14,839:INFO:Initializing setup()
2023-05-27 23:34:14,839:INFO:self.USI: 594b
2023-05-27 23:34:14,839:INFO:self._variable_keys: {'y', 'gpu_param', 'USI', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'data', 'y_train', 'fold_groups_param', 'X', 'transform_target_param', 'logging_param', 'target_param', 'idx', 'fold_generator', 'exp_id', 'memory', 'exp_name_log', 'pipeline', 'html_param', 'log_plots_param', 'seed', 'n_jobs_param', '_available_plots', 'fold_shuffle_param', 'X_train', 'y_test'}
2023-05-27 23:34:14,839:INFO:Checking environment
2023-05-27 23:34:14,839:INFO:python_version: 3.10.9
2023-05-27 23:34:14,839:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-05-27 23:34:14,839:INFO:machine: AMD64
2023-05-27 23:34:14,839:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-27 23:34:14,839:INFO:Memory: svmem(total=17041244160, available=4793249792, percent=71.9, used=12247994368, free=4793249792)
2023-05-27 23:34:14,839:INFO:Physical Core: 6
2023-05-27 23:34:14,839:INFO:Logical Core: 12
2023-05-27 23:34:14,839:INFO:Checking libraries
2023-05-27 23:34:14,839:INFO:System:
2023-05-27 23:34:14,839:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-05-27 23:34:14,839:INFO:executable: C:\Users\medo2\anaconda3\python.exe
2023-05-27 23:34:14,839:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-27 23:34:14,839:INFO:PyCaret required dependencies:
2023-05-27 23:34:14,839:INFO:                 pip: 23.0.1
2023-05-27 23:34:14,839:INFO:          setuptools: 65.6.3
2023-05-27 23:34:14,839:INFO:             pycaret: 3.0.2
2023-05-27 23:34:14,839:INFO:             IPython: 8.10.0
2023-05-27 23:34:14,839:INFO:          ipywidgets: 7.6.5
2023-05-27 23:34:14,839:INFO:                tqdm: 4.64.1
2023-05-27 23:34:14,839:INFO:               numpy: 1.23.5
2023-05-27 23:34:14,839:INFO:              pandas: 1.5.3
2023-05-27 23:34:14,839:INFO:              jinja2: 3.1.2
2023-05-27 23:34:14,839:INFO:               scipy: 1.10.0
2023-05-27 23:34:14,839:INFO:              joblib: 1.2.0
2023-05-27 23:34:14,839:INFO:             sklearn: 1.2.1
2023-05-27 23:34:14,839:INFO:                pyod: 1.0.9
2023-05-27 23:34:14,839:INFO:            imblearn: 0.10.1
2023-05-27 23:34:14,839:INFO:   category_encoders: 2.6.1
2023-05-27 23:34:14,839:INFO:            lightgbm: 3.3.5
2023-05-27 23:34:14,839:INFO:               numba: 0.56.4
2023-05-27 23:34:14,839:INFO:            requests: 2.28.1
2023-05-27 23:34:14,839:INFO:          matplotlib: 3.7.0
2023-05-27 23:34:14,839:INFO:          scikitplot: 0.3.7
2023-05-27 23:34:14,839:INFO:         yellowbrick: 1.5
2023-05-27 23:34:14,839:INFO:              plotly: 5.9.0
2023-05-27 23:34:14,839:INFO:             kaleido: 0.2.1
2023-05-27 23:34:14,839:INFO:         statsmodels: 0.13.5
2023-05-27 23:34:14,839:INFO:              sktime: 0.17.0
2023-05-27 23:34:14,839:INFO:               tbats: 1.1.3
2023-05-27 23:34:14,839:INFO:            pmdarima: 2.0.3
2023-05-27 23:34:14,839:INFO:              psutil: 5.9.0
2023-05-27 23:34:14,839:INFO:PyCaret optional dependencies:
2023-05-27 23:34:14,870:INFO:                shap: Not installed
2023-05-27 23:34:14,870:INFO:           interpret: Not installed
2023-05-27 23:34:14,870:INFO:                umap: Not installed
2023-05-27 23:34:14,870:INFO:    pandas_profiling: Not installed
2023-05-27 23:34:14,870:INFO:  explainerdashboard: Not installed
2023-05-27 23:34:14,870:INFO:             autoviz: Not installed
2023-05-27 23:34:14,870:INFO:           fairlearn: Not installed
2023-05-27 23:34:14,870:INFO:             xgboost: Not installed
2023-05-27 23:34:14,870:INFO:            catboost: Not installed
2023-05-27 23:34:14,870:INFO:              kmodes: Not installed
2023-05-27 23:34:14,870:INFO:             mlxtend: Not installed
2023-05-27 23:34:14,870:INFO:       statsforecast: Not installed
2023-05-27 23:34:14,870:INFO:        tune_sklearn: Not installed
2023-05-27 23:34:14,870:INFO:                 ray: Not installed
2023-05-27 23:34:14,870:INFO:            hyperopt: Not installed
2023-05-27 23:34:14,870:INFO:              optuna: Not installed
2023-05-27 23:34:14,870:INFO:               skopt: Not installed
2023-05-27 23:34:14,870:INFO:              mlflow: Not installed
2023-05-27 23:34:14,870:INFO:              gradio: Not installed
2023-05-27 23:34:14,870:INFO:             fastapi: Not installed
2023-05-27 23:34:14,870:INFO:             uvicorn: Not installed
2023-05-27 23:34:14,870:INFO:              m2cgen: Not installed
2023-05-27 23:34:14,870:INFO:           evidently: Not installed
2023-05-27 23:34:14,870:INFO:               fugue: Not installed
2023-05-27 23:34:14,870:INFO:           streamlit: Not installed
2023-05-27 23:34:14,870:INFO:             prophet: Not installed
2023-05-27 23:34:14,870:INFO:None
2023-05-27 23:34:14,870:INFO:Set up data.
2023-05-27 23:34:14,972:INFO:Set up train/test split.
2023-05-27 23:34:14,988:INFO:Set up index.
2023-05-27 23:34:14,988:INFO:Set up folding strategy.
2023-05-27 23:34:14,988:INFO:Assigning column types.
2023-05-27 23:34:15,003:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-27 23:34:15,003:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,019:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,441:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,441:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,441:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,566:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-27 23:34:15,566:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,691:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,821:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-27 23:34:15,821:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:15,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:15,946:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,071:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-27 23:34:16,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,196:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,323:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-27 23:34:16,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:34:16,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,573:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-27 23:34:16,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:16,828:INFO:Preparing preprocessing pipeline...
2023-05-27 23:34:16,828:INFO:Set up simple imputation.
2023-05-27 23:34:16,828:INFO:Set up column name cleaning.
2023-05-27 23:34:16,906:INFO:Finished creating preprocessing pipeline.
2023-05-27 23:34:16,922:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\medo2\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Job title_academic advisor',
                                             'Job title_account manager',
                                             'Job title_accountant',
                                             'Job title_accounting manager',
                                             'Job title_administrative '
                                             'assistant',
                                             'Job title_administrative '
                                             'assistant ',
                                             'Job title_analyst',
                                             'Job title_archivist...
                                             'Job title_digital marketing '
                                             'manager',
                                             'Job title_director',
                                             'Job title_director of '
                                             'engineering',
                                             'Job title_director of operations',
                                             'Job title_editor', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-27 23:34:16,922:INFO:Creating final display dataframe.
2023-05-27 23:34:17,250:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      total_salary
2                   Target type        Regression
3           Original data shape       (3861, 385)
4        Transformed data shape       (3861, 385)
5   Transformed train set shape       (2702, 385)
6    Transformed test set shape       (1159, 385)
7              Numeric features               384
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              594b
2023-05-27 23:34:17,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:17,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:17,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:17,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:34:17,511:INFO:setup() successfully completed in 2.67s...............
2023-05-27 23:35:49,916:INFO:PyCaret RegressionExperiment
2023-05-27 23:35:49,916:INFO:Logging name: reg-default-name
2023-05-27 23:35:49,916:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-27 23:35:49,916:INFO:version 3.0.2
2023-05-27 23:35:49,916:INFO:Initializing setup()
2023-05-27 23:35:49,916:INFO:self.USI: 9f6d
2023-05-27 23:35:49,916:INFO:self._variable_keys: {'y', 'gpu_param', 'USI', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'data', 'y_train', 'fold_groups_param', 'X', 'transform_target_param', 'logging_param', 'target_param', 'idx', 'fold_generator', 'exp_id', 'memory', 'exp_name_log', 'pipeline', 'html_param', 'log_plots_param', 'seed', 'n_jobs_param', '_available_plots', 'fold_shuffle_param', 'X_train', 'y_test'}
2023-05-27 23:35:49,916:INFO:Checking environment
2023-05-27 23:35:49,916:INFO:python_version: 3.10.9
2023-05-27 23:35:49,916:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-05-27 23:35:49,916:INFO:machine: AMD64
2023-05-27 23:35:49,916:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-27 23:35:49,916:INFO:Memory: svmem(total=17041244160, available=4406280192, percent=74.1, used=12634963968, free=4406280192)
2023-05-27 23:35:49,916:INFO:Physical Core: 6
2023-05-27 23:35:49,916:INFO:Logical Core: 12
2023-05-27 23:35:49,916:INFO:Checking libraries
2023-05-27 23:35:49,916:INFO:System:
2023-05-27 23:35:49,916:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-05-27 23:35:49,916:INFO:executable: C:\Users\medo2\anaconda3\python.exe
2023-05-27 23:35:49,916:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-27 23:35:49,916:INFO:PyCaret required dependencies:
2023-05-27 23:35:49,916:INFO:                 pip: 23.0.1
2023-05-27 23:35:49,916:INFO:          setuptools: 65.6.3
2023-05-27 23:35:49,916:INFO:             pycaret: 3.0.2
2023-05-27 23:35:49,916:INFO:             IPython: 8.10.0
2023-05-27 23:35:49,916:INFO:          ipywidgets: 7.6.5
2023-05-27 23:35:49,932:INFO:                tqdm: 4.64.1
2023-05-27 23:35:49,932:INFO:               numpy: 1.23.5
2023-05-27 23:35:49,932:INFO:              pandas: 1.5.3
2023-05-27 23:35:49,932:INFO:              jinja2: 3.1.2
2023-05-27 23:35:49,932:INFO:               scipy: 1.10.0
2023-05-27 23:35:49,932:INFO:              joblib: 1.2.0
2023-05-27 23:35:49,932:INFO:             sklearn: 1.2.1
2023-05-27 23:35:49,932:INFO:                pyod: 1.0.9
2023-05-27 23:35:49,932:INFO:            imblearn: 0.10.1
2023-05-27 23:35:49,932:INFO:   category_encoders: 2.6.1
2023-05-27 23:35:49,932:INFO:            lightgbm: 3.3.5
2023-05-27 23:35:49,932:INFO:               numba: 0.56.4
2023-05-27 23:35:49,932:INFO:            requests: 2.28.1
2023-05-27 23:35:49,932:INFO:          matplotlib: 3.7.0
2023-05-27 23:35:49,932:INFO:          scikitplot: 0.3.7
2023-05-27 23:35:49,932:INFO:         yellowbrick: 1.5
2023-05-27 23:35:49,932:INFO:              plotly: 5.9.0
2023-05-27 23:35:49,932:INFO:             kaleido: 0.2.1
2023-05-27 23:35:49,932:INFO:         statsmodels: 0.13.5
2023-05-27 23:35:49,932:INFO:              sktime: 0.17.0
2023-05-27 23:35:49,932:INFO:               tbats: 1.1.3
2023-05-27 23:35:49,932:INFO:            pmdarima: 2.0.3
2023-05-27 23:35:49,932:INFO:              psutil: 5.9.0
2023-05-27 23:35:49,932:INFO:PyCaret optional dependencies:
2023-05-27 23:35:49,932:INFO:                shap: Not installed
2023-05-27 23:35:49,932:INFO:           interpret: Not installed
2023-05-27 23:35:49,932:INFO:                umap: Not installed
2023-05-27 23:35:49,932:INFO:    pandas_profiling: Not installed
2023-05-27 23:35:49,932:INFO:  explainerdashboard: Not installed
2023-05-27 23:35:49,932:INFO:             autoviz: Not installed
2023-05-27 23:35:49,932:INFO:           fairlearn: Not installed
2023-05-27 23:35:49,932:INFO:             xgboost: Not installed
2023-05-27 23:35:49,932:INFO:            catboost: Not installed
2023-05-27 23:35:49,932:INFO:              kmodes: Not installed
2023-05-27 23:35:49,932:INFO:             mlxtend: Not installed
2023-05-27 23:35:49,932:INFO:       statsforecast: Not installed
2023-05-27 23:35:49,932:INFO:        tune_sklearn: Not installed
2023-05-27 23:35:49,932:INFO:                 ray: Not installed
2023-05-27 23:35:49,932:INFO:            hyperopt: Not installed
2023-05-27 23:35:49,932:INFO:              optuna: Not installed
2023-05-27 23:35:49,932:INFO:               skopt: Not installed
2023-05-27 23:35:49,932:INFO:              mlflow: Not installed
2023-05-27 23:35:49,932:INFO:              gradio: Not installed
2023-05-27 23:35:49,932:INFO:             fastapi: Not installed
2023-05-27 23:35:49,932:INFO:             uvicorn: Not installed
2023-05-27 23:35:49,932:INFO:              m2cgen: Not installed
2023-05-27 23:35:49,932:INFO:           evidently: Not installed
2023-05-27 23:35:49,932:INFO:               fugue: Not installed
2023-05-27 23:35:49,932:INFO:           streamlit: Not installed
2023-05-27 23:35:49,932:INFO:             prophet: Not installed
2023-05-27 23:35:49,932:INFO:None
2023-05-27 23:35:49,932:INFO:Set up data.
2023-05-27 23:35:50,135:INFO:Set up train/test split.
2023-05-27 23:35:50,151:INFO:Set up index.
2023-05-27 23:35:50,151:INFO:Set up folding strategy.
2023-05-27 23:35:50,151:INFO:Assigning column types.
2023-05-27 23:35:50,167:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-27 23:35:50,167:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,167:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,167:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,279:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,279:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,279:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,408:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-27 23:35:50,408:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,533:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,658:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-27 23:35:50,658:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,783:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:50,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:50,899:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-27 23:35:50,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:51,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:51,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:51,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:35:51,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,149:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-27 23:35:51,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:51,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:35:51,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,399:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-27 23:35:51,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:51,665:INFO:Preparing preprocessing pipeline...
2023-05-27 23:35:51,665:INFO:Set up simple imputation.
2023-05-27 23:35:51,665:INFO:Set up column name cleaning.
2023-05-27 23:35:51,743:INFO:Finished creating preprocessing pipeline.
2023-05-27 23:35:51,759:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\medo2\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Job title_academic advisor',
                                             'Job title_account manager',
                                             'Job title_accountant',
                                             'Job title_accounting manager',
                                             'Job title_administrative '
                                             'assistant',
                                             'Job title_administrative '
                                             'assistant ',
                                             'Job title_analyst',
                                             'Job title_archivist...
                                             'Job title_digital marketing '
                                             'manager',
                                             'Job title_director',
                                             'Job title_director of '
                                             'engineering',
                                             'Job title_director of operations',
                                             'Job title_editor', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-27 23:35:51,759:INFO:Creating final display dataframe.
2023-05-27 23:35:52,071:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      total_salary
2                   Target type        Regression
3           Original data shape       (3861, 385)
4        Transformed data shape       (3861, 385)
5   Transformed train set shape       (2702, 385)
6    Transformed test set shape       (1159, 385)
7              Numeric features               384
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9f6d
2023-05-27 23:35:52,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:52,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:52,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:52,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:35:52,326:INFO:setup() successfully completed in 2.41s...............
2023-05-27 23:36:08,843:INFO:Initializing compare_models()
2023-05-27 23:36:08,843:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-27 23:36:08,843:INFO:Checking exceptions
2023-05-27 23:36:08,859:INFO:Preparing display monitor
2023-05-27 23:36:08,890:INFO:Initializing Linear Regression
2023-05-27 23:36:08,890:INFO:Total runtime is 0.0 minutes
2023-05-27 23:36:08,890:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:08,890:INFO:Initializing create_model()
2023-05-27 23:36:08,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:08,890:INFO:Checking exceptions
2023-05-27 23:36:08,890:INFO:Importing libraries
2023-05-27 23:36:08,890:INFO:Copying training dataset
2023-05-27 23:36:08,921:INFO:Defining folds
2023-05-27 23:36:08,921:INFO:Declaring metric variables
2023-05-27 23:36:08,921:INFO:Importing untrained model
2023-05-27 23:36:08,921:INFO:Linear Regression Imported successfully
2023-05-27 23:36:08,937:INFO:Starting cross validation
2023-05-27 23:36:08,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:18,481:INFO:Calculating mean and std
2023-05-27 23:36:18,481:INFO:Creating metrics dataframe
2023-05-27 23:36:18,502:INFO:Uploading results into container
2023-05-27 23:36:18,502:INFO:Uploading model into container now
2023-05-27 23:36:18,502:INFO:_master_model_container: 1
2023-05-27 23:36:18,502:INFO:_display_container: 2
2023-05-27 23:36:18,502:INFO:LinearRegression(n_jobs=-1)
2023-05-27 23:36:18,502:INFO:create_model() successfully completed......................................
2023-05-27 23:36:18,626:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:18,626:INFO:Creating metrics dataframe
2023-05-27 23:36:18,635:INFO:Initializing Lasso Regression
2023-05-27 23:36:18,635:INFO:Total runtime is 0.16240708430608114 minutes
2023-05-27 23:36:18,635:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:18,635:INFO:Initializing create_model()
2023-05-27 23:36:18,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:18,635:INFO:Checking exceptions
2023-05-27 23:36:18,635:INFO:Importing libraries
2023-05-27 23:36:18,635:INFO:Copying training dataset
2023-05-27 23:36:18,666:INFO:Defining folds
2023-05-27 23:36:18,666:INFO:Declaring metric variables
2023-05-27 23:36:18,675:INFO:Importing untrained model
2023-05-27 23:36:18,680:INFO:Lasso Regression Imported successfully
2023-05-27 23:36:18,690:INFO:Starting cross validation
2023-05-27 23:36:18,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:22,213:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+12, tolerance: 2.643e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,283:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+11, tolerance: 2.791e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,361:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.139e+11, tolerance: 2.448e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,392:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+12, tolerance: 2.789e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,459:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e+12, tolerance: 2.760e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,490:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+12, tolerance: 2.720e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,568:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+12, tolerance: 2.556e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:22,584:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+12, tolerance: 2.699e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:24,879:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+12, tolerance: 2.285e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:24,927:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.198e+10, tolerance: 2.722e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-27 23:36:25,099:INFO:Calculating mean and std
2023-05-27 23:36:25,099:INFO:Creating metrics dataframe
2023-05-27 23:36:25,130:INFO:Uploading results into container
2023-05-27 23:36:25,130:INFO:Uploading model into container now
2023-05-27 23:36:25,130:INFO:_master_model_container: 2
2023-05-27 23:36:25,130:INFO:_display_container: 2
2023-05-27 23:36:25,130:INFO:Lasso(random_state=123)
2023-05-27 23:36:25,130:INFO:create_model() successfully completed......................................
2023-05-27 23:36:25,237:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:25,237:INFO:Creating metrics dataframe
2023-05-27 23:36:25,245:INFO:Initializing Ridge Regression
2023-05-27 23:36:25,245:INFO:Total runtime is 0.27257937987645464 minutes
2023-05-27 23:36:25,253:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:25,253:INFO:Initializing create_model()
2023-05-27 23:36:25,253:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:25,253:INFO:Checking exceptions
2023-05-27 23:36:25,253:INFO:Importing libraries
2023-05-27 23:36:25,253:INFO:Copying training dataset
2023-05-27 23:36:25,278:INFO:Defining folds
2023-05-27 23:36:25,278:INFO:Declaring metric variables
2023-05-27 23:36:25,278:INFO:Importing untrained model
2023-05-27 23:36:25,286:INFO:Ridge Regression Imported successfully
2023-05-27 23:36:25,295:INFO:Starting cross validation
2023-05-27 23:36:25,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:25,806:INFO:Calculating mean and std
2023-05-27 23:36:25,806:INFO:Creating metrics dataframe
2023-05-27 23:36:25,837:INFO:Uploading results into container
2023-05-27 23:36:25,837:INFO:Uploading model into container now
2023-05-27 23:36:25,837:INFO:_master_model_container: 3
2023-05-27 23:36:25,837:INFO:_display_container: 2
2023-05-27 23:36:25,837:INFO:Ridge(random_state=123)
2023-05-27 23:36:25,837:INFO:create_model() successfully completed......................................
2023-05-27 23:36:25,926:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:25,926:INFO:Creating metrics dataframe
2023-05-27 23:36:25,942:INFO:Initializing Elastic Net
2023-05-27 23:36:25,942:INFO:Total runtime is 0.2841950972874959 minutes
2023-05-27 23:36:25,942:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:25,942:INFO:Initializing create_model()
2023-05-27 23:36:25,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:25,942:INFO:Checking exceptions
2023-05-27 23:36:25,942:INFO:Importing libraries
2023-05-27 23:36:25,942:INFO:Copying training dataset
2023-05-27 23:36:25,957:INFO:Defining folds
2023-05-27 23:36:25,957:INFO:Declaring metric variables
2023-05-27 23:36:25,957:INFO:Importing untrained model
2023-05-27 23:36:25,973:INFO:Elastic Net Imported successfully
2023-05-27 23:36:25,973:INFO:Starting cross validation
2023-05-27 23:36:25,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:26,473:INFO:Calculating mean and std
2023-05-27 23:36:26,473:INFO:Creating metrics dataframe
2023-05-27 23:36:26,489:INFO:Uploading results into container
2023-05-27 23:36:26,489:INFO:Uploading model into container now
2023-05-27 23:36:26,489:INFO:_master_model_container: 4
2023-05-27 23:36:26,489:INFO:_display_container: 2
2023-05-27 23:36:26,489:INFO:ElasticNet(random_state=123)
2023-05-27 23:36:26,489:INFO:create_model() successfully completed......................................
2023-05-27 23:36:26,582:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:26,582:INFO:Creating metrics dataframe
2023-05-27 23:36:26,602:INFO:Initializing Least Angle Regression
2023-05-27 23:36:26,602:INFO:Total runtime is 0.29520331621170043 minutes
2023-05-27 23:36:26,606:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:26,606:INFO:Initializing create_model()
2023-05-27 23:36:26,606:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:26,606:INFO:Checking exceptions
2023-05-27 23:36:26,606:INFO:Importing libraries
2023-05-27 23:36:26,606:INFO:Copying training dataset
2023-05-27 23:36:26,627:INFO:Defining folds
2023-05-27 23:36:26,627:INFO:Declaring metric variables
2023-05-27 23:36:26,627:INFO:Importing untrained model
2023-05-27 23:36:26,627:INFO:Least Angle Regression Imported successfully
2023-05-27 23:36:26,643:INFO:Starting cross validation
2023-05-27 23:36:26,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:26,908:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.535e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,916:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=6.908e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,920:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=4.439e+02, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,925:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=4.031e+02, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,936:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.406e+02, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,951:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.859e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,951:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=9.126e+01, with an active set of 136 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,951:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=5.649e+02, with an active set of 116 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,951:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=8.968e+01, with an active set of 138 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,967:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.935e+01, with an active set of 157 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,967:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=1.858e+03, with an active set of 170 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,982:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=1.815e+03, with an active set of 180 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,998:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=1.811e+03, with an active set of 182 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,998:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=1.206e+03, with an active set of 170 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,998:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=1.802e+03, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:26,998:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=1.775e+03, with an active set of 194 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=1.229e+03, with an active set of 187 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=2.504e+02, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=3.497e+01, with an active set of 223 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=1.190e+03, with an active set of 194 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=3.373e+01, with an active set of 227 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.189e+03, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=3.356e+01, with an active set of 227 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,014:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.730e+03, with an active set of 212 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,029:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.215e+03, with an active set of 202 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,029:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.044e+05, with an active set of 135 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,029:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=1.871e+02, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,029:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.113e+01, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,029:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.876e+05, with an active set of 141 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,045:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=7.763e+01, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,045:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.563e+02, with an active set of 151 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,045:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.467e+02, with an active set of 157 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,045:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.921e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,045:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.281e+03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,045:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.357e+02, with an active set of 165 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=1.932e+03, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.353e+02, with an active set of 165 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=2.840e+04, with an active set of 190 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=1.293e+02, with an active set of 170 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.876e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.188e+05, with an active set of 183 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,061:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=4.350e+04, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.207e+03, with an active set of 140 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=4.563e+04, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.591e+02, with an active set of 106 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.860e+02, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=4.576e+04, with an active set of 211 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=4.372e+04, with an active set of 214 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=5.336e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.334e+02, with an active set of 151 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,076:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 310 iterations, i.e. alpha=2.035e+04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,092:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=2.349e+05, with an active set of 206 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,092:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=9.647e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,107:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=2.434e+04, with an active set of 280 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,107:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=8.624e+01, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,107:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=8.335e+01, with an active set of 232 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,123:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=7.761e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,123:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.101e+02, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,123:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=7.166e+01, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,123:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=7.166e+01, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,123:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.349e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,139:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=3.026e+03, with an active set of 163 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,139:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=5.359e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,139:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=9.584e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,154:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=2.850e+03, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,154:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=9.036e+01, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,154:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=5.965e+01, with an active set of 257 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,154:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=5.906e+01, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,154:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=5.778e+01, with an active set of 259 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,170:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=2.484e+03, with an active set of 190 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,170:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=5.726e+03, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,170:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 388 iterations, i.e. alpha=1.042e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,170:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=2.553e+05, with an active set of 280 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,186:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.160e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,186:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=7.622e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,186:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 392 iterations, i.e. alpha=5.732e+04, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,201:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=2.524e+05, with an active set of 295 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,201:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=5.745e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,217:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.980e+03, with an active set of 228 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,217:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=4.552e+01, with an active set of 294 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,217:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=4.544e+01, with an active set of 294 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,217:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=4.530e+01, with an active set of 294 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,217:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=7.258e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,232:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=3.260e+04, with an active set of 281 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,232:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=6.775e+01, with an active set of 263 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.660e+04, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.370e+04, with an active set of 356 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.322e+04, with an active set of 356 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.205e+04, with an active set of 356 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=9.850e+03, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=8.270e+03, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=4.300e+01, with an active set of 306 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=6.391e+03, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=4.550e+03, with an active set of 356 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=4.182e+01, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.728e+03, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,248:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=3.232e+04, with an active set of 291 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,264:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=4.133e+02, with an active set of 271 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,295:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.577e+04, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=2.336e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=4.562e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=2.323e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=3.946e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=2.251e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=3.738e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=2.233e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=3.373e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=2.218e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=3.238e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=2.057e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=2.696e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=1.913e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,326:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=7.923e+06, with an active set of 359 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,326:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=1.883e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,326:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=4.083e+06, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,326:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=3.281e+06, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,326:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=1.652e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,326:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=2.722e+06, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,357:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 432 iterations, i.e. alpha=6.995e+09, with an active set of 348 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,373:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 437 iterations, i.e. alpha=1.040e+10, with an active set of 351 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,373:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=9.206e+09, with an active set of 354 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,373:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 441 iterations, i.e. alpha=5.289e+09, with an active set of 354 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 415 iterations, i.e. alpha=7.979e+02, with an active set of 329 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=5.056e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=3.851e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=4.457e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=2.901e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=4.404e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=2.174e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=3.810e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=2.091e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.633e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.543e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=2.240e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.176e+10, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=1.258e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=3.563e+09, with an active set of 356 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=7.659e+05, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 419 iterations, i.e. alpha=7.967e+02, with an active set of 333 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=2.516e+08, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=5.695e+05, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=2.878e+05, with an active set of 357 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,389:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 457 iterations, i.e. alpha=2.812e+05, with an active set of 357 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,412:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 420 iterations, i.e. alpha=1.073e+08, with an active set of 354 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,415:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=7.450e+07, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,416:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 430 iterations, i.e. alpha=7.559e+02, with an active set of 342 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,416:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=7.362e+07, with an active set of 356 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,416:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=5.461e+07, with an active set of 356 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,417:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=5.433e+07, with an active set of 356 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,418:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.855e+07, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,418:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.046e+07, with an active set of 356 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,422:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=3.834e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,422:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=3.061e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,423:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 414 iterations, i.e. alpha=3.957e+12, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,423:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=2.892e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,424:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=2.484e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,425:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=2.149e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,426:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=1.666e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,427:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=1.430e+07, with an active set of 357 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,427:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=4.924e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,427:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=2.438e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,427:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=1.712e+06, with an active set of 357 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=1.899e+08, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=9.858e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=9.749e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=9.213e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=5.434e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=4.471e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=2.958e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=2.573e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=1.290e+07, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,443:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 456 iterations, i.e. alpha=7.633e+06, with an active set of 359 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=8.780e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=7.946e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=6.512e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=5.897e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=3.450e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=3.003e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=2.913e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=2.725e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=1.932e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=1.553e+15, with an active set of 358 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=6.725e+14, with an active set of 358 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:27,942:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-05-27 23:36:27,942:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-05-27 23:36:27,942:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-05-27 23:36:28,129:INFO:Calculating mean and std
2023-05-27 23:36:28,129:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\numpy\core\_methods.py:236: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2023-05-27 23:36:28,129:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\numpy\core\_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2023-05-27 23:36:28,129:INFO:Creating metrics dataframe
2023-05-27 23:36:28,160:INFO:Uploading results into container
2023-05-27 23:36:28,160:INFO:Uploading model into container now
2023-05-27 23:36:28,160:INFO:_master_model_container: 5
2023-05-27 23:36:28,160:INFO:_display_container: 2
2023-05-27 23:36:28,160:INFO:Lars(random_state=123)
2023-05-27 23:36:28,160:INFO:create_model() successfully completed......................................
2023-05-27 23:36:28,254:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:28,254:INFO:Creating metrics dataframe
2023-05-27 23:36:28,270:INFO:Initializing Lasso Least Angle Regression
2023-05-27 23:36:28,270:INFO:Total runtime is 0.32299544811248776 minutes
2023-05-27 23:36:28,285:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:28,285:INFO:Initializing create_model()
2023-05-27 23:36:28,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:28,285:INFO:Checking exceptions
2023-05-27 23:36:28,285:INFO:Importing libraries
2023-05-27 23:36:28,285:INFO:Copying training dataset
2023-05-27 23:36:28,301:INFO:Defining folds
2023-05-27 23:36:28,301:INFO:Declaring metric variables
2023-05-27 23:36:28,301:INFO:Importing untrained model
2023-05-27 23:36:28,317:INFO:Lasso Least Angle Regression Imported successfully
2023-05-27 23:36:28,317:INFO:Starting cross validation
2023-05-27 23:36:28,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:28,567:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.072e+03, previous alpha=2.067e+03, with an active set of 13 regressors.
  warnings.warn(

2023-05-27 23:36:28,645:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=8.387e+01, with an active set of 144 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,645:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=8.157e+01, with an active set of 147 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,661:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.406e+02, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,677:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=5.227e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,677:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=5.099e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,677:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.286e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,692:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=9.065e+01, with an active set of 135 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,692:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=8.992e+01, with an active set of 136 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,708:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=3.643e+01, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,708:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=7.817e+01, with an active set of 157 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,708:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.669e+01, with an active set of 159 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,708:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=6.228e+01, with an active set of 165 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,708:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.018e+01, with an active set of 220 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,723:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=6.430e+01, with an active set of 180 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,708:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.004e+01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,723:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=5.974e+01, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,723:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.825e+01, with an active set of 226 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,723:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.823e+01, with an active set of 226 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,723:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=9.341e+01, with an active set of 140 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,739:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=2.593e+01, with an active set of 233 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,739:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 248 iterations, alpha=2.655e+01, previous alpha=2.555e+01, with an active set of 233 regressors.
  warnings.warn(

2023-05-27 23:36:28,739:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.268e+02, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,739:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 131 iterations, alpha=1.177e+02, previous alpha=1.177e+02, with an active set of 124 regressors.
  warnings.warn(

2023-05-27 23:36:28,739:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=4.298e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,755:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=3.908e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,755:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=3.814e+01, with an active set of 220 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,755:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=5.327e+01, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,755:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.354e+01, with an active set of 227 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,755:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.354e+02, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=3.100e+01, with an active set of 234 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=3.154e+01, with an active set of 214 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.632e+01, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=3.010e+01, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.283e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 229 iterations, alpha=3.138e+01, previous alpha=3.129e+01, with an active set of 214 regressors.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 251 iterations, alpha=2.976e+01, previous alpha=2.976e+01, with an active set of 238 regressors.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.921e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,770:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.281e+03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,786:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=3.540e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,786:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=3.540e+01, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,786:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.633e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,786:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.926e+01, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,786:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.500e+01, with an active set of 161 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,786:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.771e+01, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=6.533e+01, with an active set of 170 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=2.577e+01, with an active set of 229 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=7.201e+01, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=2.441e+02, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 193 iterations, alpha=5.918e+01, previous alpha=5.910e+01, with an active set of 182 regressors.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=2.321e+01, with an active set of 235 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=8.254e+01, with an active set of 149 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,802:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.789e+02, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,817:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.885e+01, with an active set of 155 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,817:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=4.803e+01, with an active set of 208 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,833:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 271 iterations, i.e. alpha=1.872e+01, with an active set of 247 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,833:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=1.824e+01, with an active set of 249 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,833:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.746e+01, with an active set of 250 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,833:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.000e+02, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,833:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=4.356e+01, with an active set of 195 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=3.507e+01, with an active set of 221 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=8.015e+01, with an active set of 150 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=3.949e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=3.949e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=3.949e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 284 iterations, alpha=1.501e+01, previous alpha=1.499e+01, with an active set of 257 regressors.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=7.067e+01, with an active set of 161 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=2.784e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=6.613e+01, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=6.600e+01, with an active set of 167 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=6.600e+01, with an active set of 167 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.623e+01, with an active set of 237 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,848:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.623e+01, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,864:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.610e+01, with an active set of 237 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,864:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=3.508e+01, with an active set of 218 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,864:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 195 iterations, alpha=5.462e+01, previous alpha=5.408e+01, with an active set of 180 regressors.
  warnings.warn(

2023-05-27 23:36:28,864:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=3.080e+01, with an active set of 227 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,864:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=3.063e+01, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,880:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=2.199e+01, with an active set of 248 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,880:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 271 iterations, alpha=2.202e+01, previous alpha=2.199e+01, with an active set of 248 regressors.
  warnings.warn(

2023-05-27 23:36:28,895:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.456e+01, with an active set of 242 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,895:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=2.261e+01, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-27 23:36:28,911:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 277 iterations, alpha=2.204e+01, previous alpha=2.193e+01, with an active set of 254 regressors.
  warnings.warn(

2023-05-27 23:36:29,348:INFO:Calculating mean and std
2023-05-27 23:36:29,348:INFO:Creating metrics dataframe
2023-05-27 23:36:29,380:INFO:Uploading results into container
2023-05-27 23:36:29,380:INFO:Uploading model into container now
2023-05-27 23:36:29,380:INFO:_master_model_container: 6
2023-05-27 23:36:29,380:INFO:_display_container: 2
2023-05-27 23:36:29,380:INFO:LassoLars(random_state=123)
2023-05-27 23:36:29,380:INFO:create_model() successfully completed......................................
2023-05-27 23:36:29,473:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:29,473:INFO:Creating metrics dataframe
2023-05-27 23:36:29,489:INFO:Initializing Orthogonal Matching Pursuit
2023-05-27 23:36:29,489:INFO:Total runtime is 0.34331472714742023 minutes
2023-05-27 23:36:29,489:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:29,489:INFO:Initializing create_model()
2023-05-27 23:36:29,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:29,489:INFO:Checking exceptions
2023-05-27 23:36:29,489:INFO:Importing libraries
2023-05-27 23:36:29,489:INFO:Copying training dataset
2023-05-27 23:36:29,505:INFO:Defining folds
2023-05-27 23:36:29,505:INFO:Declaring metric variables
2023-05-27 23:36:29,505:INFO:Importing untrained model
2023-05-27 23:36:29,520:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-27 23:36:29,520:INFO:Starting cross validation
2023-05-27 23:36:29,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:30,114:INFO:Calculating mean and std
2023-05-27 23:36:30,114:INFO:Creating metrics dataframe
2023-05-27 23:36:30,145:INFO:Uploading results into container
2023-05-27 23:36:30,145:INFO:Uploading model into container now
2023-05-27 23:36:30,145:INFO:_master_model_container: 7
2023-05-27 23:36:30,145:INFO:_display_container: 2
2023-05-27 23:36:30,145:INFO:OrthogonalMatchingPursuit()
2023-05-27 23:36:30,145:INFO:create_model() successfully completed......................................
2023-05-27 23:36:30,239:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:30,255:INFO:Creating metrics dataframe
2023-05-27 23:36:30,255:INFO:Initializing Bayesian Ridge
2023-05-27 23:36:30,255:INFO:Total runtime is 0.3560751398404439 minutes
2023-05-27 23:36:30,255:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:30,255:INFO:Initializing create_model()
2023-05-27 23:36:30,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:30,255:INFO:Checking exceptions
2023-05-27 23:36:30,255:INFO:Importing libraries
2023-05-27 23:36:30,255:INFO:Copying training dataset
2023-05-27 23:36:30,286:INFO:Defining folds
2023-05-27 23:36:30,286:INFO:Declaring metric variables
2023-05-27 23:36:30,286:INFO:Importing untrained model
2023-05-27 23:36:30,286:INFO:Bayesian Ridge Imported successfully
2023-05-27 23:36:30,302:INFO:Starting cross validation
2023-05-27 23:36:30,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:31,584:INFO:Calculating mean and std
2023-05-27 23:36:31,600:INFO:Creating metrics dataframe
2023-05-27 23:36:31,631:INFO:Uploading results into container
2023-05-27 23:36:31,631:INFO:Uploading model into container now
2023-05-27 23:36:31,631:INFO:_master_model_container: 8
2023-05-27 23:36:31,631:INFO:_display_container: 2
2023-05-27 23:36:31,631:INFO:BayesianRidge()
2023-05-27 23:36:31,631:INFO:create_model() successfully completed......................................
2023-05-27 23:36:31,725:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:31,725:INFO:Creating metrics dataframe
2023-05-27 23:36:31,725:INFO:Initializing Passive Aggressive Regressor
2023-05-27 23:36:31,725:INFO:Total runtime is 0.38058241605758664 minutes
2023-05-27 23:36:31,741:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:31,741:INFO:Initializing create_model()
2023-05-27 23:36:31,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:31,741:INFO:Checking exceptions
2023-05-27 23:36:31,741:INFO:Importing libraries
2023-05-27 23:36:31,741:INFO:Copying training dataset
2023-05-27 23:36:31,756:INFO:Defining folds
2023-05-27 23:36:31,756:INFO:Declaring metric variables
2023-05-27 23:36:31,756:INFO:Importing untrained model
2023-05-27 23:36:31,756:INFO:Passive Aggressive Regressor Imported successfully
2023-05-27 23:36:31,772:INFO:Starting cross validation
2023-05-27 23:36:31,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:37,618:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,681:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,712:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,790:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,806:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,806:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,806:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,853:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,853:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:37,963:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-27 23:36:38,353:INFO:Calculating mean and std
2023-05-27 23:36:38,353:INFO:Creating metrics dataframe
2023-05-27 23:36:38,400:INFO:Uploading results into container
2023-05-27 23:36:38,400:INFO:Uploading model into container now
2023-05-27 23:36:38,400:INFO:_master_model_container: 9
2023-05-27 23:36:38,400:INFO:_display_container: 2
2023-05-27 23:36:38,400:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-27 23:36:38,400:INFO:create_model() successfully completed......................................
2023-05-27 23:36:38,510:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:38,510:INFO:Creating metrics dataframe
2023-05-27 23:36:38,510:INFO:Initializing Huber Regressor
2023-05-27 23:36:38,510:INFO:Total runtime is 0.49365619818369544 minutes
2023-05-27 23:36:38,525:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:38,525:INFO:Initializing create_model()
2023-05-27 23:36:38,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:38,525:INFO:Checking exceptions
2023-05-27 23:36:38,525:INFO:Importing libraries
2023-05-27 23:36:38,525:INFO:Copying training dataset
2023-05-27 23:36:38,541:INFO:Defining folds
2023-05-27 23:36:38,541:INFO:Declaring metric variables
2023-05-27 23:36:38,541:INFO:Importing untrained model
2023-05-27 23:36:38,556:INFO:Huber Regressor Imported successfully
2023-05-27 23:36:38,556:INFO:Starting cross validation
2023-05-27 23:36:38,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:42,171:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,265:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,265:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,359:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,484:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,484:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,555:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,555:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,633:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:42,649:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-27 23:36:43,009:INFO:Calculating mean and std
2023-05-27 23:36:43,009:INFO:Creating metrics dataframe
2023-05-27 23:36:43,064:INFO:Uploading results into container
2023-05-27 23:36:43,064:INFO:Uploading model into container now
2023-05-27 23:36:43,064:INFO:_master_model_container: 10
2023-05-27 23:36:43,064:INFO:_display_container: 2
2023-05-27 23:36:43,064:INFO:HuberRegressor()
2023-05-27 23:36:43,064:INFO:create_model() successfully completed......................................
2023-05-27 23:36:43,163:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:43,163:INFO:Creating metrics dataframe
2023-05-27 23:36:43,163:INFO:Initializing K Neighbors Regressor
2023-05-27 23:36:43,163:INFO:Total runtime is 0.5712159156799316 minutes
2023-05-27 23:36:43,179:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:43,179:INFO:Initializing create_model()
2023-05-27 23:36:43,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:43,179:INFO:Checking exceptions
2023-05-27 23:36:43,179:INFO:Importing libraries
2023-05-27 23:36:43,179:INFO:Copying training dataset
2023-05-27 23:36:43,194:INFO:Defining folds
2023-05-27 23:36:43,194:INFO:Declaring metric variables
2023-05-27 23:36:43,194:INFO:Importing untrained model
2023-05-27 23:36:43,214:INFO:K Neighbors Regressor Imported successfully
2023-05-27 23:36:43,222:INFO:Starting cross validation
2023-05-27 23:36:43,224:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:44,088:INFO:Calculating mean and std
2023-05-27 23:36:44,104:INFO:Creating metrics dataframe
2023-05-27 23:36:44,156:INFO:Uploading results into container
2023-05-27 23:36:44,156:INFO:Uploading model into container now
2023-05-27 23:36:44,157:INFO:_master_model_container: 11
2023-05-27 23:36:44,157:INFO:_display_container: 2
2023-05-27 23:36:44,158:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-27 23:36:44,158:INFO:create_model() successfully completed......................................
2023-05-27 23:36:44,232:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:44,248:INFO:Creating metrics dataframe
2023-05-27 23:36:44,248:INFO:Initializing Decision Tree Regressor
2023-05-27 23:36:44,248:INFO:Total runtime is 0.5892891526222228 minutes
2023-05-27 23:36:44,248:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:44,248:INFO:Initializing create_model()
2023-05-27 23:36:44,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:44,248:INFO:Checking exceptions
2023-05-27 23:36:44,248:INFO:Importing libraries
2023-05-27 23:36:44,248:INFO:Copying training dataset
2023-05-27 23:36:44,279:INFO:Defining folds
2023-05-27 23:36:44,279:INFO:Declaring metric variables
2023-05-27 23:36:44,287:INFO:Importing untrained model
2023-05-27 23:36:44,291:INFO:Decision Tree Regressor Imported successfully
2023-05-27 23:36:44,299:INFO:Starting cross validation
2023-05-27 23:36:44,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:45,366:INFO:Calculating mean and std
2023-05-27 23:36:45,366:INFO:Creating metrics dataframe
2023-05-27 23:36:45,425:INFO:Uploading results into container
2023-05-27 23:36:45,425:INFO:Uploading model into container now
2023-05-27 23:36:45,425:INFO:_master_model_container: 12
2023-05-27 23:36:45,425:INFO:_display_container: 2
2023-05-27 23:36:45,425:INFO:DecisionTreeRegressor(random_state=123)
2023-05-27 23:36:45,425:INFO:create_model() successfully completed......................................
2023-05-27 23:36:45,514:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:45,514:INFO:Creating metrics dataframe
2023-05-27 23:36:45,514:INFO:Initializing Random Forest Regressor
2023-05-27 23:36:45,514:INFO:Total runtime is 0.6103981852531433 minutes
2023-05-27 23:36:45,530:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:45,530:INFO:Initializing create_model()
2023-05-27 23:36:45,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:45,530:INFO:Checking exceptions
2023-05-27 23:36:45,530:INFO:Importing libraries
2023-05-27 23:36:45,530:INFO:Copying training dataset
2023-05-27 23:36:45,545:INFO:Defining folds
2023-05-27 23:36:45,545:INFO:Declaring metric variables
2023-05-27 23:36:45,545:INFO:Importing untrained model
2023-05-27 23:36:45,560:INFO:Random Forest Regressor Imported successfully
2023-05-27 23:36:45,568:INFO:Starting cross validation
2023-05-27 23:36:45,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:52,022:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:36:52,793:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:36:54,386:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-27 23:36:54,461:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:36:55,513:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-27 23:36:56,074:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-27 23:36:56,460:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-27 23:36:56,637:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-27 23:36:56,715:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:36:56,722:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:36:57,345:INFO:Calculating mean and std
2023-05-27 23:36:57,355:INFO:Creating metrics dataframe
2023-05-27 23:36:57,425:INFO:Uploading results into container
2023-05-27 23:36:57,426:INFO:Uploading model into container now
2023-05-27 23:36:57,427:INFO:_master_model_container: 13
2023-05-27 23:36:57,427:INFO:_display_container: 2
2023-05-27 23:36:57,428:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-27 23:36:57,428:INFO:create_model() successfully completed......................................
2023-05-27 23:36:57,533:INFO:SubProcess create_model() end ==================================
2023-05-27 23:36:57,533:INFO:Creating metrics dataframe
2023-05-27 23:36:57,548:INFO:Initializing Extra Trees Regressor
2023-05-27 23:36:57,549:INFO:Total runtime is 0.8109764059384663 minutes
2023-05-27 23:36:57,553:INFO:SubProcess create_model() called ==================================
2023-05-27 23:36:57,553:INFO:Initializing create_model()
2023-05-27 23:36:57,553:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:36:57,553:INFO:Checking exceptions
2023-05-27 23:36:57,553:INFO:Importing libraries
2023-05-27 23:36:57,553:INFO:Copying training dataset
2023-05-27 23:36:57,577:INFO:Defining folds
2023-05-27 23:36:57,577:INFO:Declaring metric variables
2023-05-27 23:36:57,578:INFO:Importing untrained model
2023-05-27 23:36:57,587:INFO:Extra Trees Regressor Imported successfully
2023-05-27 23:36:57,597:INFO:Starting cross validation
2023-05-27 23:36:57,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:36:58,641:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-27 23:36:58,810:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-27 23:37:07,856:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:37:07,983:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:37:10,667:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-27 23:37:11,184:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-27 23:37:11,388:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:37:11,388:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-27 23:37:11,435:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:37:11,529:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:37:11,545:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-27 23:37:12,244:INFO:Calculating mean and std
2023-05-27 23:37:12,244:INFO:Creating metrics dataframe
2023-05-27 23:37:12,322:INFO:Uploading results into container
2023-05-27 23:37:12,322:INFO:Uploading model into container now
2023-05-27 23:37:12,322:INFO:_master_model_container: 14
2023-05-27 23:37:12,322:INFO:_display_container: 2
2023-05-27 23:37:12,322:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-27 23:37:12,322:INFO:create_model() successfully completed......................................
2023-05-27 23:37:12,432:INFO:SubProcess create_model() end ==================================
2023-05-27 23:37:12,432:INFO:Creating metrics dataframe
2023-05-27 23:37:12,448:INFO:Initializing AdaBoost Regressor
2023-05-27 23:37:12,448:INFO:Total runtime is 1.0592917323112487 minutes
2023-05-27 23:37:12,448:INFO:SubProcess create_model() called ==================================
2023-05-27 23:37:12,448:INFO:Initializing create_model()
2023-05-27 23:37:12,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:37:12,448:INFO:Checking exceptions
2023-05-27 23:37:12,448:INFO:Importing libraries
2023-05-27 23:37:12,448:INFO:Copying training dataset
2023-05-27 23:37:12,479:INFO:Defining folds
2023-05-27 23:37:12,479:INFO:Declaring metric variables
2023-05-27 23:37:12,479:INFO:Importing untrained model
2023-05-27 23:37:12,479:INFO:AdaBoost Regressor Imported successfully
2023-05-27 23:37:12,495:INFO:Starting cross validation
2023-05-27 23:37:12,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:37:16,222:INFO:Calculating mean and std
2023-05-27 23:37:16,222:INFO:Creating metrics dataframe
2023-05-27 23:37:16,300:INFO:Uploading results into container
2023-05-27 23:37:16,300:INFO:Uploading model into container now
2023-05-27 23:37:16,300:INFO:_master_model_container: 15
2023-05-27 23:37:16,300:INFO:_display_container: 2
2023-05-27 23:37:16,300:INFO:AdaBoostRegressor(random_state=123)
2023-05-27 23:37:16,300:INFO:create_model() successfully completed......................................
2023-05-27 23:37:16,394:INFO:SubProcess create_model() end ==================================
2023-05-27 23:37:16,394:INFO:Creating metrics dataframe
2023-05-27 23:37:16,410:INFO:Initializing Gradient Boosting Regressor
2023-05-27 23:37:16,410:INFO:Total runtime is 1.1253286441167196 minutes
2023-05-27 23:37:16,410:INFO:SubProcess create_model() called ==================================
2023-05-27 23:37:16,410:INFO:Initializing create_model()
2023-05-27 23:37:16,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:37:16,410:INFO:Checking exceptions
2023-05-27 23:37:16,410:INFO:Importing libraries
2023-05-27 23:37:16,410:INFO:Copying training dataset
2023-05-27 23:37:16,425:INFO:Defining folds
2023-05-27 23:37:16,425:INFO:Declaring metric variables
2023-05-27 23:37:16,441:INFO:Importing untrained model
2023-05-27 23:37:16,441:INFO:Gradient Boosting Regressor Imported successfully
2023-05-27 23:37:16,441:INFO:Starting cross validation
2023-05-27 23:37:16,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:37:19,925:INFO:Calculating mean and std
2023-05-27 23:37:19,925:INFO:Creating metrics dataframe
2023-05-27 23:37:20,019:INFO:Uploading results into container
2023-05-27 23:37:20,019:INFO:Uploading model into container now
2023-05-27 23:37:20,019:INFO:_master_model_container: 16
2023-05-27 23:37:20,019:INFO:_display_container: 2
2023-05-27 23:37:20,019:INFO:GradientBoostingRegressor(random_state=123)
2023-05-27 23:37:20,019:INFO:create_model() successfully completed......................................
2023-05-27 23:37:20,097:INFO:SubProcess create_model() end ==================================
2023-05-27 23:37:20,097:INFO:Creating metrics dataframe
2023-05-27 23:37:20,113:INFO:Initializing Light Gradient Boosting Machine
2023-05-27 23:37:20,113:INFO:Total runtime is 1.1870425343513489 minutes
2023-05-27 23:37:20,128:INFO:SubProcess create_model() called ==================================
2023-05-27 23:37:20,128:INFO:Initializing create_model()
2023-05-27 23:37:20,128:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:37:20,128:INFO:Checking exceptions
2023-05-27 23:37:20,128:INFO:Importing libraries
2023-05-27 23:37:20,128:INFO:Copying training dataset
2023-05-27 23:37:20,144:INFO:Defining folds
2023-05-27 23:37:20,144:INFO:Declaring metric variables
2023-05-27 23:37:20,144:INFO:Importing untrained model
2023-05-27 23:37:20,160:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-27 23:37:20,160:INFO:Starting cross validation
2023-05-27 23:37:20,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:37:22,722:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-05-27 23:37:22,722:WARNING:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-27 23:37:22,722:INFO:Initializing create_model()
2023-05-27 23:37:22,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:37:22,722:INFO:Checking exceptions
2023-05-27 23:37:22,722:INFO:Importing libraries
2023-05-27 23:37:22,722:INFO:Copying training dataset
2023-05-27 23:37:22,738:INFO:Defining folds
2023-05-27 23:37:22,738:INFO:Declaring metric variables
2023-05-27 23:37:22,753:INFO:Importing untrained model
2023-05-27 23:37:22,753:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-27 23:37:22,769:INFO:Starting cross validation
2023-05-27 23:37:22,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:37:24,098:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-05-27 23:37:24,098:ERROR:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 808, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-27 23:37:24,238:INFO:Initializing Dummy Regressor
2023-05-27 23:37:24,238:INFO:Total runtime is 1.2557998021443686 minutes
2023-05-27 23:37:24,238:INFO:SubProcess create_model() called ==================================
2023-05-27 23:37:24,238:INFO:Initializing create_model()
2023-05-27 23:37:24,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44D3757E0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:37:24,238:INFO:Checking exceptions
2023-05-27 23:37:24,238:INFO:Importing libraries
2023-05-27 23:37:24,238:INFO:Copying training dataset
2023-05-27 23:37:24,254:INFO:Defining folds
2023-05-27 23:37:24,254:INFO:Declaring metric variables
2023-05-27 23:37:24,269:INFO:Importing untrained model
2023-05-27 23:37:24,269:INFO:Dummy Regressor Imported successfully
2023-05-27 23:37:24,285:INFO:Starting cross validation
2023-05-27 23:37:24,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:37:25,118:INFO:Calculating mean and std
2023-05-27 23:37:25,118:INFO:Creating metrics dataframe
2023-05-27 23:37:25,196:INFO:Uploading results into container
2023-05-27 23:37:25,196:INFO:Uploading model into container now
2023-05-27 23:37:25,196:INFO:_master_model_container: 17
2023-05-27 23:37:25,211:INFO:_display_container: 2
2023-05-27 23:37:25,211:INFO:DummyRegressor()
2023-05-27 23:37:25,211:INFO:create_model() successfully completed......................................
2023-05-27 23:37:25,290:INFO:SubProcess create_model() end ==================================
2023-05-27 23:37:25,305:INFO:Creating metrics dataframe
2023-05-27 23:37:25,321:INFO:Initializing create_model()
2023-05-27 23:37:25,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A449D2F7C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:37:25,321:INFO:Checking exceptions
2023-05-27 23:37:25,321:INFO:Importing libraries
2023-05-27 23:37:25,321:INFO:Copying training dataset
2023-05-27 23:37:25,352:INFO:Defining folds
2023-05-27 23:37:25,352:INFO:Declaring metric variables
2023-05-27 23:37:25,352:INFO:Importing untrained model
2023-05-27 23:37:25,352:INFO:Declaring custom model
2023-05-27 23:37:25,352:INFO:Bayesian Ridge Imported successfully
2023-05-27 23:37:25,352:INFO:Cross validation set to False
2023-05-27 23:37:25,352:INFO:Fitting Model
2023-05-27 23:37:25,868:INFO:BayesianRidge()
2023-05-27 23:37:25,868:INFO:create_model() successfully completed......................................
2023-05-27 23:37:25,993:INFO:_master_model_container: 17
2023-05-27 23:37:25,993:INFO:_display_container: 2
2023-05-27 23:37:25,993:INFO:BayesianRidge()
2023-05-27 23:37:25,993:INFO:compare_models() successfully completed......................................
2023-05-27 23:38:52,656:INFO:PyCaret RegressionExperiment
2023-05-27 23:38:52,656:INFO:Logging name: reg-default-name
2023-05-27 23:38:52,656:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-27 23:38:52,656:INFO:version 3.0.2
2023-05-27 23:38:52,656:INFO:Initializing setup()
2023-05-27 23:38:52,656:INFO:self.USI: ca20
2023-05-27 23:38:52,656:INFO:self._variable_keys: {'y', 'gpu_param', 'USI', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'data', 'y_train', 'fold_groups_param', 'X', 'transform_target_param', 'logging_param', 'target_param', 'idx', 'fold_generator', 'exp_id', 'memory', 'exp_name_log', 'pipeline', 'html_param', 'log_plots_param', 'seed', 'n_jobs_param', '_available_plots', 'fold_shuffle_param', 'X_train', 'y_test'}
2023-05-27 23:38:52,656:INFO:Checking environment
2023-05-27 23:38:52,656:INFO:python_version: 3.10.9
2023-05-27 23:38:52,656:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-05-27 23:38:52,656:INFO:machine: AMD64
2023-05-27 23:38:52,656:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-27 23:38:52,656:INFO:Memory: svmem(total=17041244160, available=2490589184, percent=85.4, used=14550654976, free=2490589184)
2023-05-27 23:38:52,656:INFO:Physical Core: 6
2023-05-27 23:38:52,656:INFO:Logical Core: 12
2023-05-27 23:38:52,656:INFO:Checking libraries
2023-05-27 23:38:52,656:INFO:System:
2023-05-27 23:38:52,656:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-05-27 23:38:52,656:INFO:executable: C:\Users\medo2\anaconda3\python.exe
2023-05-27 23:38:52,656:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-27 23:38:52,656:INFO:PyCaret required dependencies:
2023-05-27 23:38:52,656:INFO:                 pip: 23.0.1
2023-05-27 23:38:52,656:INFO:          setuptools: 65.6.3
2023-05-27 23:38:52,656:INFO:             pycaret: 3.0.2
2023-05-27 23:38:52,656:INFO:             IPython: 8.10.0
2023-05-27 23:38:52,656:INFO:          ipywidgets: 7.6.5
2023-05-27 23:38:52,656:INFO:                tqdm: 4.64.1
2023-05-27 23:38:52,656:INFO:               numpy: 1.23.5
2023-05-27 23:38:52,656:INFO:              pandas: 1.5.3
2023-05-27 23:38:52,656:INFO:              jinja2: 3.1.2
2023-05-27 23:38:52,656:INFO:               scipy: 1.10.0
2023-05-27 23:38:52,656:INFO:              joblib: 1.2.0
2023-05-27 23:38:52,656:INFO:             sklearn: 1.2.1
2023-05-27 23:38:52,656:INFO:                pyod: 1.0.9
2023-05-27 23:38:52,656:INFO:            imblearn: 0.10.1
2023-05-27 23:38:52,656:INFO:   category_encoders: 2.6.1
2023-05-27 23:38:52,656:INFO:            lightgbm: 3.3.5
2023-05-27 23:38:52,656:INFO:               numba: 0.56.4
2023-05-27 23:38:52,656:INFO:            requests: 2.28.1
2023-05-27 23:38:52,656:INFO:          matplotlib: 3.7.0
2023-05-27 23:38:52,656:INFO:          scikitplot: 0.3.7
2023-05-27 23:38:52,656:INFO:         yellowbrick: 1.5
2023-05-27 23:38:52,656:INFO:              plotly: 5.9.0
2023-05-27 23:38:52,656:INFO:             kaleido: 0.2.1
2023-05-27 23:38:52,656:INFO:         statsmodels: 0.13.5
2023-05-27 23:38:52,656:INFO:              sktime: 0.17.0
2023-05-27 23:38:52,656:INFO:               tbats: 1.1.3
2023-05-27 23:38:52,656:INFO:            pmdarima: 2.0.3
2023-05-27 23:38:52,656:INFO:              psutil: 5.9.0
2023-05-27 23:38:52,656:INFO:PyCaret optional dependencies:
2023-05-27 23:38:52,656:INFO:                shap: Not installed
2023-05-27 23:38:52,656:INFO:           interpret: Not installed
2023-05-27 23:38:52,656:INFO:                umap: Not installed
2023-05-27 23:38:52,656:INFO:    pandas_profiling: Not installed
2023-05-27 23:38:52,656:INFO:  explainerdashboard: Not installed
2023-05-27 23:38:52,656:INFO:             autoviz: Not installed
2023-05-27 23:38:52,656:INFO:           fairlearn: Not installed
2023-05-27 23:38:52,656:INFO:             xgboost: Not installed
2023-05-27 23:38:52,656:INFO:            catboost: Not installed
2023-05-27 23:38:52,656:INFO:              kmodes: Not installed
2023-05-27 23:38:52,656:INFO:             mlxtend: Not installed
2023-05-27 23:38:52,656:INFO:       statsforecast: Not installed
2023-05-27 23:38:52,656:INFO:        tune_sklearn: Not installed
2023-05-27 23:38:52,656:INFO:                 ray: Not installed
2023-05-27 23:38:52,656:INFO:            hyperopt: Not installed
2023-05-27 23:38:52,656:INFO:              optuna: Not installed
2023-05-27 23:38:52,656:INFO:               skopt: Not installed
2023-05-27 23:38:52,656:INFO:              mlflow: Not installed
2023-05-27 23:38:52,656:INFO:              gradio: Not installed
2023-05-27 23:38:52,656:INFO:             fastapi: Not installed
2023-05-27 23:38:52,656:INFO:             uvicorn: Not installed
2023-05-27 23:38:52,656:INFO:              m2cgen: Not installed
2023-05-27 23:38:52,656:INFO:           evidently: Not installed
2023-05-27 23:38:52,656:INFO:               fugue: Not installed
2023-05-27 23:38:52,656:INFO:           streamlit: Not installed
2023-05-27 23:38:52,656:INFO:             prophet: Not installed
2023-05-27 23:38:52,656:INFO:None
2023-05-27 23:38:52,656:INFO:Set up data.
2023-05-27 23:38:52,750:INFO:Set up train/test split.
2023-05-27 23:38:52,765:INFO:Set up index.
2023-05-27 23:38:52,765:INFO:Set up folding strategy.
2023-05-27 23:38:52,765:INFO:Assigning column types.
2023-05-27 23:38:52,781:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-27 23:38:52,781:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,781:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:52,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:52,906:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,906:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:38:52,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,015:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-27 23:38:53,031:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,093:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,265:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-27 23:38:53,281:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,359:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,406:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,531:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-27 23:38:53,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,641:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,765:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-27 23:38:53,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:53,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:53,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:38:54,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,014:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-27 23:38:54,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,280:INFO:Preparing preprocessing pipeline...
2023-05-27 23:38:54,280:INFO:Set up simple imputation.
2023-05-27 23:38:54,280:INFO:Set up column name cleaning.
2023-05-27 23:38:54,358:INFO:Finished creating preprocessing pipeline.
2023-05-27 23:38:54,373:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\medo2\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Job title_academic advisor',
                                             'Job title_account manager',
                                             'Job title_accountant',
                                             'Job title_accounting manager',
                                             'Job title_administrative '
                                             'assistant',
                                             'Job title_administrative '
                                             'assistant ',
                                             'Job title_analyst',
                                             'Job title_archivist...
                                             'Job title_digital marketing '
                                             'manager',
                                             'Job title_director',
                                             'Job title_director of '
                                             'engineering',
                                             'Job title_director of operations',
                                             'Job title_editor', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-27 23:38:54,373:INFO:Creating final display dataframe.
2023-05-27 23:38:54,708:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      total_salary
2                   Target type        Regression
3           Original data shape       (3861, 385)
4        Transformed data shape       (3861, 385)
5   Transformed train set shape       (2702, 385)
6    Transformed test set shape       (1159, 385)
7              Numeric features               384
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ca20
2023-05-27 23:38:54,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:38:54,954:INFO:setup() successfully completed in 2.35s...............
2023-05-27 23:39:07,899:INFO:PyCaret RegressionExperiment
2023-05-27 23:39:07,899:INFO:Logging name: reg-default-name
2023-05-27 23:39:07,899:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-27 23:39:07,899:INFO:version 3.0.2
2023-05-27 23:39:07,899:INFO:Initializing setup()
2023-05-27 23:39:07,899:INFO:self.USI: b789
2023-05-27 23:39:07,899:INFO:self._variable_keys: {'y', 'gpu_param', 'USI', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'data', 'y_train', 'fold_groups_param', 'X', 'transform_target_param', 'logging_param', 'target_param', 'idx', 'fold_generator', 'exp_id', 'memory', 'exp_name_log', 'pipeline', 'html_param', 'log_plots_param', 'seed', 'n_jobs_param', '_available_plots', 'fold_shuffle_param', 'X_train', 'y_test'}
2023-05-27 23:39:07,899:INFO:Checking environment
2023-05-27 23:39:07,914:INFO:python_version: 3.10.9
2023-05-27 23:39:07,914:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-05-27 23:39:07,914:INFO:machine: AMD64
2023-05-27 23:39:07,914:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-27 23:39:07,914:INFO:Memory: svmem(total=17041244160, available=2580439040, percent=84.9, used=14460805120, free=2580439040)
2023-05-27 23:39:07,914:INFO:Physical Core: 6
2023-05-27 23:39:07,914:INFO:Logical Core: 12
2023-05-27 23:39:07,914:INFO:Checking libraries
2023-05-27 23:39:07,914:INFO:System:
2023-05-27 23:39:07,914:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-05-27 23:39:07,914:INFO:executable: C:\Users\medo2\anaconda3\python.exe
2023-05-27 23:39:07,914:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-27 23:39:07,914:INFO:PyCaret required dependencies:
2023-05-27 23:39:07,914:INFO:                 pip: 23.0.1
2023-05-27 23:39:07,914:INFO:          setuptools: 65.6.3
2023-05-27 23:39:07,914:INFO:             pycaret: 3.0.2
2023-05-27 23:39:07,914:INFO:             IPython: 8.10.0
2023-05-27 23:39:07,914:INFO:          ipywidgets: 7.6.5
2023-05-27 23:39:07,914:INFO:                tqdm: 4.64.1
2023-05-27 23:39:07,914:INFO:               numpy: 1.23.5
2023-05-27 23:39:07,914:INFO:              pandas: 1.5.3
2023-05-27 23:39:07,914:INFO:              jinja2: 3.1.2
2023-05-27 23:39:07,914:INFO:               scipy: 1.10.0
2023-05-27 23:39:07,914:INFO:              joblib: 1.2.0
2023-05-27 23:39:07,914:INFO:             sklearn: 1.2.1
2023-05-27 23:39:07,914:INFO:                pyod: 1.0.9
2023-05-27 23:39:07,914:INFO:            imblearn: 0.10.1
2023-05-27 23:39:07,914:INFO:   category_encoders: 2.6.1
2023-05-27 23:39:07,914:INFO:            lightgbm: 3.3.5
2023-05-27 23:39:07,914:INFO:               numba: 0.56.4
2023-05-27 23:39:07,914:INFO:            requests: 2.28.1
2023-05-27 23:39:07,914:INFO:          matplotlib: 3.7.0
2023-05-27 23:39:07,914:INFO:          scikitplot: 0.3.7
2023-05-27 23:39:07,914:INFO:         yellowbrick: 1.5
2023-05-27 23:39:07,914:INFO:              plotly: 5.9.0
2023-05-27 23:39:07,914:INFO:             kaleido: 0.2.1
2023-05-27 23:39:07,914:INFO:         statsmodels: 0.13.5
2023-05-27 23:39:07,914:INFO:              sktime: 0.17.0
2023-05-27 23:39:07,914:INFO:               tbats: 1.1.3
2023-05-27 23:39:07,914:INFO:            pmdarima: 2.0.3
2023-05-27 23:39:07,914:INFO:              psutil: 5.9.0
2023-05-27 23:39:07,914:INFO:PyCaret optional dependencies:
2023-05-27 23:39:07,914:INFO:                shap: Not installed
2023-05-27 23:39:07,914:INFO:           interpret: Not installed
2023-05-27 23:39:07,914:INFO:                umap: Not installed
2023-05-27 23:39:07,914:INFO:    pandas_profiling: Not installed
2023-05-27 23:39:07,914:INFO:  explainerdashboard: Not installed
2023-05-27 23:39:07,914:INFO:             autoviz: Not installed
2023-05-27 23:39:07,914:INFO:           fairlearn: Not installed
2023-05-27 23:39:07,914:INFO:             xgboost: Not installed
2023-05-27 23:39:07,914:INFO:            catboost: Not installed
2023-05-27 23:39:07,914:INFO:              kmodes: Not installed
2023-05-27 23:39:07,914:INFO:             mlxtend: Not installed
2023-05-27 23:39:07,914:INFO:       statsforecast: Not installed
2023-05-27 23:39:07,914:INFO:        tune_sklearn: Not installed
2023-05-27 23:39:07,914:INFO:                 ray: Not installed
2023-05-27 23:39:07,914:INFO:            hyperopt: Not installed
2023-05-27 23:39:07,914:INFO:              optuna: Not installed
2023-05-27 23:39:07,914:INFO:               skopt: Not installed
2023-05-27 23:39:07,914:INFO:              mlflow: Not installed
2023-05-27 23:39:07,914:INFO:              gradio: Not installed
2023-05-27 23:39:07,914:INFO:             fastapi: Not installed
2023-05-27 23:39:07,914:INFO:             uvicorn: Not installed
2023-05-27 23:39:07,914:INFO:              m2cgen: Not installed
2023-05-27 23:39:07,914:INFO:           evidently: Not installed
2023-05-27 23:39:07,914:INFO:               fugue: Not installed
2023-05-27 23:39:07,914:INFO:           streamlit: Not installed
2023-05-27 23:39:07,914:INFO:             prophet: Not installed
2023-05-27 23:39:07,914:INFO:None
2023-05-27 23:39:07,914:INFO:Set up data.
2023-05-27 23:39:08,008:INFO:Set up train/test split.
2023-05-27 23:39:08,024:INFO:Set up index.
2023-05-27 23:39:08,024:INFO:Set up folding strategy.
2023-05-27 23:39:08,024:INFO:Assigning column types.
2023-05-27 23:39:08,039:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-27 23:39:08,039:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,149:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,164:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,280:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-27 23:39:08,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,280:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,420:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,425:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,554:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-27 23:39:08,563:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,796:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-27 23:39:08,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:08,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:08,999:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:09,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-27 23:39:09,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,042:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-27 23:39:09,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:09,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-27 23:39:09,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,312:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-27 23:39:09,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:09,553:INFO:Preparing preprocessing pipeline...
2023-05-27 23:39:09,553:INFO:Set up simple imputation.
2023-05-27 23:39:09,569:INFO:Set up column name cleaning.
2023-05-27 23:39:09,647:INFO:Finished creating preprocessing pipeline.
2023-05-27 23:39:09,647:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\medo2\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Job title_academic advisor',
                                             'Job title_account manager',
                                             'Job title_accountant',
                                             'Job title_accounting manager',
                                             'Job title_administrative '
                                             'assistant',
                                             'Job title_administrative '
                                             'assistant ',
                                             'Job title_analyst',
                                             'Job title_archivist...
                                             'Job title_digital marketing '
                                             'manager',
                                             'Job title_director',
                                             'Job title_director of '
                                             'engineering',
                                             'Job title_director of operations',
                                             'Job title_editor', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-27 23:39:09,647:INFO:Creating final display dataframe.
2023-05-27 23:39:09,973:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      total_salary
2                   Target type        Regression
3           Original data shape       (3861, 385)
4        Transformed data shape       (3861, 385)
5   Transformed train set shape       (2702, 385)
6    Transformed test set shape       (1159, 385)
7              Numeric features               384
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b789
2023-05-27 23:39:10,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:10,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:10,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:10,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-27 23:39:10,242:INFO:setup() successfully completed in 2.38s...............
2023-05-27 23:39:21,152:INFO:Initializing compare_models()
2023-05-27 23:39:21,152:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-27 23:39:21,153:INFO:Checking exceptions
2023-05-27 23:39:21,163:INFO:Preparing display monitor
2023-05-27 23:39:21,195:INFO:Initializing Linear Regression
2023-05-27 23:39:21,195:INFO:Total runtime is 0.0 minutes
2023-05-27 23:39:21,199:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:21,199:INFO:Initializing create_model()
2023-05-27 23:39:21,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:21,199:INFO:Checking exceptions
2023-05-27 23:39:21,200:INFO:Importing libraries
2023-05-27 23:39:21,200:INFO:Copying training dataset
2023-05-27 23:39:21,207:INFO:Defining folds
2023-05-27 23:39:21,207:INFO:Declaring metric variables
2023-05-27 23:39:21,222:INFO:Importing untrained model
2023-05-27 23:39:21,222:INFO:Linear Regression Imported successfully
2023-05-27 23:39:21,237:INFO:Starting cross validation
2023-05-27 23:39:21,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:22,093:INFO:Calculating mean and std
2023-05-27 23:39:22,093:INFO:Creating metrics dataframe
2023-05-27 23:39:22,182:INFO:Uploading results into container
2023-05-27 23:39:22,182:INFO:Uploading model into container now
2023-05-27 23:39:22,182:INFO:_master_model_container: 1
2023-05-27 23:39:22,182:INFO:_display_container: 2
2023-05-27 23:39:22,182:INFO:LinearRegression(n_jobs=-1)
2023-05-27 23:39:22,182:INFO:create_model() successfully completed......................................
2023-05-27 23:39:22,295:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:22,295:INFO:Creating metrics dataframe
2023-05-27 23:39:22,304:INFO:Initializing Lasso Regression
2023-05-27 23:39:22,304:INFO:Total runtime is 0.018487783273061116 minutes
2023-05-27 23:39:22,310:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:22,310:INFO:Initializing create_model()
2023-05-27 23:39:22,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:22,310:INFO:Checking exceptions
2023-05-27 23:39:22,311:INFO:Importing libraries
2023-05-27 23:39:22,311:INFO:Copying training dataset
2023-05-27 23:39:22,337:INFO:Defining folds
2023-05-27 23:39:22,338:INFO:Declaring metric variables
2023-05-27 23:39:22,340:INFO:Importing untrained model
2023-05-27 23:39:22,340:INFO:Lasso Regression Imported successfully
2023-05-27 23:39:22,352:INFO:Starting cross validation
2023-05-27 23:39:22,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:23,264:INFO:Calculating mean and std
2023-05-27 23:39:23,265:INFO:Creating metrics dataframe
2023-05-27 23:39:23,330:INFO:Uploading results into container
2023-05-27 23:39:23,346:INFO:Uploading model into container now
2023-05-27 23:39:23,346:INFO:_master_model_container: 2
2023-05-27 23:39:23,346:INFO:_display_container: 2
2023-05-27 23:39:23,346:INFO:Lasso(random_state=123)
2023-05-27 23:39:23,346:INFO:create_model() successfully completed......................................
2023-05-27 23:39:23,424:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:23,424:INFO:Creating metrics dataframe
2023-05-27 23:39:23,440:INFO:Initializing Ridge Regression
2023-05-27 23:39:23,440:INFO:Total runtime is 0.03740472793579101 minutes
2023-05-27 23:39:23,440:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:23,440:INFO:Initializing create_model()
2023-05-27 23:39:23,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:23,440:INFO:Checking exceptions
2023-05-27 23:39:23,440:INFO:Importing libraries
2023-05-27 23:39:23,440:INFO:Copying training dataset
2023-05-27 23:39:23,469:INFO:Defining folds
2023-05-27 23:39:23,469:INFO:Declaring metric variables
2023-05-27 23:39:23,473:INFO:Importing untrained model
2023-05-27 23:39:23,477:INFO:Ridge Regression Imported successfully
2023-05-27 23:39:23,485:INFO:Starting cross validation
2023-05-27 23:39:23,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:24,378:INFO:Calculating mean and std
2023-05-27 23:39:24,378:INFO:Creating metrics dataframe
2023-05-27 23:39:24,472:INFO:Uploading results into container
2023-05-27 23:39:24,472:INFO:Uploading model into container now
2023-05-27 23:39:24,472:INFO:_master_model_container: 3
2023-05-27 23:39:24,472:INFO:_display_container: 2
2023-05-27 23:39:24,472:INFO:Ridge(random_state=123)
2023-05-27 23:39:24,472:INFO:create_model() successfully completed......................................
2023-05-27 23:39:24,550:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:24,550:INFO:Creating metrics dataframe
2023-05-27 23:39:24,565:INFO:Initializing Elastic Net
2023-05-27 23:39:24,565:INFO:Total runtime is 0.05617055495580037 minutes
2023-05-27 23:39:24,565:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:24,565:INFO:Initializing create_model()
2023-05-27 23:39:24,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:24,565:INFO:Checking exceptions
2023-05-27 23:39:24,565:INFO:Importing libraries
2023-05-27 23:39:24,565:INFO:Copying training dataset
2023-05-27 23:39:24,596:INFO:Defining folds
2023-05-27 23:39:24,596:INFO:Declaring metric variables
2023-05-27 23:39:24,600:INFO:Importing untrained model
2023-05-27 23:39:24,605:INFO:Elastic Net Imported successfully
2023-05-27 23:39:24,611:INFO:Starting cross validation
2023-05-27 23:39:24,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:25,524:INFO:Calculating mean and std
2023-05-27 23:39:25,524:INFO:Creating metrics dataframe
2023-05-27 23:39:25,597:INFO:Uploading results into container
2023-05-27 23:39:25,597:INFO:Uploading model into container now
2023-05-27 23:39:25,597:INFO:_master_model_container: 4
2023-05-27 23:39:25,597:INFO:_display_container: 2
2023-05-27 23:39:25,597:INFO:ElasticNet(random_state=123)
2023-05-27 23:39:25,597:INFO:create_model() successfully completed......................................
2023-05-27 23:39:25,675:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:25,690:INFO:Creating metrics dataframe
2023-05-27 23:39:25,690:INFO:Initializing Least Angle Regression
2023-05-27 23:39:25,706:INFO:Total runtime is 0.07518080870310465 minutes
2023-05-27 23:39:25,706:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:25,706:INFO:Initializing create_model()
2023-05-27 23:39:25,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:25,706:INFO:Checking exceptions
2023-05-27 23:39:25,706:INFO:Importing libraries
2023-05-27 23:39:25,706:INFO:Copying training dataset
2023-05-27 23:39:25,733:INFO:Defining folds
2023-05-27 23:39:25,733:INFO:Declaring metric variables
2023-05-27 23:39:25,737:INFO:Importing untrained model
2023-05-27 23:39:25,741:INFO:Least Angle Regression Imported successfully
2023-05-27 23:39:25,749:INFO:Starting cross validation
2023-05-27 23:39:25,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:26,233:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-05-27 23:39:26,234:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-05-27 23:39:26,234:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-05-27 23:39:26,669:INFO:Calculating mean and std
2023-05-27 23:39:26,669:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\numpy\core\_methods.py:236: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2023-05-27 23:39:26,670:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\numpy\core\_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2023-05-27 23:39:26,675:INFO:Creating metrics dataframe
2023-05-27 23:39:26,767:INFO:Uploading results into container
2023-05-27 23:39:26,768:INFO:Uploading model into container now
2023-05-27 23:39:26,768:INFO:_master_model_container: 5
2023-05-27 23:39:26,768:INFO:_display_container: 2
2023-05-27 23:39:26,768:INFO:Lars(random_state=123)
2023-05-27 23:39:26,768:INFO:create_model() successfully completed......................................
2023-05-27 23:39:26,861:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:26,861:INFO:Creating metrics dataframe
2023-05-27 23:39:26,877:INFO:Initializing Lasso Least Angle Regression
2023-05-27 23:39:26,877:INFO:Total runtime is 0.0946937322616577 minutes
2023-05-27 23:39:26,877:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:26,877:INFO:Initializing create_model()
2023-05-27 23:39:26,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:26,877:INFO:Checking exceptions
2023-05-27 23:39:26,877:INFO:Importing libraries
2023-05-27 23:39:26,877:INFO:Copying training dataset
2023-05-27 23:39:26,892:INFO:Defining folds
2023-05-27 23:39:26,892:INFO:Declaring metric variables
2023-05-27 23:39:26,892:INFO:Importing untrained model
2023-05-27 23:39:26,908:INFO:Lasso Least Angle Regression Imported successfully
2023-05-27 23:39:26,908:INFO:Starting cross validation
2023-05-27 23:39:26,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:27,190:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.072e+03, previous alpha=2.067e+03, with an active set of 13 regressors.
  warnings.warn(

2023-05-27 23:39:27,924:INFO:Calculating mean and std
2023-05-27 23:39:27,924:INFO:Creating metrics dataframe
2023-05-27 23:39:28,018:INFO:Uploading results into container
2023-05-27 23:39:28,018:INFO:Uploading model into container now
2023-05-27 23:39:28,018:INFO:_master_model_container: 6
2023-05-27 23:39:28,018:INFO:_display_container: 2
2023-05-27 23:39:28,018:INFO:LassoLars(random_state=123)
2023-05-27 23:39:28,018:INFO:create_model() successfully completed......................................
2023-05-27 23:39:28,096:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:28,096:INFO:Creating metrics dataframe
2023-05-27 23:39:28,112:INFO:Initializing Orthogonal Matching Pursuit
2023-05-27 23:39:28,112:INFO:Total runtime is 0.11527360677719115 minutes
2023-05-27 23:39:28,112:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:28,112:INFO:Initializing create_model()
2023-05-27 23:39:28,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:28,112:INFO:Checking exceptions
2023-05-27 23:39:28,112:INFO:Importing libraries
2023-05-27 23:39:28,112:INFO:Copying training dataset
2023-05-27 23:39:28,143:INFO:Defining folds
2023-05-27 23:39:28,143:INFO:Declaring metric variables
2023-05-27 23:39:28,143:INFO:Importing untrained model
2023-05-27 23:39:28,143:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-27 23:39:28,159:INFO:Starting cross validation
2023-05-27 23:39:28,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:29,109:INFO:Calculating mean and std
2023-05-27 23:39:29,109:INFO:Creating metrics dataframe
2023-05-27 23:39:29,187:INFO:Uploading results into container
2023-05-27 23:39:29,203:INFO:Uploading model into container now
2023-05-27 23:39:29,203:INFO:_master_model_container: 7
2023-05-27 23:39:29,203:INFO:_display_container: 2
2023-05-27 23:39:29,203:INFO:OrthogonalMatchingPursuit()
2023-05-27 23:39:29,203:INFO:create_model() successfully completed......................................
2023-05-27 23:39:29,296:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:29,296:INFO:Creating metrics dataframe
2023-05-27 23:39:29,312:INFO:Initializing Bayesian Ridge
2023-05-27 23:39:29,312:INFO:Total runtime is 0.1352799932161967 minutes
2023-05-27 23:39:29,312:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:29,312:INFO:Initializing create_model()
2023-05-27 23:39:29,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:29,312:INFO:Checking exceptions
2023-05-27 23:39:29,312:INFO:Importing libraries
2023-05-27 23:39:29,312:INFO:Copying training dataset
2023-05-27 23:39:29,343:INFO:Defining folds
2023-05-27 23:39:29,343:INFO:Declaring metric variables
2023-05-27 23:39:29,343:INFO:Importing untrained model
2023-05-27 23:39:29,355:INFO:Bayesian Ridge Imported successfully
2023-05-27 23:39:29,365:INFO:Starting cross validation
2023-05-27 23:39:29,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:30,339:INFO:Calculating mean and std
2023-05-27 23:39:30,339:INFO:Creating metrics dataframe
2023-05-27 23:39:30,417:INFO:Uploading results into container
2023-05-27 23:39:30,417:INFO:Uploading model into container now
2023-05-27 23:39:30,417:INFO:_master_model_container: 8
2023-05-27 23:39:30,417:INFO:_display_container: 2
2023-05-27 23:39:30,417:INFO:BayesianRidge()
2023-05-27 23:39:30,417:INFO:create_model() successfully completed......................................
2023-05-27 23:39:30,511:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:30,511:INFO:Creating metrics dataframe
2023-05-27 23:39:30,527:INFO:Initializing Passive Aggressive Regressor
2023-05-27 23:39:30,527:INFO:Total runtime is 0.15552383661270142 minutes
2023-05-27 23:39:30,527:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:30,527:INFO:Initializing create_model()
2023-05-27 23:39:30,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:30,527:INFO:Checking exceptions
2023-05-27 23:39:30,527:INFO:Importing libraries
2023-05-27 23:39:30,527:INFO:Copying training dataset
2023-05-27 23:39:30,542:INFO:Defining folds
2023-05-27 23:39:30,542:INFO:Declaring metric variables
2023-05-27 23:39:30,558:INFO:Importing untrained model
2023-05-27 23:39:30,558:INFO:Passive Aggressive Regressor Imported successfully
2023-05-27 23:39:30,558:INFO:Starting cross validation
2023-05-27 23:39:30,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:31,512:INFO:Calculating mean and std
2023-05-27 23:39:31,512:INFO:Creating metrics dataframe
2023-05-27 23:39:31,590:INFO:Uploading results into container
2023-05-27 23:39:31,590:INFO:Uploading model into container now
2023-05-27 23:39:31,590:INFO:_master_model_container: 9
2023-05-27 23:39:31,590:INFO:_display_container: 2
2023-05-27 23:39:31,590:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-27 23:39:31,590:INFO:create_model() successfully completed......................................
2023-05-27 23:39:31,668:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:31,668:INFO:Creating metrics dataframe
2023-05-27 23:39:31,684:INFO:Initializing Huber Regressor
2023-05-27 23:39:31,684:INFO:Total runtime is 0.1748052716255188 minutes
2023-05-27 23:39:31,684:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:31,684:INFO:Initializing create_model()
2023-05-27 23:39:31,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:31,684:INFO:Checking exceptions
2023-05-27 23:39:31,684:INFO:Importing libraries
2023-05-27 23:39:31,684:INFO:Copying training dataset
2023-05-27 23:39:31,715:INFO:Defining folds
2023-05-27 23:39:31,715:INFO:Declaring metric variables
2023-05-27 23:39:31,715:INFO:Importing untrained model
2023-05-27 23:39:31,715:INFO:Huber Regressor Imported successfully
2023-05-27 23:39:31,730:INFO:Starting cross validation
2023-05-27 23:39:31,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:32,572:INFO:Calculating mean and std
2023-05-27 23:39:32,572:INFO:Creating metrics dataframe
2023-05-27 23:39:32,650:INFO:Uploading results into container
2023-05-27 23:39:32,650:INFO:Uploading model into container now
2023-05-27 23:39:32,650:INFO:_master_model_container: 10
2023-05-27 23:39:32,650:INFO:_display_container: 2
2023-05-27 23:39:32,650:INFO:HuberRegressor()
2023-05-27 23:39:32,650:INFO:create_model() successfully completed......................................
2023-05-27 23:39:32,728:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:32,728:INFO:Creating metrics dataframe
2023-05-27 23:39:32,744:INFO:Initializing K Neighbors Regressor
2023-05-27 23:39:32,744:INFO:Total runtime is 0.1924789230028788 minutes
2023-05-27 23:39:32,744:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:32,744:INFO:Initializing create_model()
2023-05-27 23:39:32,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:32,744:INFO:Checking exceptions
2023-05-27 23:39:32,744:INFO:Importing libraries
2023-05-27 23:39:32,744:INFO:Copying training dataset
2023-05-27 23:39:32,775:INFO:Defining folds
2023-05-27 23:39:32,775:INFO:Declaring metric variables
2023-05-27 23:39:32,775:INFO:Importing untrained model
2023-05-27 23:39:32,775:INFO:K Neighbors Regressor Imported successfully
2023-05-27 23:39:32,775:INFO:Starting cross validation
2023-05-27 23:39:32,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:33,757:INFO:Calculating mean and std
2023-05-27 23:39:33,757:INFO:Creating metrics dataframe
2023-05-27 23:39:33,835:INFO:Uploading results into container
2023-05-27 23:39:33,835:INFO:Uploading model into container now
2023-05-27 23:39:33,835:INFO:_master_model_container: 11
2023-05-27 23:39:33,835:INFO:_display_container: 2
2023-05-27 23:39:33,835:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-27 23:39:33,835:INFO:create_model() successfully completed......................................
2023-05-27 23:39:33,929:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:33,929:INFO:Creating metrics dataframe
2023-05-27 23:39:33,929:INFO:Initializing Decision Tree Regressor
2023-05-27 23:39:33,929:INFO:Total runtime is 0.2122276425361633 minutes
2023-05-27 23:39:33,945:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:33,945:INFO:Initializing create_model()
2023-05-27 23:39:33,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:33,945:INFO:Checking exceptions
2023-05-27 23:39:33,945:INFO:Importing libraries
2023-05-27 23:39:33,945:INFO:Copying training dataset
2023-05-27 23:39:33,960:INFO:Defining folds
2023-05-27 23:39:33,960:INFO:Declaring metric variables
2023-05-27 23:39:33,960:INFO:Importing untrained model
2023-05-27 23:39:33,960:INFO:Decision Tree Regressor Imported successfully
2023-05-27 23:39:33,981:INFO:Starting cross validation
2023-05-27 23:39:33,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:34,877:INFO:Calculating mean and std
2023-05-27 23:39:34,877:INFO:Creating metrics dataframe
2023-05-27 23:39:34,963:INFO:Uploading results into container
2023-05-27 23:39:34,963:INFO:Uploading model into container now
2023-05-27 23:39:34,963:INFO:_master_model_container: 12
2023-05-27 23:39:34,963:INFO:_display_container: 2
2023-05-27 23:39:34,963:INFO:DecisionTreeRegressor(random_state=123)
2023-05-27 23:39:34,963:INFO:create_model() successfully completed......................................
2023-05-27 23:39:35,077:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:35,077:INFO:Creating metrics dataframe
2023-05-27 23:39:35,109:INFO:Initializing Random Forest Regressor
2023-05-27 23:39:35,109:INFO:Total runtime is 0.23189202547073362 minutes
2023-05-27 23:39:35,109:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:35,109:INFO:Initializing create_model()
2023-05-27 23:39:35,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:35,109:INFO:Checking exceptions
2023-05-27 23:39:35,109:INFO:Importing libraries
2023-05-27 23:39:35,109:INFO:Copying training dataset
2023-05-27 23:39:35,124:INFO:Defining folds
2023-05-27 23:39:35,124:INFO:Declaring metric variables
2023-05-27 23:39:35,140:INFO:Importing untrained model
2023-05-27 23:39:35,140:INFO:Random Forest Regressor Imported successfully
2023-05-27 23:39:35,140:INFO:Starting cross validation
2023-05-27 23:39:35,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:36,482:INFO:Calculating mean and std
2023-05-27 23:39:36,482:INFO:Creating metrics dataframe
2023-05-27 23:39:36,575:INFO:Uploading results into container
2023-05-27 23:39:36,575:INFO:Uploading model into container now
2023-05-27 23:39:36,575:INFO:_master_model_container: 13
2023-05-27 23:39:36,575:INFO:_display_container: 2
2023-05-27 23:39:36,575:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-27 23:39:36,575:INFO:create_model() successfully completed......................................
2023-05-27 23:39:36,676:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:36,676:INFO:Creating metrics dataframe
2023-05-27 23:39:36,676:INFO:Initializing Extra Trees Regressor
2023-05-27 23:39:36,676:INFO:Total runtime is 0.258005694548289 minutes
2023-05-27 23:39:36,691:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:36,691:INFO:Initializing create_model()
2023-05-27 23:39:36,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:36,691:INFO:Checking exceptions
2023-05-27 23:39:36,691:INFO:Importing libraries
2023-05-27 23:39:36,691:INFO:Copying training dataset
2023-05-27 23:39:36,707:INFO:Defining folds
2023-05-27 23:39:36,707:INFO:Declaring metric variables
2023-05-27 23:39:36,707:INFO:Importing untrained model
2023-05-27 23:39:36,722:INFO:Extra Trees Regressor Imported successfully
2023-05-27 23:39:36,722:INFO:Starting cross validation
2023-05-27 23:39:36,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:38,059:INFO:Calculating mean and std
2023-05-27 23:39:38,059:INFO:Creating metrics dataframe
2023-05-27 23:39:38,159:INFO:Uploading results into container
2023-05-27 23:39:38,159:INFO:Uploading model into container now
2023-05-27 23:39:38,159:INFO:_master_model_container: 14
2023-05-27 23:39:38,159:INFO:_display_container: 2
2023-05-27 23:39:38,159:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-27 23:39:38,159:INFO:create_model() successfully completed......................................
2023-05-27 23:39:38,252:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:38,252:INFO:Creating metrics dataframe
2023-05-27 23:39:38,268:INFO:Initializing AdaBoost Regressor
2023-05-27 23:39:38,268:INFO:Total runtime is 0.2845476269721985 minutes
2023-05-27 23:39:38,268:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:38,284:INFO:Initializing create_model()
2023-05-27 23:39:38,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:38,284:INFO:Checking exceptions
2023-05-27 23:39:38,284:INFO:Importing libraries
2023-05-27 23:39:38,284:INFO:Copying training dataset
2023-05-27 23:39:38,299:INFO:Defining folds
2023-05-27 23:39:38,299:INFO:Declaring metric variables
2023-05-27 23:39:38,299:INFO:Importing untrained model
2023-05-27 23:39:38,315:INFO:AdaBoost Regressor Imported successfully
2023-05-27 23:39:38,315:INFO:Starting cross validation
2023-05-27 23:39:38,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:39,317:INFO:Calculating mean and std
2023-05-27 23:39:39,317:INFO:Creating metrics dataframe
2023-05-27 23:39:39,411:INFO:Uploading results into container
2023-05-27 23:39:39,411:INFO:Uploading model into container now
2023-05-27 23:39:39,411:INFO:_master_model_container: 15
2023-05-27 23:39:39,411:INFO:_display_container: 2
2023-05-27 23:39:39,411:INFO:AdaBoostRegressor(random_state=123)
2023-05-27 23:39:39,411:INFO:create_model() successfully completed......................................
2023-05-27 23:39:39,505:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:39,505:INFO:Creating metrics dataframe
2023-05-27 23:39:39,520:INFO:Initializing Gradient Boosting Regressor
2023-05-27 23:39:39,520:INFO:Total runtime is 0.3054196238517761 minutes
2023-05-27 23:39:39,520:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:39,520:INFO:Initializing create_model()
2023-05-27 23:39:39,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:39,520:INFO:Checking exceptions
2023-05-27 23:39:39,520:INFO:Importing libraries
2023-05-27 23:39:39,520:INFO:Copying training dataset
2023-05-27 23:39:39,552:INFO:Defining folds
2023-05-27 23:39:39,552:INFO:Declaring metric variables
2023-05-27 23:39:39,552:INFO:Importing untrained model
2023-05-27 23:39:39,552:INFO:Gradient Boosting Regressor Imported successfully
2023-05-27 23:39:39,567:INFO:Starting cross validation
2023-05-27 23:39:39,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:40,590:INFO:Calculating mean and std
2023-05-27 23:39:40,590:INFO:Creating metrics dataframe
2023-05-27 23:39:40,668:INFO:Uploading results into container
2023-05-27 23:39:40,668:INFO:Uploading model into container now
2023-05-27 23:39:40,668:INFO:_master_model_container: 16
2023-05-27 23:39:40,668:INFO:_display_container: 2
2023-05-27 23:39:40,668:INFO:GradientBoostingRegressor(random_state=123)
2023-05-27 23:39:40,668:INFO:create_model() successfully completed......................................
2023-05-27 23:39:40,754:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:40,754:INFO:Creating metrics dataframe
2023-05-27 23:39:40,769:INFO:Initializing Light Gradient Boosting Machine
2023-05-27 23:39:40,769:INFO:Total runtime is 0.3262317975362142 minutes
2023-05-27 23:39:40,785:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:40,785:INFO:Initializing create_model()
2023-05-27 23:39:40,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:40,785:INFO:Checking exceptions
2023-05-27 23:39:40,785:INFO:Importing libraries
2023-05-27 23:39:40,785:INFO:Copying training dataset
2023-05-27 23:39:40,811:INFO:Defining folds
2023-05-27 23:39:40,811:INFO:Declaring metric variables
2023-05-27 23:39:40,816:INFO:Importing untrained model
2023-05-27 23:39:40,816:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-27 23:39:40,832:INFO:Starting cross validation
2023-05-27 23:39:40,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:41,661:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-05-27 23:39:41,661:WARNING:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-27 23:39:41,661:INFO:Initializing create_model()
2023-05-27 23:39:41,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:41,661:INFO:Checking exceptions
2023-05-27 23:39:41,661:INFO:Importing libraries
2023-05-27 23:39:41,661:INFO:Copying training dataset
2023-05-27 23:39:41,692:INFO:Defining folds
2023-05-27 23:39:41,692:INFO:Declaring metric variables
2023-05-27 23:39:41,692:INFO:Importing untrained model
2023-05-27 23:39:41,692:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-27 23:39:41,708:INFO:Starting cross validation
2023-05-27 23:39:41,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:42,539:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-05-27 23:39:42,539:ERROR:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 808, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-27 23:39:42,664:INFO:Initializing Dummy Regressor
2023-05-27 23:39:42,664:INFO:Total runtime is 0.3578199783960978 minutes
2023-05-27 23:39:42,664:INFO:SubProcess create_model() called ==================================
2023-05-27 23:39:42,664:INFO:Initializing create_model()
2023-05-27 23:39:42,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A449D2E2C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:42,664:INFO:Checking exceptions
2023-05-27 23:39:42,664:INFO:Importing libraries
2023-05-27 23:39:42,664:INFO:Copying training dataset
2023-05-27 23:39:42,680:INFO:Defining folds
2023-05-27 23:39:42,680:INFO:Declaring metric variables
2023-05-27 23:39:42,680:INFO:Importing untrained model
2023-05-27 23:39:42,697:INFO:Dummy Regressor Imported successfully
2023-05-27 23:39:42,709:INFO:Starting cross validation
2023-05-27 23:39:42,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:39:43,593:INFO:Calculating mean and std
2023-05-27 23:39:43,594:INFO:Creating metrics dataframe
2023-05-27 23:39:43,674:INFO:Uploading results into container
2023-05-27 23:39:43,675:INFO:Uploading model into container now
2023-05-27 23:39:43,675:INFO:_master_model_container: 17
2023-05-27 23:39:43,675:INFO:_display_container: 2
2023-05-27 23:39:43,675:INFO:DummyRegressor()
2023-05-27 23:39:43,675:INFO:create_model() successfully completed......................................
2023-05-27 23:39:43,765:INFO:SubProcess create_model() end ==================================
2023-05-27 23:39:43,765:INFO:Creating metrics dataframe
2023-05-27 23:39:43,781:INFO:Initializing create_model()
2023-05-27 23:39:43,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44CE06770>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:39:43,781:INFO:Checking exceptions
2023-05-27 23:39:43,781:INFO:Importing libraries
2023-05-27 23:39:43,781:INFO:Copying training dataset
2023-05-27 23:39:43,801:INFO:Defining folds
2023-05-27 23:39:43,801:INFO:Declaring metric variables
2023-05-27 23:39:43,801:INFO:Importing untrained model
2023-05-27 23:39:43,801:INFO:Declaring custom model
2023-05-27 23:39:43,801:INFO:Bayesian Ridge Imported successfully
2023-05-27 23:39:43,801:INFO:Cross validation set to False
2023-05-27 23:39:43,801:INFO:Fitting Model
2023-05-27 23:39:43,942:INFO:BayesianRidge()
2023-05-27 23:39:43,942:INFO:create_model() successfully completed......................................
2023-05-27 23:39:44,067:INFO:_master_model_container: 17
2023-05-27 23:39:44,067:INFO:_display_container: 2
2023-05-27 23:39:44,067:INFO:BayesianRidge()
2023-05-27 23:39:44,067:INFO:compare_models() successfully completed......................................
2023-05-27 23:40:04,443:INFO:Initializing compare_models()
2023-05-27 23:40:04,443:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-27 23:40:04,444:INFO:Checking exceptions
2023-05-27 23:40:04,451:INFO:Preparing display monitor
2023-05-27 23:40:04,480:INFO:Initializing Linear Regression
2023-05-27 23:40:04,481:INFO:Total runtime is 1.6629695892333984e-05 minutes
2023-05-27 23:40:04,486:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:04,486:INFO:Initializing create_model()
2023-05-27 23:40:04,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:04,486:INFO:Checking exceptions
2023-05-27 23:40:04,487:INFO:Importing libraries
2023-05-27 23:40:04,487:INFO:Copying training dataset
2023-05-27 23:40:04,508:INFO:Defining folds
2023-05-27 23:40:04,508:INFO:Declaring metric variables
2023-05-27 23:40:04,511:INFO:Importing untrained model
2023-05-27 23:40:04,515:INFO:Linear Regression Imported successfully
2023-05-27 23:40:04,525:INFO:Starting cross validation
2023-05-27 23:40:04,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:05,380:INFO:Calculating mean and std
2023-05-27 23:40:05,380:INFO:Creating metrics dataframe
2023-05-27 23:40:05,458:INFO:Uploading results into container
2023-05-27 23:40:05,458:INFO:Uploading model into container now
2023-05-27 23:40:05,458:INFO:_master_model_container: 1
2023-05-27 23:40:05,458:INFO:_display_container: 2
2023-05-27 23:40:05,458:INFO:LinearRegression(n_jobs=-1)
2023-05-27 23:40:05,458:INFO:create_model() successfully completed......................................
2023-05-27 23:40:05,561:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:05,561:INFO:Creating metrics dataframe
2023-05-27 23:40:05,566:INFO:Initializing Lasso Regression
2023-05-27 23:40:05,566:INFO:Total runtime is 0.01809550921122233 minutes
2023-05-27 23:40:05,566:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:05,566:INFO:Initializing create_model()
2023-05-27 23:40:05,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:05,566:INFO:Checking exceptions
2023-05-27 23:40:05,566:INFO:Importing libraries
2023-05-27 23:40:05,566:INFO:Copying training dataset
2023-05-27 23:40:05,595:INFO:Defining folds
2023-05-27 23:40:05,595:INFO:Declaring metric variables
2023-05-27 23:40:05,599:INFO:Importing untrained model
2023-05-27 23:40:05,603:INFO:Lasso Regression Imported successfully
2023-05-27 23:40:05,610:INFO:Starting cross validation
2023-05-27 23:40:05,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:06,474:INFO:Calculating mean and std
2023-05-27 23:40:06,474:INFO:Creating metrics dataframe
2023-05-27 23:40:06,554:INFO:Uploading results into container
2023-05-27 23:40:06,554:INFO:Uploading model into container now
2023-05-27 23:40:06,554:INFO:_master_model_container: 2
2023-05-27 23:40:06,554:INFO:_display_container: 2
2023-05-27 23:40:06,554:INFO:Lasso(random_state=123)
2023-05-27 23:40:06,554:INFO:create_model() successfully completed......................................
2023-05-27 23:40:06,636:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:06,636:INFO:Creating metrics dataframe
2023-05-27 23:40:06,652:INFO:Initializing Ridge Regression
2023-05-27 23:40:06,652:INFO:Total runtime is 0.03619960149129232 minutes
2023-05-27 23:40:06,652:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:06,652:INFO:Initializing create_model()
2023-05-27 23:40:06,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:06,652:INFO:Checking exceptions
2023-05-27 23:40:06,652:INFO:Importing libraries
2023-05-27 23:40:06,652:INFO:Copying training dataset
2023-05-27 23:40:06,685:INFO:Defining folds
2023-05-27 23:40:06,685:INFO:Declaring metric variables
2023-05-27 23:40:06,689:INFO:Importing untrained model
2023-05-27 23:40:06,694:INFO:Ridge Regression Imported successfully
2023-05-27 23:40:06,702:INFO:Starting cross validation
2023-05-27 23:40:06,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:07,632:INFO:Calculating mean and std
2023-05-27 23:40:07,632:INFO:Creating metrics dataframe
2023-05-27 23:40:07,713:INFO:Uploading results into container
2023-05-27 23:40:07,713:INFO:Uploading model into container now
2023-05-27 23:40:07,713:INFO:_master_model_container: 3
2023-05-27 23:40:07,713:INFO:_display_container: 2
2023-05-27 23:40:07,713:INFO:Ridge(random_state=123)
2023-05-27 23:40:07,713:INFO:create_model() successfully completed......................................
2023-05-27 23:40:07,822:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:07,822:INFO:Creating metrics dataframe
2023-05-27 23:40:07,838:INFO:Initializing Elastic Net
2023-05-27 23:40:07,838:INFO:Total runtime is 0.055957118670145675 minutes
2023-05-27 23:40:07,838:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:07,838:INFO:Initializing create_model()
2023-05-27 23:40:07,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:07,838:INFO:Checking exceptions
2023-05-27 23:40:07,838:INFO:Importing libraries
2023-05-27 23:40:07,838:INFO:Copying training dataset
2023-05-27 23:40:07,872:INFO:Defining folds
2023-05-27 23:40:07,872:INFO:Declaring metric variables
2023-05-27 23:40:07,876:INFO:Importing untrained model
2023-05-27 23:40:07,881:INFO:Elastic Net Imported successfully
2023-05-27 23:40:07,891:INFO:Starting cross validation
2023-05-27 23:40:07,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:08,865:INFO:Calculating mean and std
2023-05-27 23:40:08,865:INFO:Creating metrics dataframe
2023-05-27 23:40:08,955:INFO:Uploading results into container
2023-05-27 23:40:08,955:INFO:Uploading model into container now
2023-05-27 23:40:08,955:INFO:_master_model_container: 4
2023-05-27 23:40:08,955:INFO:_display_container: 2
2023-05-27 23:40:08,955:INFO:ElasticNet(random_state=123)
2023-05-27 23:40:08,955:INFO:create_model() successfully completed......................................
2023-05-27 23:40:09,049:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:09,049:INFO:Creating metrics dataframe
2023-05-27 23:40:09,065:INFO:Initializing Least Angle Regression
2023-05-27 23:40:09,065:INFO:Total runtime is 0.07640820344289144 minutes
2023-05-27 23:40:09,075:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:09,075:INFO:Initializing create_model()
2023-05-27 23:40:09,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:09,075:INFO:Checking exceptions
2023-05-27 23:40:09,076:INFO:Importing libraries
2023-05-27 23:40:09,076:INFO:Copying training dataset
2023-05-27 23:40:09,099:INFO:Defining folds
2023-05-27 23:40:09,099:INFO:Declaring metric variables
2023-05-27 23:40:09,103:INFO:Importing untrained model
2023-05-27 23:40:09,107:INFO:Least Angle Regression Imported successfully
2023-05-27 23:40:09,115:INFO:Starting cross validation
2023-05-27 23:40:09,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:09,571:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-05-27 23:40:09,571:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-05-27 23:40:09,571:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\metrics\_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-05-27 23:40:10,024:INFO:Calculating mean and std
2023-05-27 23:40:10,024:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\numpy\core\_methods.py:236: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2023-05-27 23:40:10,024:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\numpy\core\_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2023-05-27 23:40:10,024:INFO:Creating metrics dataframe
2023-05-27 23:40:10,097:INFO:Uploading results into container
2023-05-27 23:40:10,097:INFO:Uploading model into container now
2023-05-27 23:40:10,097:INFO:_master_model_container: 5
2023-05-27 23:40:10,097:INFO:_display_container: 2
2023-05-27 23:40:10,097:INFO:Lars(random_state=123)
2023-05-27 23:40:10,097:INFO:create_model() successfully completed......................................
2023-05-27 23:40:10,191:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:10,191:INFO:Creating metrics dataframe
2023-05-27 23:40:10,191:INFO:Initializing Lasso Least Angle Regression
2023-05-27 23:40:10,191:INFO:Total runtime is 0.09517486492792765 minutes
2023-05-27 23:40:10,207:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:10,207:INFO:Initializing create_model()
2023-05-27 23:40:10,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:10,208:INFO:Checking exceptions
2023-05-27 23:40:10,208:INFO:Importing libraries
2023-05-27 23:40:10,208:INFO:Copying training dataset
2023-05-27 23:40:10,231:INFO:Defining folds
2023-05-27 23:40:10,231:INFO:Declaring metric variables
2023-05-27 23:40:10,234:INFO:Importing untrained model
2023-05-27 23:40:10,238:INFO:Lasso Least Angle Regression Imported successfully
2023-05-27 23:40:10,247:INFO:Starting cross validation
2023-05-27 23:40:10,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:10,449:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.072e+03, previous alpha=2.067e+03, with an active set of 13 regressors.
  warnings.warn(

2023-05-27 23:40:11,122:INFO:Calculating mean and std
2023-05-27 23:40:11,122:INFO:Creating metrics dataframe
2023-05-27 23:40:11,211:INFO:Uploading results into container
2023-05-27 23:40:11,211:INFO:Uploading model into container now
2023-05-27 23:40:11,211:INFO:_master_model_container: 6
2023-05-27 23:40:11,211:INFO:_display_container: 2
2023-05-27 23:40:11,211:INFO:LassoLars(random_state=123)
2023-05-27 23:40:11,211:INFO:create_model() successfully completed......................................
2023-05-27 23:40:11,305:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:11,305:INFO:Creating metrics dataframe
2023-05-27 23:40:11,305:INFO:Initializing Orthogonal Matching Pursuit
2023-05-27 23:40:11,305:INFO:Total runtime is 0.1137460708618164 minutes
2023-05-27 23:40:11,320:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:11,320:INFO:Initializing create_model()
2023-05-27 23:40:11,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:11,320:INFO:Checking exceptions
2023-05-27 23:40:11,320:INFO:Importing libraries
2023-05-27 23:40:11,320:INFO:Copying training dataset
2023-05-27 23:40:11,343:INFO:Defining folds
2023-05-27 23:40:11,343:INFO:Declaring metric variables
2023-05-27 23:40:11,347:INFO:Importing untrained model
2023-05-27 23:40:11,352:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-27 23:40:11,359:INFO:Starting cross validation
2023-05-27 23:40:11,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:12,227:INFO:Calculating mean and std
2023-05-27 23:40:12,242:INFO:Creating metrics dataframe
2023-05-27 23:40:12,304:INFO:Uploading results into container
2023-05-27 23:40:12,319:INFO:Uploading model into container now
2023-05-27 23:40:12,319:INFO:_master_model_container: 7
2023-05-27 23:40:12,319:INFO:_display_container: 2
2023-05-27 23:40:12,319:INFO:OrthogonalMatchingPursuit()
2023-05-27 23:40:12,319:INFO:create_model() successfully completed......................................
2023-05-27 23:40:12,413:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:12,413:INFO:Creating metrics dataframe
2023-05-27 23:40:12,433:INFO:Initializing Bayesian Ridge
2023-05-27 23:40:12,433:INFO:Total runtime is 0.13254501819610595 minutes
2023-05-27 23:40:12,437:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:12,438:INFO:Initializing create_model()
2023-05-27 23:40:12,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:12,438:INFO:Checking exceptions
2023-05-27 23:40:12,438:INFO:Importing libraries
2023-05-27 23:40:12,438:INFO:Copying training dataset
2023-05-27 23:40:12,464:INFO:Defining folds
2023-05-27 23:40:12,464:INFO:Declaring metric variables
2023-05-27 23:40:12,468:INFO:Importing untrained model
2023-05-27 23:40:12,473:INFO:Bayesian Ridge Imported successfully
2023-05-27 23:40:12,474:INFO:Starting cross validation
2023-05-27 23:40:12,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:13,324:INFO:Calculating mean and std
2023-05-27 23:40:13,324:INFO:Creating metrics dataframe
2023-05-27 23:40:13,403:INFO:Uploading results into container
2023-05-27 23:40:13,403:INFO:Uploading model into container now
2023-05-27 23:40:13,403:INFO:_master_model_container: 8
2023-05-27 23:40:13,403:INFO:_display_container: 2
2023-05-27 23:40:13,403:INFO:BayesianRidge()
2023-05-27 23:40:13,403:INFO:create_model() successfully completed......................................
2023-05-27 23:40:13,490:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:13,490:INFO:Creating metrics dataframe
2023-05-27 23:40:13,504:INFO:Initializing Passive Aggressive Regressor
2023-05-27 23:40:13,504:INFO:Total runtime is 0.15039221048355103 minutes
2023-05-27 23:40:13,506:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:13,506:INFO:Initializing create_model()
2023-05-27 23:40:13,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:13,506:INFO:Checking exceptions
2023-05-27 23:40:13,506:INFO:Importing libraries
2023-05-27 23:40:13,506:INFO:Copying training dataset
2023-05-27 23:40:13,526:INFO:Defining folds
2023-05-27 23:40:13,531:INFO:Declaring metric variables
2023-05-27 23:40:13,535:INFO:Importing untrained model
2023-05-27 23:40:13,539:INFO:Passive Aggressive Regressor Imported successfully
2023-05-27 23:40:13,547:INFO:Starting cross validation
2023-05-27 23:40:13,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:14,390:INFO:Calculating mean and std
2023-05-27 23:40:14,406:INFO:Creating metrics dataframe
2023-05-27 23:40:14,478:INFO:Uploading results into container
2023-05-27 23:40:14,478:INFO:Uploading model into container now
2023-05-27 23:40:14,478:INFO:_master_model_container: 9
2023-05-27 23:40:14,478:INFO:_display_container: 2
2023-05-27 23:40:14,478:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-27 23:40:14,478:INFO:create_model() successfully completed......................................
2023-05-27 23:40:14,564:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:14,564:INFO:Creating metrics dataframe
2023-05-27 23:40:14,580:INFO:Initializing Huber Regressor
2023-05-27 23:40:14,580:INFO:Total runtime is 0.16832815806070964 minutes
2023-05-27 23:40:14,590:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:14,590:INFO:Initializing create_model()
2023-05-27 23:40:14,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:14,590:INFO:Checking exceptions
2023-05-27 23:40:14,590:INFO:Importing libraries
2023-05-27 23:40:14,590:INFO:Copying training dataset
2023-05-27 23:40:14,613:INFO:Defining folds
2023-05-27 23:40:14,613:INFO:Declaring metric variables
2023-05-27 23:40:14,617:INFO:Importing untrained model
2023-05-27 23:40:14,620:INFO:Huber Regressor Imported successfully
2023-05-27 23:40:14,626:INFO:Starting cross validation
2023-05-27 23:40:14,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:15,480:INFO:Calculating mean and std
2023-05-27 23:40:15,480:INFO:Creating metrics dataframe
2023-05-27 23:40:15,545:INFO:Uploading results into container
2023-05-27 23:40:15,561:INFO:Uploading model into container now
2023-05-27 23:40:15,561:INFO:_master_model_container: 10
2023-05-27 23:40:15,561:INFO:_display_container: 2
2023-05-27 23:40:15,561:INFO:HuberRegressor()
2023-05-27 23:40:15,561:INFO:create_model() successfully completed......................................
2023-05-27 23:40:15,638:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:15,638:INFO:Creating metrics dataframe
2023-05-27 23:40:15,654:INFO:Initializing K Neighbors Regressor
2023-05-27 23:40:15,654:INFO:Total runtime is 0.18622848987579346 minutes
2023-05-27 23:40:15,669:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:15,669:INFO:Initializing create_model()
2023-05-27 23:40:15,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:15,669:INFO:Checking exceptions
2023-05-27 23:40:15,669:INFO:Importing libraries
2023-05-27 23:40:15,669:INFO:Copying training dataset
2023-05-27 23:40:15,690:INFO:Defining folds
2023-05-27 23:40:15,690:INFO:Declaring metric variables
2023-05-27 23:40:15,697:INFO:Importing untrained model
2023-05-27 23:40:15,702:INFO:K Neighbors Regressor Imported successfully
2023-05-27 23:40:15,711:INFO:Starting cross validation
2023-05-27 23:40:15,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:16,656:INFO:Calculating mean and std
2023-05-27 23:40:16,656:INFO:Creating metrics dataframe
2023-05-27 23:40:16,753:INFO:Uploading results into container
2023-05-27 23:40:16,753:INFO:Uploading model into container now
2023-05-27 23:40:16,753:INFO:_master_model_container: 11
2023-05-27 23:40:16,753:INFO:_display_container: 2
2023-05-27 23:40:16,753:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-27 23:40:16,753:INFO:create_model() successfully completed......................................
2023-05-27 23:40:16,846:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:16,846:INFO:Creating metrics dataframe
2023-05-27 23:40:16,846:INFO:Initializing Decision Tree Regressor
2023-05-27 23:40:16,846:INFO:Total runtime is 0.2061058799425761 minutes
2023-05-27 23:40:16,866:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:16,866:INFO:Initializing create_model()
2023-05-27 23:40:16,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:16,866:INFO:Checking exceptions
2023-05-27 23:40:16,867:INFO:Importing libraries
2023-05-27 23:40:16,867:INFO:Copying training dataset
2023-05-27 23:40:16,891:INFO:Defining folds
2023-05-27 23:40:16,891:INFO:Declaring metric variables
2023-05-27 23:40:16,895:INFO:Importing untrained model
2023-05-27 23:40:16,899:INFO:Decision Tree Regressor Imported successfully
2023-05-27 23:40:16,907:INFO:Starting cross validation
2023-05-27 23:40:16,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:17,751:INFO:Calculating mean and std
2023-05-27 23:40:17,753:INFO:Creating metrics dataframe
2023-05-27 23:40:17,846:INFO:Uploading results into container
2023-05-27 23:40:17,847:INFO:Uploading model into container now
2023-05-27 23:40:17,847:INFO:_master_model_container: 12
2023-05-27 23:40:17,848:INFO:_display_container: 2
2023-05-27 23:40:17,848:INFO:DecisionTreeRegressor(random_state=123)
2023-05-27 23:40:17,848:INFO:create_model() successfully completed......................................
2023-05-27 23:40:17,946:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:17,946:INFO:Creating metrics dataframe
2023-05-27 23:40:17,959:INFO:Initializing Random Forest Regressor
2023-05-27 23:40:17,959:INFO:Total runtime is 0.22464176416397094 minutes
2023-05-27 23:40:17,962:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:17,963:INFO:Initializing create_model()
2023-05-27 23:40:17,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:17,963:INFO:Checking exceptions
2023-05-27 23:40:17,963:INFO:Importing libraries
2023-05-27 23:40:17,963:INFO:Copying training dataset
2023-05-27 23:40:17,986:INFO:Defining folds
2023-05-27 23:40:17,986:INFO:Declaring metric variables
2023-05-27 23:40:17,990:INFO:Importing untrained model
2023-05-27 23:40:17,994:INFO:Random Forest Regressor Imported successfully
2023-05-27 23:40:18,001:INFO:Starting cross validation
2023-05-27 23:40:18,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:19,126:INFO:Calculating mean and std
2023-05-27 23:40:19,126:INFO:Creating metrics dataframe
2023-05-27 23:40:19,195:INFO:Uploading results into container
2023-05-27 23:40:19,195:INFO:Uploading model into container now
2023-05-27 23:40:19,195:INFO:_master_model_container: 13
2023-05-27 23:40:19,195:INFO:_display_container: 2
2023-05-27 23:40:19,195:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-27 23:40:19,195:INFO:create_model() successfully completed......................................
2023-05-27 23:40:19,289:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:19,289:INFO:Creating metrics dataframe
2023-05-27 23:40:19,305:INFO:Initializing Extra Trees Regressor
2023-05-27 23:40:19,305:INFO:Total runtime is 0.24707628885904948 minutes
2023-05-27 23:40:19,305:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:19,305:INFO:Initializing create_model()
2023-05-27 23:40:19,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:19,305:INFO:Checking exceptions
2023-05-27 23:40:19,305:INFO:Importing libraries
2023-05-27 23:40:19,305:INFO:Copying training dataset
2023-05-27 23:40:19,336:INFO:Defining folds
2023-05-27 23:40:19,336:INFO:Declaring metric variables
2023-05-27 23:40:19,339:INFO:Importing untrained model
2023-05-27 23:40:19,343:INFO:Extra Trees Regressor Imported successfully
2023-05-27 23:40:19,350:INFO:Starting cross validation
2023-05-27 23:40:19,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:20,530:INFO:Calculating mean and std
2023-05-27 23:40:20,530:INFO:Creating metrics dataframe
2023-05-27 23:40:20,620:INFO:Uploading results into container
2023-05-27 23:40:20,620:INFO:Uploading model into container now
2023-05-27 23:40:20,620:INFO:_master_model_container: 14
2023-05-27 23:40:20,620:INFO:_display_container: 2
2023-05-27 23:40:20,620:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-27 23:40:20,620:INFO:create_model() successfully completed......................................
2023-05-27 23:40:20,713:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:20,713:INFO:Creating metrics dataframe
2023-05-27 23:40:20,729:INFO:Initializing AdaBoost Regressor
2023-05-27 23:40:20,729:INFO:Total runtime is 0.27081449031829835 minutes
2023-05-27 23:40:20,729:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:20,729:INFO:Initializing create_model()
2023-05-27 23:40:20,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:20,729:INFO:Checking exceptions
2023-05-27 23:40:20,729:INFO:Importing libraries
2023-05-27 23:40:20,729:INFO:Copying training dataset
2023-05-27 23:40:20,759:INFO:Defining folds
2023-05-27 23:40:20,759:INFO:Declaring metric variables
2023-05-27 23:40:20,763:INFO:Importing untrained model
2023-05-27 23:40:20,768:INFO:AdaBoost Regressor Imported successfully
2023-05-27 23:40:20,775:INFO:Starting cross validation
2023-05-27 23:40:20,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:21,669:INFO:Calculating mean and std
2023-05-27 23:40:21,669:INFO:Creating metrics dataframe
2023-05-27 23:40:21,738:INFO:Uploading results into container
2023-05-27 23:40:21,738:INFO:Uploading model into container now
2023-05-27 23:40:21,738:INFO:_master_model_container: 15
2023-05-27 23:40:21,738:INFO:_display_container: 2
2023-05-27 23:40:21,738:INFO:AdaBoostRegressor(random_state=123)
2023-05-27 23:40:21,738:INFO:create_model() successfully completed......................................
2023-05-27 23:40:21,832:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:21,832:INFO:Creating metrics dataframe
2023-05-27 23:40:21,848:INFO:Initializing Gradient Boosting Regressor
2023-05-27 23:40:21,848:INFO:Total runtime is 0.28945658604304 minutes
2023-05-27 23:40:21,848:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:21,848:INFO:Initializing create_model()
2023-05-27 23:40:21,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:21,848:INFO:Checking exceptions
2023-05-27 23:40:21,848:INFO:Importing libraries
2023-05-27 23:40:21,848:INFO:Copying training dataset
2023-05-27 23:40:21,881:INFO:Defining folds
2023-05-27 23:40:21,881:INFO:Declaring metric variables
2023-05-27 23:40:21,892:INFO:Importing untrained model
2023-05-27 23:40:21,897:INFO:Gradient Boosting Regressor Imported successfully
2023-05-27 23:40:21,906:INFO:Starting cross validation
2023-05-27 23:40:21,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:22,872:INFO:Calculating mean and std
2023-05-27 23:40:22,872:INFO:Creating metrics dataframe
2023-05-27 23:40:22,955:INFO:Uploading results into container
2023-05-27 23:40:22,955:INFO:Uploading model into container now
2023-05-27 23:40:22,955:INFO:_master_model_container: 16
2023-05-27 23:40:22,955:INFO:_display_container: 2
2023-05-27 23:40:22,955:INFO:GradientBoostingRegressor(random_state=123)
2023-05-27 23:40:22,955:INFO:create_model() successfully completed......................................
2023-05-27 23:40:23,053:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:23,054:INFO:Creating metrics dataframe
2023-05-27 23:40:23,057:INFO:Initializing Light Gradient Boosting Machine
2023-05-27 23:40:23,057:INFO:Total runtime is 0.3096133788426717 minutes
2023-05-27 23:40:23,071:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:23,072:INFO:Initializing create_model()
2023-05-27 23:40:23,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:23,072:INFO:Checking exceptions
2023-05-27 23:40:23,073:INFO:Importing libraries
2023-05-27 23:40:23,073:INFO:Copying training dataset
2023-05-27 23:40:23,098:INFO:Defining folds
2023-05-27 23:40:23,099:INFO:Declaring metric variables
2023-05-27 23:40:23,104:INFO:Importing untrained model
2023-05-27 23:40:23,108:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-27 23:40:23,117:INFO:Starting cross validation
2023-05-27 23:40:23,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:23,970:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-05-27 23:40:23,970:WARNING:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-27 23:40:23,970:INFO:Initializing create_model()
2023-05-27 23:40:23,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:23,970:INFO:Checking exceptions
2023-05-27 23:40:23,970:INFO:Importing libraries
2023-05-27 23:40:23,970:INFO:Copying training dataset
2023-05-27 23:40:24,001:INFO:Defining folds
2023-05-27 23:40:24,001:INFO:Declaring metric variables
2023-05-27 23:40:24,001:INFO:Importing untrained model
2023-05-27 23:40:24,001:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-27 23:40:24,017:INFO:Starting cross validation
2023-05-27 23:40:24,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:24,878:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-05-27 23:40:24,878:ERROR:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 808, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-27 23:40:25,003:INFO:Initializing Dummy Regressor
2023-05-27 23:40:25,003:INFO:Total runtime is 0.34204197724660235 minutes
2023-05-27 23:40:25,018:INFO:SubProcess create_model() called ==================================
2023-05-27 23:40:25,018:INFO:Initializing create_model()
2023-05-27 23:40:25,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A44CFA2E00>, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:25,018:INFO:Checking exceptions
2023-05-27 23:40:25,018:INFO:Importing libraries
2023-05-27 23:40:25,018:INFO:Copying training dataset
2023-05-27 23:40:25,034:INFO:Defining folds
2023-05-27 23:40:25,034:INFO:Declaring metric variables
2023-05-27 23:40:25,034:INFO:Importing untrained model
2023-05-27 23:40:25,034:INFO:Dummy Regressor Imported successfully
2023-05-27 23:40:25,050:INFO:Starting cross validation
2023-05-27 23:40:25,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-27 23:40:25,956:INFO:Calculating mean and std
2023-05-27 23:40:25,956:INFO:Creating metrics dataframe
2023-05-27 23:40:26,034:INFO:Uploading results into container
2023-05-27 23:40:26,034:INFO:Uploading model into container now
2023-05-27 23:40:26,034:INFO:_master_model_container: 17
2023-05-27 23:40:26,034:INFO:_display_container: 2
2023-05-27 23:40:26,034:INFO:DummyRegressor()
2023-05-27 23:40:26,034:INFO:create_model() successfully completed......................................
2023-05-27 23:40:26,128:INFO:SubProcess create_model() end ==================================
2023-05-27 23:40:26,128:INFO:Creating metrics dataframe
2023-05-27 23:40:26,143:INFO:Initializing create_model()
2023-05-27 23:40:26,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A44D06DC30>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-27 23:40:26,143:INFO:Checking exceptions
2023-05-27 23:40:26,159:INFO:Importing libraries
2023-05-27 23:40:26,159:INFO:Copying training dataset
2023-05-27 23:40:26,175:INFO:Defining folds
2023-05-27 23:40:26,175:INFO:Declaring metric variables
2023-05-27 23:40:26,175:INFO:Importing untrained model
2023-05-27 23:40:26,175:INFO:Declaring custom model
2023-05-27 23:40:26,175:INFO:Bayesian Ridge Imported successfully
2023-05-27 23:40:26,175:INFO:Cross validation set to False
2023-05-27 23:40:26,175:INFO:Fitting Model
2023-05-27 23:40:26,321:INFO:BayesianRidge()
2023-05-27 23:40:26,321:INFO:create_model() successfully completed......................................
2023-05-27 23:40:26,472:INFO:_master_model_container: 17
2023-05-27 23:40:26,472:INFO:_display_container: 2
2023-05-27 23:40:26,472:INFO:BayesianRidge()
2023-05-27 23:40:26,472:INFO:compare_models() successfully completed......................................
2023-05-28 00:10:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 00:10:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 00:10:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 00:10:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 00:10:48,082:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-28 00:15:06,220:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2023-05-28 00:32:12,160:INFO:PyCaret RegressionExperiment
2023-05-28 00:32:12,160:INFO:Logging name: reg-default-name
2023-05-28 00:32:12,160:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-28 00:32:12,160:INFO:version 3.0.2
2023-05-28 00:32:12,160:INFO:Initializing setup()
2023-05-28 00:32:12,160:INFO:self.USI: f4c1
2023-05-28 00:32:12,160:INFO:self._variable_keys: {'seed', 'X_train', 'log_plots_param', 'pipeline', 'n_jobs_param', 'fold_groups_param', 'logging_param', 'X_test', 'fold_shuffle_param', 'memory', 'y_train', 'y', 'exp_id', 'gpu_param', 'y_test', 'X', 'gpu_n_jobs_param', 'transform_target_param', 'USI', 'fold_generator', 'html_param', 'exp_name_log', 'target_param', '_ml_usecase', 'idx', 'data', '_available_plots'}
2023-05-28 00:32:12,160:INFO:Checking environment
2023-05-28 00:32:12,160:INFO:python_version: 3.10.9
2023-05-28 00:32:12,160:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-05-28 00:32:12,160:INFO:machine: AMD64
2023-05-28 00:32:12,160:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-28 00:32:12,160:INFO:Memory: svmem(total=17041244160, available=2860625920, percent=83.2, used=14180618240, free=2860625920)
2023-05-28 00:32:12,160:INFO:Physical Core: 6
2023-05-28 00:32:12,160:INFO:Logical Core: 12
2023-05-28 00:32:12,160:INFO:Checking libraries
2023-05-28 00:32:12,160:INFO:System:
2023-05-28 00:32:12,160:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-05-28 00:32:12,160:INFO:executable: C:\Users\medo2\anaconda3\python.exe
2023-05-28 00:32:12,160:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-28 00:32:12,160:INFO:PyCaret required dependencies:
2023-05-28 00:32:12,160:INFO:                 pip: 23.0.1
2023-05-28 00:32:12,160:INFO:          setuptools: 65.6.3
2023-05-28 00:32:12,160:INFO:             pycaret: 3.0.2
2023-05-28 00:32:12,160:INFO:             IPython: 8.10.0
2023-05-28 00:32:12,160:INFO:          ipywidgets: 7.6.5
2023-05-28 00:32:12,160:INFO:                tqdm: 4.64.1
2023-05-28 00:32:12,160:INFO:               numpy: 1.23.5
2023-05-28 00:32:12,160:INFO:              pandas: 1.5.3
2023-05-28 00:32:12,160:INFO:              jinja2: 3.1.2
2023-05-28 00:32:12,160:INFO:               scipy: 1.10.0
2023-05-28 00:32:12,160:INFO:              joblib: 1.2.0
2023-05-28 00:32:12,160:INFO:             sklearn: 1.2.1
2023-05-28 00:32:12,160:INFO:                pyod: 1.0.9
2023-05-28 00:32:12,160:INFO:            imblearn: 0.10.1
2023-05-28 00:32:12,160:INFO:   category_encoders: 2.6.1
2023-05-28 00:32:12,160:INFO:            lightgbm: 3.3.5
2023-05-28 00:32:12,160:INFO:               numba: 0.56.4
2023-05-28 00:32:12,160:INFO:            requests: 2.28.1
2023-05-28 00:32:12,160:INFO:          matplotlib: 3.7.0
2023-05-28 00:32:12,160:INFO:          scikitplot: 0.3.7
2023-05-28 00:32:12,160:INFO:         yellowbrick: 1.5
2023-05-28 00:32:12,160:INFO:              plotly: 5.9.0
2023-05-28 00:32:12,160:INFO:             kaleido: 0.2.1
2023-05-28 00:32:12,160:INFO:         statsmodels: 0.13.5
2023-05-28 00:32:12,160:INFO:              sktime: 0.17.0
2023-05-28 00:32:12,160:INFO:               tbats: 1.1.3
2023-05-28 00:32:12,160:INFO:            pmdarima: 2.0.3
2023-05-28 00:32:12,160:INFO:              psutil: 5.9.0
2023-05-28 00:32:12,160:INFO:PyCaret optional dependencies:
2023-05-28 00:32:12,176:INFO:                shap: Not installed
2023-05-28 00:32:12,176:INFO:           interpret: Not installed
2023-05-28 00:32:12,176:INFO:                umap: Not installed
2023-05-28 00:32:12,176:INFO:    pandas_profiling: Not installed
2023-05-28 00:32:12,176:INFO:  explainerdashboard: Not installed
2023-05-28 00:32:12,176:INFO:             autoviz: Not installed
2023-05-28 00:32:12,176:INFO:           fairlearn: Not installed
2023-05-28 00:32:12,176:INFO:             xgboost: Not installed
2023-05-28 00:32:12,176:INFO:            catboost: Not installed
2023-05-28 00:32:12,176:INFO:              kmodes: Not installed
2023-05-28 00:32:12,176:INFO:             mlxtend: Not installed
2023-05-28 00:32:12,176:INFO:       statsforecast: Not installed
2023-05-28 00:32:12,176:INFO:        tune_sklearn: Not installed
2023-05-28 00:32:12,176:INFO:                 ray: Not installed
2023-05-28 00:32:12,176:INFO:            hyperopt: Not installed
2023-05-28 00:32:12,176:INFO:              optuna: Not installed
2023-05-28 00:32:12,176:INFO:               skopt: Not installed
2023-05-28 00:32:12,176:INFO:              mlflow: Not installed
2023-05-28 00:32:12,176:INFO:              gradio: Not installed
2023-05-28 00:32:12,176:INFO:             fastapi: Not installed
2023-05-28 00:32:12,176:INFO:             uvicorn: Not installed
2023-05-28 00:32:12,191:INFO:              m2cgen: Not installed
2023-05-28 00:32:12,191:INFO:           evidently: Not installed
2023-05-28 00:32:12,191:INFO:               fugue: Not installed
2023-05-28 00:32:12,191:INFO:           streamlit: Not installed
2023-05-28 00:32:12,191:INFO:             prophet: Not installed
2023-05-28 00:32:12,191:INFO:None
2023-05-28 00:32:12,191:INFO:Set up data.
2023-05-28 00:32:12,332:INFO:Set up train/test split.
2023-05-28 00:32:12,363:INFO:Set up index.
2023-05-28 00:32:12,363:INFO:Set up folding strategy.
2023-05-28 00:32:12,363:INFO:Assigning column types.
2023-05-28 00:32:12,379:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-28 00:32:12,379:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,379:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,379:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:12,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:12,765:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,780:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,780:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:12,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:12,890:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-28 00:32:12,905:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:32:12,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,017:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,142:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-28 00:32:13,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,282:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,392:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-28 00:32:13,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,643:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-28 00:32:13,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:32:13,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:13,894:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-28 00:32:14,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:14,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:14,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:14,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:14,161:INFO:Preparing preprocessing pipeline...
2023-05-28 00:32:14,161:INFO:Set up simple imputation.
2023-05-28 00:32:14,161:INFO:Set up column name cleaning.
2023-05-28 00:32:14,302:INFO:Finished creating preprocessing pipeline.
2023-05-28 00:32:14,302:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\medo2\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Job title_academic advisor',
                                             'Job title_account executive',
                                             'Job title_account manager',
                                             'Job title_accountant',
                                             'Job title_accounting manager',
                                             'Job title_administrative '
                                             'assistant',
                                             'Job title_administrative '
                                             'assistant ',
                                             'Job title_...
                                             'Job title_branch manager',
                                             'Job title_business analyst',
                                             'Job title_business development '
                                             'manager',
                                             'Job title_business intelligence '
                                             'analyst',
                                             'Job title_case manager', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-28 00:32:14,302:INFO:Creating final display dataframe.
2023-05-28 00:32:14,803:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      total_salary
2                   Target type        Regression
3           Original data shape       (5705, 633)
4        Transformed data shape       (5705, 633)
5   Transformed train set shape       (3993, 633)
6    Transformed test set shape       (1712, 633)
7              Numeric features               632
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              f4c1
2023-05-28 00:32:14,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:14,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:15,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:15,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:32:15,116:INFO:setup() successfully completed in 3.02s...............
2023-05-28 00:32:37,252:INFO:Initializing compare_models()
2023-05-28 00:32:37,252:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-28 00:32:37,252:INFO:Checking exceptions
2023-05-28 00:32:37,278:INFO:Preparing display monitor
2023-05-28 00:32:37,313:INFO:Initializing Linear Regression
2023-05-28 00:32:37,313:INFO:Total runtime is 0.0 minutes
2023-05-28 00:32:37,313:INFO:SubProcess create_model() called ==================================
2023-05-28 00:32:37,313:INFO:Initializing create_model()
2023-05-28 00:32:37,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:32:37,313:INFO:Checking exceptions
2023-05-28 00:32:37,313:INFO:Importing libraries
2023-05-28 00:32:37,313:INFO:Copying training dataset
2023-05-28 00:32:37,363:INFO:Defining folds
2023-05-28 00:32:37,363:INFO:Declaring metric variables
2023-05-28 00:32:37,368:INFO:Importing untrained model
2023-05-28 00:32:37,370:INFO:Linear Regression Imported successfully
2023-05-28 00:32:37,381:INFO:Starting cross validation
2023-05-28 00:32:37,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:32:41,870:INFO:Calculating mean and std
2023-05-28 00:32:41,870:INFO:Creating metrics dataframe
2023-05-28 00:32:41,927:INFO:Uploading results into container
2023-05-28 00:32:41,927:INFO:Uploading model into container now
2023-05-28 00:32:41,927:INFO:_master_model_container: 1
2023-05-28 00:32:41,927:INFO:_display_container: 2
2023-05-28 00:32:41,927:INFO:LinearRegression(n_jobs=-1)
2023-05-28 00:32:41,927:INFO:create_model() successfully completed......................................
2023-05-28 00:32:42,035:INFO:SubProcess create_model() end ==================================
2023-05-28 00:32:42,035:INFO:Creating metrics dataframe
2023-05-28 00:32:42,035:INFO:Initializing Lasso Regression
2023-05-28 00:32:42,035:INFO:Total runtime is 0.07870838642120362 minutes
2023-05-28 00:32:42,051:INFO:SubProcess create_model() called ==================================
2023-05-28 00:32:42,051:INFO:Initializing create_model()
2023-05-28 00:32:42,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:32:42,051:INFO:Checking exceptions
2023-05-28 00:32:42,051:INFO:Importing libraries
2023-05-28 00:32:42,051:INFO:Copying training dataset
2023-05-28 00:32:42,082:INFO:Defining folds
2023-05-28 00:32:42,082:INFO:Declaring metric variables
2023-05-28 00:32:42,082:INFO:Importing untrained model
2023-05-28 00:32:42,099:INFO:Lasso Regression Imported successfully
2023-05-28 00:32:42,107:INFO:Starting cross validation
2023-05-28 00:32:42,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:32:48,423:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.206e+11, tolerance: 3.312e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:49,627:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+11, tolerance: 3.344e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:49,932:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+11, tolerance: 2.754e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:50,026:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+11, tolerance: 3.202e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:50,472:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.588e+10, tolerance: 3.325e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:50,485:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+11, tolerance: 3.272e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:50,630:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+11, tolerance: 3.155e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:50,693:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.856e+10, tolerance: 3.013e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:52,155:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+11, tolerance: 3.334e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:52,676:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.986e+10, tolerance: 3.260e+09
  model = cd_fast.enet_coordinate_descent(

2023-05-28 00:32:52,997:INFO:Calculating mean and std
2023-05-28 00:32:52,998:INFO:Creating metrics dataframe
2023-05-28 00:32:53,080:INFO:Uploading results into container
2023-05-28 00:32:53,080:INFO:Uploading model into container now
2023-05-28 00:32:53,081:INFO:_master_model_container: 2
2023-05-28 00:32:53,081:INFO:_display_container: 2
2023-05-28 00:32:53,081:INFO:Lasso(random_state=42)
2023-05-28 00:32:53,081:INFO:create_model() successfully completed......................................
2023-05-28 00:32:53,192:INFO:SubProcess create_model() end ==================================
2023-05-28 00:32:53,192:INFO:Creating metrics dataframe
2023-05-28 00:32:53,202:INFO:Initializing Ridge Regression
2023-05-28 00:32:53,203:INFO:Total runtime is 0.26483458280563354 minutes
2023-05-28 00:32:53,206:INFO:SubProcess create_model() called ==================================
2023-05-28 00:32:53,206:INFO:Initializing create_model()
2023-05-28 00:32:53,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:32:53,207:INFO:Checking exceptions
2023-05-28 00:32:53,207:INFO:Importing libraries
2023-05-28 00:32:53,207:INFO:Copying training dataset
2023-05-28 00:32:53,256:INFO:Defining folds
2023-05-28 00:32:53,256:INFO:Declaring metric variables
2023-05-28 00:32:53,261:INFO:Importing untrained model
2023-05-28 00:32:53,267:INFO:Ridge Regression Imported successfully
2023-05-28 00:32:53,278:INFO:Starting cross validation
2023-05-28 00:32:53,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:32:55,325:INFO:Calculating mean and std
2023-05-28 00:32:55,326:INFO:Creating metrics dataframe
2023-05-28 00:32:55,419:INFO:Uploading results into container
2023-05-28 00:32:55,420:INFO:Uploading model into container now
2023-05-28 00:32:55,420:INFO:_master_model_container: 3
2023-05-28 00:32:55,420:INFO:_display_container: 2
2023-05-28 00:32:55,421:INFO:Ridge(random_state=42)
2023-05-28 00:32:55,421:INFO:create_model() successfully completed......................................
2023-05-28 00:32:55,570:INFO:SubProcess create_model() end ==================================
2023-05-28 00:32:55,570:INFO:Creating metrics dataframe
2023-05-28 00:32:55,584:INFO:Initializing Elastic Net
2023-05-28 00:32:55,584:INFO:Total runtime is 0.30451668898264567 minutes
2023-05-28 00:32:55,589:INFO:SubProcess create_model() called ==================================
2023-05-28 00:32:55,589:INFO:Initializing create_model()
2023-05-28 00:32:55,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:32:55,589:INFO:Checking exceptions
2023-05-28 00:32:55,589:INFO:Importing libraries
2023-05-28 00:32:55,589:INFO:Copying training dataset
2023-05-28 00:32:55,651:INFO:Defining folds
2023-05-28 00:32:55,652:INFO:Declaring metric variables
2023-05-28 00:32:55,658:INFO:Importing untrained model
2023-05-28 00:32:55,663:INFO:Elastic Net Imported successfully
2023-05-28 00:32:55,672:INFO:Starting cross validation
2023-05-28 00:32:55,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:32:57,839:INFO:Calculating mean and std
2023-05-28 00:32:57,839:INFO:Creating metrics dataframe
2023-05-28 00:32:57,931:INFO:Uploading results into container
2023-05-28 00:32:57,932:INFO:Uploading model into container now
2023-05-28 00:32:57,932:INFO:_master_model_container: 4
2023-05-28 00:32:57,932:INFO:_display_container: 2
2023-05-28 00:32:57,932:INFO:ElasticNet(random_state=42)
2023-05-28 00:32:57,933:INFO:create_model() successfully completed......................................
2023-05-28 00:32:58,042:INFO:SubProcess create_model() end ==================================
2023-05-28 00:32:58,042:INFO:Creating metrics dataframe
2023-05-28 00:32:58,053:INFO:Initializing Least Angle Regression
2023-05-28 00:32:58,053:INFO:Total runtime is 0.34567802349726356 minutes
2023-05-28 00:32:58,057:INFO:SubProcess create_model() called ==================================
2023-05-28 00:32:58,057:INFO:Initializing create_model()
2023-05-28 00:32:58,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:32:58,058:INFO:Checking exceptions
2023-05-28 00:32:58,058:INFO:Importing libraries
2023-05-28 00:32:58,058:INFO:Copying training dataset
2023-05-28 00:32:58,098:INFO:Defining folds
2023-05-28 00:32:58,098:INFO:Declaring metric variables
2023-05-28 00:32:58,098:INFO:Importing untrained model
2023-05-28 00:32:58,098:INFO:Least Angle Regression Imported successfully
2023-05-28 00:32:58,113:INFO:Starting cross validation
2023-05-28 00:32:58,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:32:58,574:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.268e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,589:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.184e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,663:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.039e+03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,663:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.417e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,663:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.192e+03, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,679:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.202e+02, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,757:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=3.288e+02, with an active set of 144 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,781:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.116e+02, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,846:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.377e+04, with an active set of 279 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,863:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=2.980e+02, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,881:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=1.354e+04, with an active set of 301 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,896:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=5.456e+01, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,896:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.098e+02, with an active set of 234 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,974:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.497e+02, with an active set of 217 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:58,990:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.441e+02, with an active set of 222 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,006:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 380 iterations, i.e. alpha=1.499e+04, with an active set of 344 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,006:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.511e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,006:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=2.168e+02, with an active set of 280 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,037:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=8.977e+01, with an active set of 266 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,053:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 333 iterations, i.e. alpha=2.771e+02, with an active set of 303 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,074:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 404 iterations, i.e. alpha=1.505e+04, with an active set of 361 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,074:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 409 iterations, i.e. alpha=1.175e+02, with an active set of 356 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,081:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=1.327e+02, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,083:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 304 iterations, i.e. alpha=3.622e+01, with an active set of 284 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,093:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=3.583e+01, with an active set of 288 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,157:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=2.689e+02, with an active set of 337 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,187:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=1.283e+02, with an active set of 298 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,193:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 430 iterations, i.e. alpha=1.728e+04, with an active set of 382 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,211:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 407 iterations, i.e. alpha=2.113e+02, with an active set of 345 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,225:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.660e+02, with an active set of 354 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,234:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 391 iterations, i.e. alpha=2.655e+02, with an active set of 355 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,252:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 413 iterations, i.e. alpha=3.813e+01, with an active set of 364 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,399:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 414 iterations, i.e. alpha=1.149e+02, with an active set of 368 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,430:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 433 iterations, i.e. alpha=2.617e+02, with an active set of 392 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,430:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 433 iterations, i.e. alpha=2.616e+02, with an active set of 392 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,508:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 474 iterations, i.e. alpha=2.930e+05, with an active set of 387 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,524:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 475 iterations, i.e. alpha=2.663e+02, with an active set of 397 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:32:59,728:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 479 iterations, i.e. alpha=4.596e+02, with an active set of 426 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,193:INFO:Calculating mean and std
2023-05-28 00:33:01,193:INFO:Creating metrics dataframe
2023-05-28 00:33:01,255:INFO:Uploading results into container
2023-05-28 00:33:01,255:INFO:Uploading model into container now
2023-05-28 00:33:01,255:INFO:_master_model_container: 5
2023-05-28 00:33:01,255:INFO:_display_container: 2
2023-05-28 00:33:01,255:INFO:Lars(random_state=42)
2023-05-28 00:33:01,255:INFO:create_model() successfully completed......................................
2023-05-28 00:33:01,354:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:01,354:INFO:Creating metrics dataframe
2023-05-28 00:33:01,370:INFO:Initializing Lasso Least Angle Regression
2023-05-28 00:33:01,370:INFO:Total runtime is 0.40095638036727904 minutes
2023-05-28 00:33:01,370:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:01,370:INFO:Initializing create_model()
2023-05-28 00:33:01,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:01,370:INFO:Checking exceptions
2023-05-28 00:33:01,370:INFO:Importing libraries
2023-05-28 00:33:01,370:INFO:Copying training dataset
2023-05-28 00:33:01,417:INFO:Defining folds
2023-05-28 00:33:01,417:INFO:Declaring metric variables
2023-05-28 00:33:01,417:INFO:Importing untrained model
2023-05-28 00:33:01,417:INFO:Lasso Least Angle Regression Imported successfully
2023-05-28 00:33:01,432:INFO:Starting cross validation
2023-05-28 00:33:01,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:01,887:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=2.050e+02, previous alpha=2.049e+02, with an active set of 81 regressors.
  warnings.warn(

2023-05-28 00:33:01,887:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.268e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,902:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.184e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,933:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.564e+02, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,949:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.039e+03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,949:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.417e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,965:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.153e+03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,965:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.014e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:01,965:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 48 iterations, alpha=5.108e+02, previous alpha=4.179e+02, with an active set of 45 regressors.
  warnings.warn(

2023-05-28 00:33:02,043:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.296e+02, previous alpha=2.291e+02, with an active set of 71 regressors.
  warnings.warn(

2023-05-28 00:33:02,216:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 286 iterations, alpha=3.059e+01, previous alpha=3.059e+01, with an active set of 277 regressors.
  warnings.warn(

2023-05-28 00:33:02,261:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 372 iterations, i.e. alpha=1.610e+01, with an active set of 350 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,311:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 379 iterations, i.e. alpha=1.682e+01, with an active set of 353 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,336:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 405 iterations, i.e. alpha=1.360e+01, with an active set of 379 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,351:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=1.509e+01, with an active set of 366 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,367:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.832e+01, with an active set of 339 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,382:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=1.841e+01, with an active set of 340 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,414:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 412 iterations, i.e. alpha=1.364e+01, with an active set of 384 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,429:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 417 iterations, i.e. alpha=1.123e+01, with an active set of 391 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,461:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 436 iterations, i.e. alpha=1.181e+01, with an active set of 406 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,461:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 436 iterations, i.e. alpha=1.158e+01, with an active set of 406 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,476:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 439 iterations, alpha=1.156e+01, previous alpha=1.141e+01, with an active set of 408 regressors.
  warnings.warn(

2023-05-28 00:33:02,492:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 406 iterations, i.e. alpha=1.347e+01, with an active set of 378 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,586:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 440 iterations, i.e. alpha=1.130e+01, with an active set of 408 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,648:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 473 iterations, i.e. alpha=7.682e+00, with an active set of 441 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,679:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 484 iterations, i.e. alpha=8.140e+00, with an active set of 448 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,695:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 463 iterations, i.e. alpha=9.474e+00, with an active set of 427 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,711:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 464 iterations, i.e. alpha=9.214e+00, with an active set of 430 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,726:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 495 iterations, i.e. alpha=7.605e+00, with an active set of 455 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,726:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=8.736e+00, with an active set of 436 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,804:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 489 iterations, i.e. alpha=7.763e+00, with an active set of 447 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:02,804:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 492 iterations, i.e. alpha=7.691e+00, with an active set of 456 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-05-28 00:33:03,729:INFO:Calculating mean and std
2023-05-28 00:33:03,729:INFO:Creating metrics dataframe
2023-05-28 00:33:03,808:INFO:Uploading results into container
2023-05-28 00:33:03,808:INFO:Uploading model into container now
2023-05-28 00:33:03,808:INFO:_master_model_container: 6
2023-05-28 00:33:03,808:INFO:_display_container: 2
2023-05-28 00:33:03,808:INFO:LassoLars(random_state=42)
2023-05-28 00:33:03,808:INFO:create_model() successfully completed......................................
2023-05-28 00:33:03,901:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:03,901:INFO:Creating metrics dataframe
2023-05-28 00:33:03,901:INFO:Initializing Orthogonal Matching Pursuit
2023-05-28 00:33:03,901:INFO:Total runtime is 0.44314433336257936 minutes
2023-05-28 00:33:03,917:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:03,917:INFO:Initializing create_model()
2023-05-28 00:33:03,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:03,917:INFO:Checking exceptions
2023-05-28 00:33:03,917:INFO:Importing libraries
2023-05-28 00:33:03,917:INFO:Copying training dataset
2023-05-28 00:33:03,948:INFO:Defining folds
2023-05-28 00:33:03,948:INFO:Declaring metric variables
2023-05-28 00:33:03,948:INFO:Importing untrained model
2023-05-28 00:33:03,964:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-28 00:33:03,964:INFO:Starting cross validation
2023-05-28 00:33:03,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:05,807:INFO:Calculating mean and std
2023-05-28 00:33:05,807:INFO:Creating metrics dataframe
2023-05-28 00:33:05,885:INFO:Uploading results into container
2023-05-28 00:33:05,885:INFO:Uploading model into container now
2023-05-28 00:33:05,885:INFO:_master_model_container: 7
2023-05-28 00:33:05,885:INFO:_display_container: 2
2023-05-28 00:33:05,885:INFO:OrthogonalMatchingPursuit()
2023-05-28 00:33:05,885:INFO:create_model() successfully completed......................................
2023-05-28 00:33:05,979:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:05,979:INFO:Creating metrics dataframe
2023-05-28 00:33:05,995:INFO:Initializing Bayesian Ridge
2023-05-28 00:33:05,995:INFO:Total runtime is 0.4780376791954041 minutes
2023-05-28 00:33:05,995:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:05,995:INFO:Initializing create_model()
2023-05-28 00:33:05,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:05,995:INFO:Checking exceptions
2023-05-28 00:33:05,995:INFO:Importing libraries
2023-05-28 00:33:05,995:INFO:Copying training dataset
2023-05-28 00:33:06,042:INFO:Defining folds
2023-05-28 00:33:06,042:INFO:Declaring metric variables
2023-05-28 00:33:06,042:INFO:Importing untrained model
2023-05-28 00:33:06,042:INFO:Bayesian Ridge Imported successfully
2023-05-28 00:33:06,057:INFO:Starting cross validation
2023-05-28 00:33:06,057:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:09,859:INFO:Calculating mean and std
2023-05-28 00:33:09,859:INFO:Creating metrics dataframe
2023-05-28 00:33:09,958:INFO:Uploading results into container
2023-05-28 00:33:09,958:INFO:Uploading model into container now
2023-05-28 00:33:09,958:INFO:_master_model_container: 8
2023-05-28 00:33:09,958:INFO:_display_container: 2
2023-05-28 00:33:09,958:INFO:BayesianRidge()
2023-05-28 00:33:09,958:INFO:create_model() successfully completed......................................
2023-05-28 00:33:10,082:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:10,082:INFO:Creating metrics dataframe
2023-05-28 00:33:10,097:INFO:Initializing Passive Aggressive Regressor
2023-05-28 00:33:10,097:INFO:Total runtime is 0.5464015126228333 minutes
2023-05-28 00:33:10,101:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:10,101:INFO:Initializing create_model()
2023-05-28 00:33:10,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:10,101:INFO:Checking exceptions
2023-05-28 00:33:10,101:INFO:Importing libraries
2023-05-28 00:33:10,101:INFO:Copying training dataset
2023-05-28 00:33:10,137:INFO:Defining folds
2023-05-28 00:33:10,137:INFO:Declaring metric variables
2023-05-28 00:33:10,137:INFO:Importing untrained model
2023-05-28 00:33:10,137:INFO:Passive Aggressive Regressor Imported successfully
2023-05-28 00:33:10,153:INFO:Starting cross validation
2023-05-28 00:33:10,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:21,746:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,793:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,808:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,840:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,855:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,855:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,902:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,902:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,918:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:21,918:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1549: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-05-28 00:33:23,162:INFO:Calculating mean and std
2023-05-28 00:33:23,162:INFO:Creating metrics dataframe
2023-05-28 00:33:23,249:INFO:Uploading results into container
2023-05-28 00:33:23,249:INFO:Uploading model into container now
2023-05-28 00:33:23,249:INFO:_master_model_container: 9
2023-05-28 00:33:23,249:INFO:_display_container: 2
2023-05-28 00:33:23,249:INFO:PassiveAggressiveRegressor(random_state=42)
2023-05-28 00:33:23,249:INFO:create_model() successfully completed......................................
2023-05-28 00:33:23,343:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:23,343:INFO:Creating metrics dataframe
2023-05-28 00:33:23,359:INFO:Initializing Huber Regressor
2023-05-28 00:33:23,359:INFO:Total runtime is 0.7674317995707195 minutes
2023-05-28 00:33:23,359:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:23,359:INFO:Initializing create_model()
2023-05-28 00:33:23,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:23,359:INFO:Checking exceptions
2023-05-28 00:33:23,359:INFO:Importing libraries
2023-05-28 00:33:23,359:INFO:Copying training dataset
2023-05-28 00:33:23,390:INFO:Defining folds
2023-05-28 00:33:23,390:INFO:Declaring metric variables
2023-05-28 00:33:23,405:INFO:Importing untrained model
2023-05-28 00:33:23,405:INFO:Huber Regressor Imported successfully
2023-05-28 00:33:23,405:INFO:Starting cross validation
2023-05-28 00:33:23,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:31,783:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:31,799:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:31,815:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:31,893:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:31,955:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:31,987:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:32,127:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:32,158:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:32,158:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:32,190:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:33:33,346:INFO:Calculating mean and std
2023-05-28 00:33:33,346:INFO:Creating metrics dataframe
2023-05-28 00:33:33,440:INFO:Uploading results into container
2023-05-28 00:33:33,440:INFO:Uploading model into container now
2023-05-28 00:33:33,440:INFO:_master_model_container: 10
2023-05-28 00:33:33,440:INFO:_display_container: 2
2023-05-28 00:33:33,440:INFO:HuberRegressor()
2023-05-28 00:33:33,440:INFO:create_model() successfully completed......................................
2023-05-28 00:33:33,518:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:33,518:INFO:Creating metrics dataframe
2023-05-28 00:33:33,534:INFO:Initializing K Neighbors Regressor
2023-05-28 00:33:33,534:INFO:Total runtime is 0.9370152990023296 minutes
2023-05-28 00:33:33,534:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:33,534:INFO:Initializing create_model()
2023-05-28 00:33:33,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:33,534:INFO:Checking exceptions
2023-05-28 00:33:33,534:INFO:Importing libraries
2023-05-28 00:33:33,534:INFO:Copying training dataset
2023-05-28 00:33:33,580:INFO:Defining folds
2023-05-28 00:33:33,580:INFO:Declaring metric variables
2023-05-28 00:33:33,580:INFO:Importing untrained model
2023-05-28 00:33:33,596:INFO:K Neighbors Regressor Imported successfully
2023-05-28 00:33:33,596:INFO:Starting cross validation
2023-05-28 00:33:33,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:35,715:INFO:Calculating mean and std
2023-05-28 00:33:35,715:INFO:Creating metrics dataframe
2023-05-28 00:33:35,858:INFO:Uploading results into container
2023-05-28 00:33:35,859:INFO:Uploading model into container now
2023-05-28 00:33:35,860:INFO:_master_model_container: 11
2023-05-28 00:33:35,860:INFO:_display_container: 2
2023-05-28 00:33:35,860:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-28 00:33:35,860:INFO:create_model() successfully completed......................................
2023-05-28 00:33:35,973:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:35,973:INFO:Creating metrics dataframe
2023-05-28 00:33:35,986:INFO:Initializing Decision Tree Regressor
2023-05-28 00:33:35,986:INFO:Total runtime is 0.9778958400090536 minutes
2023-05-28 00:33:35,990:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:35,991:INFO:Initializing create_model()
2023-05-28 00:33:35,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:35,991:INFO:Checking exceptions
2023-05-28 00:33:35,991:INFO:Importing libraries
2023-05-28 00:33:35,991:INFO:Copying training dataset
2023-05-28 00:33:36,039:INFO:Defining folds
2023-05-28 00:33:36,039:INFO:Declaring metric variables
2023-05-28 00:33:36,043:INFO:Importing untrained model
2023-05-28 00:33:36,049:INFO:Decision Tree Regressor Imported successfully
2023-05-28 00:33:36,056:INFO:Starting cross validation
2023-05-28 00:33:36,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:33:38,591:INFO:Calculating mean and std
2023-05-28 00:33:38,591:INFO:Creating metrics dataframe
2023-05-28 00:33:38,706:INFO:Uploading results into container
2023-05-28 00:33:38,706:INFO:Uploading model into container now
2023-05-28 00:33:38,707:INFO:_master_model_container: 12
2023-05-28 00:33:38,707:INFO:_display_container: 2
2023-05-28 00:33:38,707:INFO:DecisionTreeRegressor(random_state=42)
2023-05-28 00:33:38,707:INFO:create_model() successfully completed......................................
2023-05-28 00:33:38,805:INFO:SubProcess create_model() end ==================================
2023-05-28 00:33:38,806:INFO:Creating metrics dataframe
2023-05-28 00:33:38,806:INFO:Initializing Random Forest Regressor
2023-05-28 00:33:38,806:INFO:Total runtime is 1.0248858650525412 minutes
2023-05-28 00:33:38,806:INFO:SubProcess create_model() called ==================================
2023-05-28 00:33:38,806:INFO:Initializing create_model()
2023-05-28 00:33:38,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:33:38,806:INFO:Checking exceptions
2023-05-28 00:33:38,806:INFO:Importing libraries
2023-05-28 00:33:38,806:INFO:Copying training dataset
2023-05-28 00:33:38,860:INFO:Defining folds
2023-05-28 00:33:38,860:INFO:Declaring metric variables
2023-05-28 00:33:38,860:INFO:Importing untrained model
2023-05-28 00:33:38,860:INFO:Random Forest Regressor Imported successfully
2023-05-28 00:33:38,860:INFO:Starting cross validation
2023-05-28 00:33:38,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:34:02,695:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:03,134:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:03,150:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:03,197:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:05,217:INFO:Calculating mean and std
2023-05-28 00:34:05,217:INFO:Creating metrics dataframe
2023-05-28 00:34:05,358:INFO:Uploading results into container
2023-05-28 00:34:05,358:INFO:Uploading model into container now
2023-05-28 00:34:05,358:INFO:_master_model_container: 13
2023-05-28 00:34:05,358:INFO:_display_container: 2
2023-05-28 00:34:05,358:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-05-28 00:34:05,358:INFO:create_model() successfully completed......................................
2023-05-28 00:34:05,498:INFO:SubProcess create_model() end ==================================
2023-05-28 00:34:05,498:INFO:Creating metrics dataframe
2023-05-28 00:34:05,514:INFO:Initializing Extra Trees Regressor
2023-05-28 00:34:05,514:INFO:Total runtime is 1.4700252095858257 minutes
2023-05-28 00:34:05,514:INFO:SubProcess create_model() called ==================================
2023-05-28 00:34:05,514:INFO:Initializing create_model()
2023-05-28 00:34:05,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:34:05,514:INFO:Checking exceptions
2023-05-28 00:34:05,514:INFO:Importing libraries
2023-05-28 00:34:05,514:INFO:Copying training dataset
2023-05-28 00:34:05,577:INFO:Defining folds
2023-05-28 00:34:05,577:INFO:Declaring metric variables
2023-05-28 00:34:05,577:INFO:Importing untrained model
2023-05-28 00:34:05,592:INFO:Extra Trees Regressor Imported successfully
2023-05-28 00:34:05,608:INFO:Starting cross validation
2023-05-28 00:34:05,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:34:06,474:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:06,535:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-28 00:34:06,574:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-28 00:34:07,505:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:07,568:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-28 00:34:07,583:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:07,646:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:07,756:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-28 00:34:08,818:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:08,990:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:09,084:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-28 00:34:31,277:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:32,065:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:33,219:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:35,682:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-28 00:34:35,976:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-28 00:34:36,345:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-28 00:34:37,871:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-28 00:34:37,936:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-28 00:34:39,676:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:39,846:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-28 00:34:40,342:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:40,704:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-28 00:34:42,254:INFO:Calculating mean and std
2023-05-28 00:34:42,254:INFO:Creating metrics dataframe
2023-05-28 00:34:42,379:INFO:Uploading results into container
2023-05-28 00:34:42,379:INFO:Uploading model into container now
2023-05-28 00:34:42,379:INFO:_master_model_container: 14
2023-05-28 00:34:42,379:INFO:_display_container: 2
2023-05-28 00:34:42,379:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-05-28 00:34:42,379:INFO:create_model() successfully completed......................................
2023-05-28 00:34:42,472:INFO:SubProcess create_model() end ==================================
2023-05-28 00:34:42,472:INFO:Creating metrics dataframe
2023-05-28 00:34:42,488:INFO:Initializing AdaBoost Regressor
2023-05-28 00:34:42,488:INFO:Total runtime is 2.08625864982605 minutes
2023-05-28 00:34:42,488:INFO:SubProcess create_model() called ==================================
2023-05-28 00:34:42,488:INFO:Initializing create_model()
2023-05-28 00:34:42,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:34:42,488:INFO:Checking exceptions
2023-05-28 00:34:42,488:INFO:Importing libraries
2023-05-28 00:34:42,488:INFO:Copying training dataset
2023-05-28 00:34:42,538:INFO:Defining folds
2023-05-28 00:34:42,539:INFO:Declaring metric variables
2023-05-28 00:34:42,542:INFO:Importing untrained model
2023-05-28 00:34:42,546:INFO:AdaBoost Regressor Imported successfully
2023-05-28 00:34:42,547:INFO:Starting cross validation
2023-05-28 00:34:42,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:34:56,503:INFO:Calculating mean and std
2023-05-28 00:34:56,503:INFO:Creating metrics dataframe
2023-05-28 00:34:56,659:INFO:Uploading results into container
2023-05-28 00:34:56,675:INFO:Uploading model into container now
2023-05-28 00:34:56,675:INFO:_master_model_container: 15
2023-05-28 00:34:56,675:INFO:_display_container: 2
2023-05-28 00:34:56,675:INFO:AdaBoostRegressor(random_state=42)
2023-05-28 00:34:56,675:INFO:create_model() successfully completed......................................
2023-05-28 00:34:56,798:INFO:SubProcess create_model() end ==================================
2023-05-28 00:34:56,798:INFO:Creating metrics dataframe
2023-05-28 00:34:56,814:INFO:Initializing Gradient Boosting Regressor
2023-05-28 00:34:56,814:INFO:Total runtime is 2.325024648507436 minutes
2023-05-28 00:34:56,814:INFO:SubProcess create_model() called ==================================
2023-05-28 00:34:56,814:INFO:Initializing create_model()
2023-05-28 00:34:56,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:34:56,814:INFO:Checking exceptions
2023-05-28 00:34:56,814:INFO:Importing libraries
2023-05-28 00:34:56,814:INFO:Copying training dataset
2023-05-28 00:34:56,877:INFO:Defining folds
2023-05-28 00:34:56,877:INFO:Declaring metric variables
2023-05-28 00:34:56,877:INFO:Importing untrained model
2023-05-28 00:34:56,892:INFO:Gradient Boosting Regressor Imported successfully
2023-05-28 00:34:56,892:INFO:Starting cross validation
2023-05-28 00:34:56,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:35:05,213:INFO:Calculating mean and std
2023-05-28 00:35:05,213:INFO:Creating metrics dataframe
2023-05-28 00:35:05,447:INFO:Uploading results into container
2023-05-28 00:35:05,447:INFO:Uploading model into container now
2023-05-28 00:35:05,447:INFO:_master_model_container: 16
2023-05-28 00:35:05,447:INFO:_display_container: 2
2023-05-28 00:35:05,447:INFO:GradientBoostingRegressor(random_state=42)
2023-05-28 00:35:05,447:INFO:create_model() successfully completed......................................
2023-05-28 00:35:05,557:INFO:SubProcess create_model() end ==================================
2023-05-28 00:35:05,557:INFO:Creating metrics dataframe
2023-05-28 00:35:05,572:INFO:Initializing Light Gradient Boosting Machine
2023-05-28 00:35:05,572:INFO:Total runtime is 2.470993967851003 minutes
2023-05-28 00:35:05,572:INFO:SubProcess create_model() called ==================================
2023-05-28 00:35:05,572:INFO:Initializing create_model()
2023-05-28 00:35:05,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:35:05,572:INFO:Checking exceptions
2023-05-28 00:35:05,572:INFO:Importing libraries
2023-05-28 00:35:05,572:INFO:Copying training dataset
2023-05-28 00:35:05,619:INFO:Defining folds
2023-05-28 00:35:05,619:INFO:Declaring metric variables
2023-05-28 00:35:05,635:INFO:Importing untrained model
2023-05-28 00:35:05,635:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-28 00:35:05,635:INFO:Starting cross validation
2023-05-28 00:35:05,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:35:10,548:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-05-28 00:35:10,548:WARNING:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-28 00:35:10,548:INFO:Initializing create_model()
2023-05-28 00:35:10,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:35:10,548:INFO:Checking exceptions
2023-05-28 00:35:10,548:INFO:Importing libraries
2023-05-28 00:35:10,548:INFO:Copying training dataset
2023-05-28 00:35:10,595:INFO:Defining folds
2023-05-28 00:35:10,595:INFO:Declaring metric variables
2023-05-28 00:35:10,595:INFO:Importing untrained model
2023-05-28 00:35:10,595:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-28 00:35:10,611:INFO:Starting cross validation
2023-05-28 00:35:10,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:35:12,595:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-05-28 00:35:12,595:ERROR:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 808, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-28 00:35:12,829:INFO:Initializing Dummy Regressor
2023-05-28 00:35:12,845:INFO:Total runtime is 2.592205019791921 minutes
2023-05-28 00:35:12,845:INFO:SubProcess create_model() called ==================================
2023-05-28 00:35:12,845:INFO:Initializing create_model()
2023-05-28 00:35:12,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF58C97820>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:35:12,845:INFO:Checking exceptions
2023-05-28 00:35:12,845:INFO:Importing libraries
2023-05-28 00:35:12,845:INFO:Copying training dataset
2023-05-28 00:35:12,876:INFO:Defining folds
2023-05-28 00:35:12,876:INFO:Declaring metric variables
2023-05-28 00:35:12,892:INFO:Importing untrained model
2023-05-28 00:35:12,892:INFO:Dummy Regressor Imported successfully
2023-05-28 00:35:12,892:INFO:Starting cross validation
2023-05-28 00:35:12,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:35:14,736:INFO:Calculating mean and std
2023-05-28 00:35:14,736:INFO:Creating metrics dataframe
2023-05-28 00:35:14,876:INFO:Uploading results into container
2023-05-28 00:35:14,876:INFO:Uploading model into container now
2023-05-28 00:35:14,876:INFO:_master_model_container: 17
2023-05-28 00:35:14,876:INFO:_display_container: 2
2023-05-28 00:35:14,876:INFO:DummyRegressor()
2023-05-28 00:35:14,876:INFO:create_model() successfully completed......................................
2023-05-28 00:35:14,970:INFO:SubProcess create_model() end ==================================
2023-05-28 00:35:14,970:INFO:Creating metrics dataframe
2023-05-28 00:35:14,986:INFO:Initializing create_model()
2023-05-28 00:35:14,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF52459ED0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:35:14,986:INFO:Checking exceptions
2023-05-28 00:35:14,986:INFO:Importing libraries
2023-05-28 00:35:14,986:INFO:Copying training dataset
2023-05-28 00:35:15,032:INFO:Defining folds
2023-05-28 00:35:15,032:INFO:Declaring metric variables
2023-05-28 00:35:15,032:INFO:Importing untrained model
2023-05-28 00:35:15,032:INFO:Declaring custom model
2023-05-28 00:35:15,032:INFO:Bayesian Ridge Imported successfully
2023-05-28 00:35:15,032:INFO:Cross validation set to False
2023-05-28 00:35:15,032:INFO:Fitting Model
2023-05-28 00:35:15,892:INFO:BayesianRidge()
2023-05-28 00:35:15,892:INFO:create_model() successfully completed......................................
2023-05-28 00:35:16,017:INFO:_master_model_container: 17
2023-05-28 00:35:16,017:INFO:_display_container: 2
2023-05-28 00:35:16,017:INFO:BayesianRidge()
2023-05-28 00:35:16,017:INFO:compare_models() successfully completed......................................
2023-05-28 00:36:37,572:INFO:PyCaret RegressionExperiment
2023-05-28 00:36:37,572:INFO:Logging name: reg-default-name
2023-05-28 00:36:37,572:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-28 00:36:37,572:INFO:version 3.0.2
2023-05-28 00:36:37,572:INFO:Initializing setup()
2023-05-28 00:36:37,572:INFO:self.USI: 68cd
2023-05-28 00:36:37,572:INFO:self._variable_keys: {'seed', 'X_train', 'log_plots_param', 'pipeline', 'n_jobs_param', 'fold_groups_param', 'logging_param', 'X_test', 'fold_shuffle_param', 'memory', 'y_train', 'y', 'exp_id', 'gpu_param', 'y_test', 'X', 'gpu_n_jobs_param', 'transform_target_param', 'USI', 'fold_generator', 'html_param', 'exp_name_log', 'target_param', '_ml_usecase', 'idx', 'data', '_available_plots'}
2023-05-28 00:36:37,572:INFO:Checking environment
2023-05-28 00:36:37,572:INFO:python_version: 3.10.9
2023-05-28 00:36:37,572:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-05-28 00:36:37,572:INFO:machine: AMD64
2023-05-28 00:36:37,572:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-28 00:36:37,572:INFO:Memory: svmem(total=17041244160, available=2503217152, percent=85.3, used=14538027008, free=2503217152)
2023-05-28 00:36:37,572:INFO:Physical Core: 6
2023-05-28 00:36:37,572:INFO:Logical Core: 12
2023-05-28 00:36:37,572:INFO:Checking libraries
2023-05-28 00:36:37,572:INFO:System:
2023-05-28 00:36:37,572:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-05-28 00:36:37,572:INFO:executable: C:\Users\medo2\anaconda3\python.exe
2023-05-28 00:36:37,572:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-28 00:36:37,572:INFO:PyCaret required dependencies:
2023-05-28 00:36:37,572:INFO:                 pip: 23.0.1
2023-05-28 00:36:37,572:INFO:          setuptools: 65.6.3
2023-05-28 00:36:37,572:INFO:             pycaret: 3.0.2
2023-05-28 00:36:37,572:INFO:             IPython: 8.10.0
2023-05-28 00:36:37,572:INFO:          ipywidgets: 7.6.5
2023-05-28 00:36:37,572:INFO:                tqdm: 4.64.1
2023-05-28 00:36:37,572:INFO:               numpy: 1.23.5
2023-05-28 00:36:37,572:INFO:              pandas: 1.5.3
2023-05-28 00:36:37,572:INFO:              jinja2: 3.1.2
2023-05-28 00:36:37,572:INFO:               scipy: 1.10.0
2023-05-28 00:36:37,572:INFO:              joblib: 1.2.0
2023-05-28 00:36:37,572:INFO:             sklearn: 1.2.1
2023-05-28 00:36:37,572:INFO:                pyod: 1.0.9
2023-05-28 00:36:37,572:INFO:            imblearn: 0.10.1
2023-05-28 00:36:37,572:INFO:   category_encoders: 2.6.1
2023-05-28 00:36:37,572:INFO:            lightgbm: 3.3.5
2023-05-28 00:36:37,572:INFO:               numba: 0.56.4
2023-05-28 00:36:37,572:INFO:            requests: 2.28.1
2023-05-28 00:36:37,572:INFO:          matplotlib: 3.7.0
2023-05-28 00:36:37,572:INFO:          scikitplot: 0.3.7
2023-05-28 00:36:37,572:INFO:         yellowbrick: 1.5
2023-05-28 00:36:37,572:INFO:              plotly: 5.9.0
2023-05-28 00:36:37,572:INFO:             kaleido: 0.2.1
2023-05-28 00:36:37,572:INFO:         statsmodels: 0.13.5
2023-05-28 00:36:37,572:INFO:              sktime: 0.17.0
2023-05-28 00:36:37,572:INFO:               tbats: 1.1.3
2023-05-28 00:36:37,572:INFO:            pmdarima: 2.0.3
2023-05-28 00:36:37,572:INFO:              psutil: 5.9.0
2023-05-28 00:36:37,572:INFO:PyCaret optional dependencies:
2023-05-28 00:36:37,572:INFO:                shap: Not installed
2023-05-28 00:36:37,572:INFO:           interpret: Not installed
2023-05-28 00:36:37,572:INFO:                umap: Not installed
2023-05-28 00:36:37,572:INFO:    pandas_profiling: Not installed
2023-05-28 00:36:37,572:INFO:  explainerdashboard: Not installed
2023-05-28 00:36:37,572:INFO:             autoviz: Not installed
2023-05-28 00:36:37,572:INFO:           fairlearn: Not installed
2023-05-28 00:36:37,572:INFO:             xgboost: Not installed
2023-05-28 00:36:37,572:INFO:            catboost: Not installed
2023-05-28 00:36:37,572:INFO:              kmodes: Not installed
2023-05-28 00:36:37,572:INFO:             mlxtend: Not installed
2023-05-28 00:36:37,572:INFO:       statsforecast: Not installed
2023-05-28 00:36:37,572:INFO:        tune_sklearn: Not installed
2023-05-28 00:36:37,572:INFO:                 ray: Not installed
2023-05-28 00:36:37,572:INFO:            hyperopt: Not installed
2023-05-28 00:36:37,572:INFO:              optuna: Not installed
2023-05-28 00:36:37,572:INFO:               skopt: Not installed
2023-05-28 00:36:37,572:INFO:              mlflow: Not installed
2023-05-28 00:36:37,572:INFO:              gradio: Not installed
2023-05-28 00:36:37,572:INFO:             fastapi: Not installed
2023-05-28 00:36:37,572:INFO:             uvicorn: Not installed
2023-05-28 00:36:37,572:INFO:              m2cgen: Not installed
2023-05-28 00:36:37,572:INFO:           evidently: Not installed
2023-05-28 00:36:37,572:INFO:               fugue: Not installed
2023-05-28 00:36:37,572:INFO:           streamlit: Not installed
2023-05-28 00:36:37,572:INFO:             prophet: Not installed
2023-05-28 00:36:37,572:INFO:None
2023-05-28 00:36:37,572:INFO:Set up data.
2023-05-28 00:36:37,713:INFO:Set up train/test split.
2023-05-28 00:36:37,744:INFO:Set up index.
2023-05-28 00:36:37,744:INFO:Set up folding strategy.
2023-05-28 00:36:37,744:INFO:Assigning column types.
2023-05-28 00:36:37,754:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-28 00:36:37,754:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,770:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:37,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:37,879:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,895:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:36:37,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,020:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-28 00:36:38,020:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,020:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,098:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,145:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,161:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,270:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-28 00:36:38,286:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,411:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,532:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-28 00:36:38,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,790:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-28 00:36:38,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:38,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:38,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-28 00:36:39,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,040:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-28 00:36:39,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:39,315:INFO:Preparing preprocessing pipeline...
2023-05-28 00:36:39,316:INFO:Set up simple imputation.
2023-05-28 00:36:39,319:INFO:Set up column name cleaning.
2023-05-28 00:36:39,470:INFO:Finished creating preprocessing pipeline.
2023-05-28 00:36:39,479:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\medo2\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Job title_academic advisor',
                                             'Job title_account executive',
                                             'Job title_account manager',
                                             'Job title_accountant',
                                             'Job title_accounting manager',
                                             'Job title_administrative '
                                             'assistant',
                                             'Job title_administrative '
                                             'assistant ',
                                             'Job title_...
                                             'Job title_branch manager',
                                             'Job title_business analyst',
                                             'Job title_business development '
                                             'manager',
                                             'Job title_business intelligence '
                                             'analyst',
                                             'Job title_case manager', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-05-28 00:36:39,479:INFO:Creating final display dataframe.
2023-05-28 00:36:40,028:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      total_salary
2                   Target type        Regression
3           Original data shape       (5705, 633)
4        Transformed data shape       (5705, 633)
5   Transformed train set shape       (3993, 633)
6    Transformed test set shape       (1712, 633)
7              Numeric features               632
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              68cd
2023-05-28 00:36:40,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:40,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:40,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:40,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-28 00:36:40,300:INFO:setup() successfully completed in 2.84s...............
2023-05-28 00:36:43,284:INFO:Initializing compare_models()
2023-05-28 00:36:43,284:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-28 00:36:43,284:INFO:Checking exceptions
2023-05-28 00:36:43,294:INFO:Preparing display monitor
2023-05-28 00:36:43,328:INFO:Initializing Linear Regression
2023-05-28 00:36:43,328:INFO:Total runtime is 0.0 minutes
2023-05-28 00:36:43,331:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:43,332:INFO:Initializing create_model()
2023-05-28 00:36:43,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:43,332:INFO:Checking exceptions
2023-05-28 00:36:43,332:INFO:Importing libraries
2023-05-28 00:36:43,332:INFO:Copying training dataset
2023-05-28 00:36:43,377:INFO:Defining folds
2023-05-28 00:36:43,378:INFO:Declaring metric variables
2023-05-28 00:36:43,381:INFO:Importing untrained model
2023-05-28 00:36:43,384:INFO:Linear Regression Imported successfully
2023-05-28 00:36:43,386:INFO:Starting cross validation
2023-05-28 00:36:43,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:45,225:INFO:Calculating mean and std
2023-05-28 00:36:45,225:INFO:Creating metrics dataframe
2023-05-28 00:36:45,355:INFO:Uploading results into container
2023-05-28 00:36:45,356:INFO:Uploading model into container now
2023-05-28 00:36:45,356:INFO:_master_model_container: 1
2023-05-28 00:36:45,356:INFO:_display_container: 2
2023-05-28 00:36:45,356:INFO:LinearRegression(n_jobs=-1)
2023-05-28 00:36:45,356:INFO:create_model() successfully completed......................................
2023-05-28 00:36:45,448:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:45,448:INFO:Creating metrics dataframe
2023-05-28 00:36:45,448:INFO:Initializing Lasso Regression
2023-05-28 00:36:45,448:INFO:Total runtime is 0.03533392349878947 minutes
2023-05-28 00:36:45,463:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:45,463:INFO:Initializing create_model()
2023-05-28 00:36:45,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:45,463:INFO:Checking exceptions
2023-05-28 00:36:45,463:INFO:Importing libraries
2023-05-28 00:36:45,463:INFO:Copying training dataset
2023-05-28 00:36:45,493:INFO:Defining folds
2023-05-28 00:36:45,493:INFO:Declaring metric variables
2023-05-28 00:36:45,509:INFO:Importing untrained model
2023-05-28 00:36:45,513:INFO:Lasso Regression Imported successfully
2023-05-28 00:36:45,520:INFO:Starting cross validation
2023-05-28 00:36:45,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:47,256:INFO:Calculating mean and std
2023-05-28 00:36:47,256:INFO:Creating metrics dataframe
2023-05-28 00:36:47,372:INFO:Uploading results into container
2023-05-28 00:36:47,372:INFO:Uploading model into container now
2023-05-28 00:36:47,372:INFO:_master_model_container: 2
2023-05-28 00:36:47,372:INFO:_display_container: 2
2023-05-28 00:36:47,372:INFO:Lasso(random_state=42)
2023-05-28 00:36:47,372:INFO:create_model() successfully completed......................................
2023-05-28 00:36:47,466:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:47,466:INFO:Creating metrics dataframe
2023-05-28 00:36:47,484:INFO:Initializing Ridge Regression
2023-05-28 00:36:47,485:INFO:Total runtime is 0.06927957932154338 minutes
2023-05-28 00:36:47,485:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:47,485:INFO:Initializing create_model()
2023-05-28 00:36:47,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:47,485:INFO:Checking exceptions
2023-05-28 00:36:47,485:INFO:Importing libraries
2023-05-28 00:36:47,485:INFO:Copying training dataset
2023-05-28 00:36:47,518:INFO:Defining folds
2023-05-28 00:36:47,518:INFO:Declaring metric variables
2023-05-28 00:36:47,534:INFO:Importing untrained model
2023-05-28 00:36:47,538:INFO:Ridge Regression Imported successfully
2023-05-28 00:36:47,545:INFO:Starting cross validation
2023-05-28 00:36:47,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:49,241:INFO:Calculating mean and std
2023-05-28 00:36:49,242:INFO:Creating metrics dataframe
2023-05-28 00:36:49,458:INFO:Uploading results into container
2023-05-28 00:36:49,458:INFO:Uploading model into container now
2023-05-28 00:36:49,458:INFO:_master_model_container: 3
2023-05-28 00:36:49,458:INFO:_display_container: 2
2023-05-28 00:36:49,458:INFO:Ridge(random_state=42)
2023-05-28 00:36:49,458:INFO:create_model() successfully completed......................................
2023-05-28 00:36:49,558:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:49,558:INFO:Creating metrics dataframe
2023-05-28 00:36:49,573:INFO:Initializing Elastic Net
2023-05-28 00:36:49,573:INFO:Total runtime is 0.1040911118189494 minutes
2023-05-28 00:36:49,573:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:49,573:INFO:Initializing create_model()
2023-05-28 00:36:49,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:49,573:INFO:Checking exceptions
2023-05-28 00:36:49,573:INFO:Importing libraries
2023-05-28 00:36:49,573:INFO:Copying training dataset
2023-05-28 00:36:49,618:INFO:Defining folds
2023-05-28 00:36:49,618:INFO:Declaring metric variables
2023-05-28 00:36:49,630:INFO:Importing untrained model
2023-05-28 00:36:49,630:INFO:Elastic Net Imported successfully
2023-05-28 00:36:49,638:INFO:Starting cross validation
2023-05-28 00:36:49,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:51,424:INFO:Calculating mean and std
2023-05-28 00:36:51,424:INFO:Creating metrics dataframe
2023-05-28 00:36:51,554:INFO:Uploading results into container
2023-05-28 00:36:51,554:INFO:Uploading model into container now
2023-05-28 00:36:51,554:INFO:_master_model_container: 4
2023-05-28 00:36:51,554:INFO:_display_container: 2
2023-05-28 00:36:51,554:INFO:ElasticNet(random_state=42)
2023-05-28 00:36:51,554:INFO:create_model() successfully completed......................................
2023-05-28 00:36:51,648:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:51,648:INFO:Creating metrics dataframe
2023-05-28 00:36:51,659:INFO:Initializing Least Angle Regression
2023-05-28 00:36:51,659:INFO:Total runtime is 0.13885704278945923 minutes
2023-05-28 00:36:51,661:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:51,661:INFO:Initializing create_model()
2023-05-28 00:36:51,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:51,661:INFO:Checking exceptions
2023-05-28 00:36:51,661:INFO:Importing libraries
2023-05-28 00:36:51,661:INFO:Copying training dataset
2023-05-28 00:36:51,702:INFO:Defining folds
2023-05-28 00:36:51,702:INFO:Declaring metric variables
2023-05-28 00:36:51,702:INFO:Importing untrained model
2023-05-28 00:36:51,713:INFO:Least Angle Regression Imported successfully
2023-05-28 00:36:51,722:INFO:Starting cross validation
2023-05-28 00:36:51,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:53,448:INFO:Calculating mean and std
2023-05-28 00:36:53,448:INFO:Creating metrics dataframe
2023-05-28 00:36:53,579:INFO:Uploading results into container
2023-05-28 00:36:53,579:INFO:Uploading model into container now
2023-05-28 00:36:53,579:INFO:_master_model_container: 5
2023-05-28 00:36:53,579:INFO:_display_container: 2
2023-05-28 00:36:53,579:INFO:Lars(random_state=42)
2023-05-28 00:36:53,579:INFO:create_model() successfully completed......................................
2023-05-28 00:36:53,673:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:53,673:INFO:Creating metrics dataframe
2023-05-28 00:36:53,673:INFO:Initializing Lasso Least Angle Regression
2023-05-28 00:36:53,673:INFO:Total runtime is 0.1724166433016459 minutes
2023-05-28 00:36:53,689:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:53,689:INFO:Initializing create_model()
2023-05-28 00:36:53,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:53,689:INFO:Checking exceptions
2023-05-28 00:36:53,689:INFO:Importing libraries
2023-05-28 00:36:53,689:INFO:Copying training dataset
2023-05-28 00:36:53,727:INFO:Defining folds
2023-05-28 00:36:53,727:INFO:Declaring metric variables
2023-05-28 00:36:53,727:INFO:Importing untrained model
2023-05-28 00:36:53,740:INFO:Lasso Least Angle Regression Imported successfully
2023-05-28 00:36:53,746:INFO:Starting cross validation
2023-05-28 00:36:53,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:55,473:INFO:Calculating mean and std
2023-05-28 00:36:55,473:INFO:Creating metrics dataframe
2023-05-28 00:36:55,588:INFO:Uploading results into container
2023-05-28 00:36:55,588:INFO:Uploading model into container now
2023-05-28 00:36:55,588:INFO:_master_model_container: 6
2023-05-28 00:36:55,588:INFO:_display_container: 2
2023-05-28 00:36:55,588:INFO:LassoLars(random_state=42)
2023-05-28 00:36:55,588:INFO:create_model() successfully completed......................................
2023-05-28 00:36:55,682:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:55,682:INFO:Creating metrics dataframe
2023-05-28 00:36:55,697:INFO:Initializing Orthogonal Matching Pursuit
2023-05-28 00:36:55,697:INFO:Total runtime is 0.2061602512995402 minutes
2023-05-28 00:36:55,712:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:55,712:INFO:Initializing create_model()
2023-05-28 00:36:55,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:55,712:INFO:Checking exceptions
2023-05-28 00:36:55,712:INFO:Importing libraries
2023-05-28 00:36:55,712:INFO:Copying training dataset
2023-05-28 00:36:55,743:INFO:Defining folds
2023-05-28 00:36:55,743:INFO:Declaring metric variables
2023-05-28 00:36:55,760:INFO:Importing untrained model
2023-05-28 00:36:55,762:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-28 00:36:55,771:INFO:Starting cross validation
2023-05-28 00:36:55,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:57,474:INFO:Calculating mean and std
2023-05-28 00:36:57,474:INFO:Creating metrics dataframe
2023-05-28 00:36:57,604:INFO:Uploading results into container
2023-05-28 00:36:57,604:INFO:Uploading model into container now
2023-05-28 00:36:57,604:INFO:_master_model_container: 7
2023-05-28 00:36:57,604:INFO:_display_container: 2
2023-05-28 00:36:57,604:INFO:OrthogonalMatchingPursuit()
2023-05-28 00:36:57,604:INFO:create_model() successfully completed......................................
2023-05-28 00:36:57,698:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:57,698:INFO:Creating metrics dataframe
2023-05-28 00:36:57,698:INFO:Initializing Bayesian Ridge
2023-05-28 00:36:57,698:INFO:Total runtime is 0.23949797550837199 minutes
2023-05-28 00:36:57,711:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:57,711:INFO:Initializing create_model()
2023-05-28 00:36:57,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:57,711:INFO:Checking exceptions
2023-05-28 00:36:57,711:INFO:Importing libraries
2023-05-28 00:36:57,711:INFO:Copying training dataset
2023-05-28 00:36:57,743:INFO:Defining folds
2023-05-28 00:36:57,743:INFO:Declaring metric variables
2023-05-28 00:36:57,743:INFO:Importing untrained model
2023-05-28 00:36:57,761:INFO:Bayesian Ridge Imported successfully
2023-05-28 00:36:57,771:INFO:Starting cross validation
2023-05-28 00:36:57,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:36:59,546:INFO:Calculating mean and std
2023-05-28 00:36:59,546:INFO:Creating metrics dataframe
2023-05-28 00:36:59,670:INFO:Uploading results into container
2023-05-28 00:36:59,670:INFO:Uploading model into container now
2023-05-28 00:36:59,670:INFO:_master_model_container: 8
2023-05-28 00:36:59,670:INFO:_display_container: 2
2023-05-28 00:36:59,670:INFO:BayesianRidge()
2023-05-28 00:36:59,670:INFO:create_model() successfully completed......................................
2023-05-28 00:36:59,764:INFO:SubProcess create_model() end ==================================
2023-05-28 00:36:59,764:INFO:Creating metrics dataframe
2023-05-28 00:36:59,780:INFO:Initializing Passive Aggressive Regressor
2023-05-28 00:36:59,780:INFO:Total runtime is 0.27419789632161456 minutes
2023-05-28 00:36:59,785:INFO:SubProcess create_model() called ==================================
2023-05-28 00:36:59,785:INFO:Initializing create_model()
2023-05-28 00:36:59,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:36:59,786:INFO:Checking exceptions
2023-05-28 00:36:59,786:INFO:Importing libraries
2023-05-28 00:36:59,786:INFO:Copying training dataset
2023-05-28 00:36:59,818:INFO:Defining folds
2023-05-28 00:36:59,818:INFO:Declaring metric variables
2023-05-28 00:36:59,833:INFO:Importing untrained model
2023-05-28 00:36:59,837:INFO:Passive Aggressive Regressor Imported successfully
2023-05-28 00:36:59,846:INFO:Starting cross validation
2023-05-28 00:36:59,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:01,580:INFO:Calculating mean and std
2023-05-28 00:37:01,580:INFO:Creating metrics dataframe
2023-05-28 00:37:01,712:INFO:Uploading results into container
2023-05-28 00:37:01,712:INFO:Uploading model into container now
2023-05-28 00:37:01,712:INFO:_master_model_container: 9
2023-05-28 00:37:01,712:INFO:_display_container: 2
2023-05-28 00:37:01,712:INFO:PassiveAggressiveRegressor(random_state=42)
2023-05-28 00:37:01,712:INFO:create_model() successfully completed......................................
2023-05-28 00:37:01,830:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:01,845:INFO:Creating metrics dataframe
2023-05-28 00:37:01,845:INFO:Initializing Huber Regressor
2023-05-28 00:37:01,845:INFO:Total runtime is 0.30862570603688555 minutes
2023-05-28 00:37:01,866:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:01,866:INFO:Initializing create_model()
2023-05-28 00:37:01,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:01,867:INFO:Checking exceptions
2023-05-28 00:37:01,867:INFO:Importing libraries
2023-05-28 00:37:01,867:INFO:Copying training dataset
2023-05-28 00:37:01,901:INFO:Defining folds
2023-05-28 00:37:01,901:INFO:Declaring metric variables
2023-05-28 00:37:01,917:INFO:Importing untrained model
2023-05-28 00:37:01,922:INFO:Huber Regressor Imported successfully
2023-05-28 00:37:01,929:INFO:Starting cross validation
2023-05-28 00:37:01,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:03,726:INFO:Calculating mean and std
2023-05-28 00:37:03,726:INFO:Creating metrics dataframe
2023-05-28 00:37:03,846:INFO:Uploading results into container
2023-05-28 00:37:03,846:INFO:Uploading model into container now
2023-05-28 00:37:03,846:INFO:_master_model_container: 10
2023-05-28 00:37:03,846:INFO:_display_container: 2
2023-05-28 00:37:03,846:INFO:HuberRegressor()
2023-05-28 00:37:03,846:INFO:create_model() successfully completed......................................
2023-05-28 00:37:03,956:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:03,956:INFO:Creating metrics dataframe
2023-05-28 00:37:03,968:INFO:Initializing K Neighbors Regressor
2023-05-28 00:37:03,969:INFO:Total runtime is 0.34402300516764317 minutes
2023-05-28 00:37:03,972:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:03,972:INFO:Initializing create_model()
2023-05-28 00:37:03,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:03,972:INFO:Checking exceptions
2023-05-28 00:37:03,973:INFO:Importing libraries
2023-05-28 00:37:03,973:INFO:Copying training dataset
2023-05-28 00:37:04,010:INFO:Defining folds
2023-05-28 00:37:04,010:INFO:Declaring metric variables
2023-05-28 00:37:04,010:INFO:Importing untrained model
2023-05-28 00:37:04,025:INFO:K Neighbors Regressor Imported successfully
2023-05-28 00:37:04,027:INFO:Starting cross validation
2023-05-28 00:37:04,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:05,892:INFO:Calculating mean and std
2023-05-28 00:37:05,892:INFO:Creating metrics dataframe
2023-05-28 00:37:06,029:INFO:Uploading results into container
2023-05-28 00:37:06,029:INFO:Uploading model into container now
2023-05-28 00:37:06,030:INFO:_master_model_container: 11
2023-05-28 00:37:06,030:INFO:_display_container: 2
2023-05-28 00:37:06,030:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-28 00:37:06,031:INFO:create_model() successfully completed......................................
2023-05-28 00:37:06,118:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:06,118:INFO:Creating metrics dataframe
2023-05-28 00:37:06,140:INFO:Initializing Decision Tree Regressor
2023-05-28 00:37:06,140:INFO:Total runtime is 0.3801982045173644 minutes
2023-05-28 00:37:06,144:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:06,144:INFO:Initializing create_model()
2023-05-28 00:37:06,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:06,144:INFO:Checking exceptions
2023-05-28 00:37:06,144:INFO:Importing libraries
2023-05-28 00:37:06,144:INFO:Copying training dataset
2023-05-28 00:37:06,185:INFO:Defining folds
2023-05-28 00:37:06,185:INFO:Declaring metric variables
2023-05-28 00:37:06,185:INFO:Importing untrained model
2023-05-28 00:37:06,193:INFO:Decision Tree Regressor Imported successfully
2023-05-28 00:37:06,201:INFO:Starting cross validation
2023-05-28 00:37:06,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:08,004:INFO:Calculating mean and std
2023-05-28 00:37:08,004:INFO:Creating metrics dataframe
2023-05-28 00:37:08,136:INFO:Uploading results into container
2023-05-28 00:37:08,136:INFO:Uploading model into container now
2023-05-28 00:37:08,136:INFO:_master_model_container: 12
2023-05-28 00:37:08,136:INFO:_display_container: 2
2023-05-28 00:37:08,136:INFO:DecisionTreeRegressor(random_state=42)
2023-05-28 00:37:08,136:INFO:create_model() successfully completed......................................
2023-05-28 00:37:08,230:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:08,230:INFO:Creating metrics dataframe
2023-05-28 00:37:08,245:INFO:Initializing Random Forest Regressor
2023-05-28 00:37:08,245:INFO:Total runtime is 0.4152795155843098 minutes
2023-05-28 00:37:08,245:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:08,245:INFO:Initializing create_model()
2023-05-28 00:37:08,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:08,251:INFO:Checking exceptions
2023-05-28 00:37:08,251:INFO:Importing libraries
2023-05-28 00:37:08,251:INFO:Copying training dataset
2023-05-28 00:37:08,286:INFO:Defining folds
2023-05-28 00:37:08,286:INFO:Declaring metric variables
2023-05-28 00:37:08,286:INFO:Importing untrained model
2023-05-28 00:37:08,300:INFO:Random Forest Regressor Imported successfully
2023-05-28 00:37:08,304:INFO:Starting cross validation
2023-05-28 00:37:08,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:10,283:INFO:Calculating mean and std
2023-05-28 00:37:10,283:INFO:Creating metrics dataframe
2023-05-28 00:37:10,404:INFO:Uploading results into container
2023-05-28 00:37:10,404:INFO:Uploading model into container now
2023-05-28 00:37:10,404:INFO:_master_model_container: 13
2023-05-28 00:37:10,404:INFO:_display_container: 2
2023-05-28 00:37:10,404:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-05-28 00:37:10,404:INFO:create_model() successfully completed......................................
2023-05-28 00:37:10,498:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:10,498:INFO:Creating metrics dataframe
2023-05-28 00:37:10,520:INFO:Initializing Extra Trees Regressor
2023-05-28 00:37:10,520:INFO:Total runtime is 0.4532007177670796 minutes
2023-05-28 00:37:10,523:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:10,523:INFO:Initializing create_model()
2023-05-28 00:37:10,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:10,523:INFO:Checking exceptions
2023-05-28 00:37:10,523:INFO:Importing libraries
2023-05-28 00:37:10,523:INFO:Copying training dataset
2023-05-28 00:37:10,560:INFO:Defining folds
2023-05-28 00:37:10,560:INFO:Declaring metric variables
2023-05-28 00:37:10,560:INFO:Importing untrained model
2023-05-28 00:37:10,576:INFO:Extra Trees Regressor Imported successfully
2023-05-28 00:37:10,586:INFO:Starting cross validation
2023-05-28 00:37:10,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:12,774:INFO:Calculating mean and std
2023-05-28 00:37:12,774:INFO:Creating metrics dataframe
2023-05-28 00:37:12,911:INFO:Uploading results into container
2023-05-28 00:37:12,911:INFO:Uploading model into container now
2023-05-28 00:37:12,911:INFO:_master_model_container: 14
2023-05-28 00:37:12,911:INFO:_display_container: 2
2023-05-28 00:37:12,911:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-05-28 00:37:12,911:INFO:create_model() successfully completed......................................
2023-05-28 00:37:13,021:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:13,021:INFO:Creating metrics dataframe
2023-05-28 00:37:13,039:INFO:Initializing AdaBoost Regressor
2023-05-28 00:37:13,039:INFO:Total runtime is 0.49517822265624994 minutes
2023-05-28 00:37:13,045:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:13,045:INFO:Initializing create_model()
2023-05-28 00:37:13,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:13,045:INFO:Checking exceptions
2023-05-28 00:37:13,045:INFO:Importing libraries
2023-05-28 00:37:13,045:INFO:Copying training dataset
2023-05-28 00:37:13,091:INFO:Defining folds
2023-05-28 00:37:13,091:INFO:Declaring metric variables
2023-05-28 00:37:13,091:INFO:Importing untrained model
2023-05-28 00:37:13,103:INFO:AdaBoost Regressor Imported successfully
2023-05-28 00:37:13,111:INFO:Starting cross validation
2023-05-28 00:37:13,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:15,343:INFO:Calculating mean and std
2023-05-28 00:37:15,345:INFO:Creating metrics dataframe
2023-05-28 00:37:15,488:INFO:Uploading results into container
2023-05-28 00:37:15,489:INFO:Uploading model into container now
2023-05-28 00:37:15,489:INFO:_master_model_container: 15
2023-05-28 00:37:15,489:INFO:_display_container: 2
2023-05-28 00:37:15,490:INFO:AdaBoostRegressor(random_state=42)
2023-05-28 00:37:15,490:INFO:create_model() successfully completed......................................
2023-05-28 00:37:15,582:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:15,582:INFO:Creating metrics dataframe
2023-05-28 00:37:15,594:INFO:Initializing Gradient Boosting Regressor
2023-05-28 00:37:15,594:INFO:Total runtime is 0.5377725084622701 minutes
2023-05-28 00:37:15,595:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:15,595:INFO:Initializing create_model()
2023-05-28 00:37:15,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:15,595:INFO:Checking exceptions
2023-05-28 00:37:15,595:INFO:Importing libraries
2023-05-28 00:37:15,595:INFO:Copying training dataset
2023-05-28 00:37:15,635:INFO:Defining folds
2023-05-28 00:37:15,635:INFO:Declaring metric variables
2023-05-28 00:37:15,635:INFO:Importing untrained model
2023-05-28 00:37:15,648:INFO:Gradient Boosting Regressor Imported successfully
2023-05-28 00:37:15,655:INFO:Starting cross validation
2023-05-28 00:37:15,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:17,568:INFO:Calculating mean and std
2023-05-28 00:37:17,568:INFO:Creating metrics dataframe
2023-05-28 00:37:17,695:INFO:Uploading results into container
2023-05-28 00:37:17,695:INFO:Uploading model into container now
2023-05-28 00:37:17,695:INFO:_master_model_container: 16
2023-05-28 00:37:17,695:INFO:_display_container: 2
2023-05-28 00:37:17,695:INFO:GradientBoostingRegressor(random_state=42)
2023-05-28 00:37:17,695:INFO:create_model() successfully completed......................................
2023-05-28 00:37:17,789:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:17,789:INFO:Creating metrics dataframe
2023-05-28 00:37:17,804:INFO:Initializing Light Gradient Boosting Machine
2023-05-28 00:37:17,804:INFO:Total runtime is 0.5746078292528788 minutes
2023-05-28 00:37:17,811:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:17,811:INFO:Initializing create_model()
2023-05-28 00:37:17,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:17,811:INFO:Checking exceptions
2023-05-28 00:37:17,811:INFO:Importing libraries
2023-05-28 00:37:17,811:INFO:Copying training dataset
2023-05-28 00:37:17,852:INFO:Defining folds
2023-05-28 00:37:17,852:INFO:Declaring metric variables
2023-05-28 00:37:17,852:INFO:Importing untrained model
2023-05-28 00:37:17,864:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-28 00:37:17,871:INFO:Starting cross validation
2023-05-28 00:37:17,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:19,535:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-05-28 00:37:19,535:WARNING:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-28 00:37:19,535:INFO:Initializing create_model()
2023-05-28 00:37:19,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:19,535:INFO:Checking exceptions
2023-05-28 00:37:19,535:INFO:Importing libraries
2023-05-28 00:37:19,535:INFO:Copying training dataset
2023-05-28 00:37:19,567:INFO:Defining folds
2023-05-28 00:37:19,567:INFO:Declaring metric variables
2023-05-28 00:37:19,582:INFO:Importing untrained model
2023-05-28 00:37:19,586:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-28 00:37:19,594:INFO:Starting cross validation
2023-05-28 00:37:19,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:21,258:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-05-28 00:37:21,258:ERROR:Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 792, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 808, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1519, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Feature (City_Washington_DC) appears more than one time.


2023-05-28 00:37:21,492:INFO:Initializing Dummy Regressor
2023-05-28 00:37:21,492:INFO:Total runtime is 0.6360694845517476 minutes
2023-05-28 00:37:21,492:INFO:SubProcess create_model() called ==================================
2023-05-28 00:37:21,492:INFO:Initializing create_model()
2023-05-28 00:37:21,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF52893F40>, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:21,492:INFO:Checking exceptions
2023-05-28 00:37:21,492:INFO:Importing libraries
2023-05-28 00:37:21,492:INFO:Copying training dataset
2023-05-28 00:37:21,535:INFO:Defining folds
2023-05-28 00:37:21,535:INFO:Declaring metric variables
2023-05-28 00:37:21,535:INFO:Importing untrained model
2023-05-28 00:37:21,553:INFO:Dummy Regressor Imported successfully
2023-05-28 00:37:21,561:INFO:Starting cross validation
2023-05-28 00:37:21,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-28 00:37:23,282:INFO:Calculating mean and std
2023-05-28 00:37:23,282:INFO:Creating metrics dataframe
2023-05-28 00:37:23,412:INFO:Uploading results into container
2023-05-28 00:37:23,412:INFO:Uploading model into container now
2023-05-28 00:37:23,412:INFO:_master_model_container: 17
2023-05-28 00:37:23,412:INFO:_display_container: 2
2023-05-28 00:37:23,412:INFO:DummyRegressor()
2023-05-28 00:37:23,412:INFO:create_model() successfully completed......................................
2023-05-28 00:37:23,505:INFO:SubProcess create_model() end ==================================
2023-05-28 00:37:23,505:INFO:Creating metrics dataframe
2023-05-28 00:37:23,526:INFO:Initializing create_model()
2023-05-28 00:37:23,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FF585228F0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-28 00:37:23,526:INFO:Checking exceptions
2023-05-28 00:37:23,536:INFO:Importing libraries
2023-05-28 00:37:23,536:INFO:Copying training dataset
2023-05-28 00:37:23,568:INFO:Defining folds
2023-05-28 00:37:23,568:INFO:Declaring metric variables
2023-05-28 00:37:23,568:INFO:Importing untrained model
2023-05-28 00:37:23,568:INFO:Declaring custom model
2023-05-28 00:37:23,568:INFO:Bayesian Ridge Imported successfully
2023-05-28 00:37:23,568:INFO:Cross validation set to False
2023-05-28 00:37:23,568:INFO:Fitting Model
2023-05-28 00:37:23,844:INFO:BayesianRidge()
2023-05-28 00:37:23,844:INFO:create_model() successfully completed......................................
2023-05-28 00:37:23,993:INFO:_master_model_container: 17
2023-05-28 00:37:23,993:INFO:_display_container: 2
2023-05-28 00:37:23,993:INFO:BayesianRidge()
2023-05-28 00:37:23,993:INFO:compare_models() successfully completed......................................
2023-05-28 00:40:08,969:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,062:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,062:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,083:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,178:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,491:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,745:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,792:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,823:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 00:40:09,902:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 01:24:05,698:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-05-28 01:39:57,574:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_de19836028434b57ae10227530077e2b_989ef7347e4a4c658d5c561cc4e50631
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,574:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_3d169798292542609ddb1b93962817fb_d8c31941450141a08e0b11a6db6ab245
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_75cd3b0e19cc46aaa8a8d5f39e2863fb_2779f4f34872418db809ad57c9a67037
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_7cc687be04164bffb3e9d6691f8199dd_aa6ed201b27e43ba829c2609e5bde6dd
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_95d909b7577048f1be9d8bfc1e4e25f8_e986c98468d741d0bccbfdbda3d59db2
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_3967255fe1774bde8f6be8284525efb2_8fa84be8fef8438eb6848f461abc91b5
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_d8118f73008f4682821d1e973d8d46a3_408600ff8374457a904852cdd275a9e2
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_eb169cc38fb246c1a3d3773868af0edf_5a6fb139655f404b97b2a62f6828d65a
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_61c9e44d28cf4456957b0ee62ec2de4e_cd6420c4a4114a858c48934c0d58d857
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,575:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_952a6f39b07c40349161ebb34b33a410_c0b312874140440884fca885b1f1d4ac
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_76d8b63ec96d4ff3987d477fa9d87af4_4b81b774dcea4cc9bae4b9a86db483b2
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_1e804a5a922644dd8cf907e42ed80c60_d9e396c6c319418c936e5e44019964dc
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_8519204757b84352a2ddb044b9a57294_968dc9946ef0428db4ae5bc70f507080
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_3fe699c87fb340568766bc1863995c61_9f9bae67dbe44451943a388d7868b799
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_a8734b72535147ccac26465efedaad8a_cde3d700072b40feb1f1c82a8e3cf840
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_e86e792b65fe48d5be0e8d1f16735ed7_2d724dc6bca042e0af97fb63a1646088
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_3b1a96ba1df34bdc829ef0a9537e0d9c_8b78b218e07945869f3987260d324211
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,576:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_abe99cb7fc59401cb1882eacccf6d1df_453e7047bcfe4632a0bcb09023c43c13
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_a32e85c929e5480ba3c915d78460f146_de2e25aabaf040af89a76f8df5150d04
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_5a815cfe554e4cc9936c46b679b4fcde_3e81797845a34cad84a75fe2c69b238d
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_61b033c30e3d4cc3a4eeea925b6d87a1_79b594a5977f46af865c1d2a1b368e3c
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_fc76a8b0244e48ccbcfc231fd8f09492_fa15d78250d948988e70e50f38b90bbd
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_529f2c9b54be4199bd0c353ca05b904f_549d7f6669144435917c507e13fece07
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_e33534ea61564f7d96899b3e95e542f9_4c3af19156ce404e9b159c9006ed4a6f
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_9d8b640434f04b089baac86c95f01a41_f34016a8c5334ca3b37b56bf3d360b73
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,577:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_ca69346fee6245e3bd46c9cac36d9a62_083dcbd93e4d49db8752c92078407450
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_1eb549762c1c4aecbbb8880bac18ae3d_a456611d36fc440fa7e995e0dc60eb5e
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_0de108681ed14a5a81de1ee27a8f877b_3fecf0896d694575a0746e16e1cbffdc
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_4aec9ed768604bd3a58fe7a879a38ec0_22e3724e8a6641318183b72eee05ab4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_21cf54a5147a4d109e16abc7dc0adc76_158f58789c08427b92fa285bb0403984
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_65b86a00f3be4846abc2b40b8edd58de_383966bb2f214c25af966f2a74ea09df
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_8e951b3b0cf349b180ec0f508c13dc82_0994f0ac51c2422086b98b337763229e
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_6e5338a0afa24452a9722035d47a468f_26a3f6a7960d47fa829e2a498c0e7d93
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_c72392f85d524c909187d4a0b4486343_5e0dab1e1da34804926777ae3b6b2152
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,578:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_8bf00273fc5644c0b3dc4bd879b807f3_f529a3abed6a407fb0224e36dc103af5
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_a1656756f0bc41b2a922c31ab7ebfa7b_03e1618a31314408aa458e89d9c52a75
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_9143df5ee2cb4ae48f0abdad64b20c40_94d23314aefc4e178ceaef9c4b0566e8
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_ecf2b30627164b569c8c28a94dde5c8b_60c4016d21344ad78b20404394935bc0
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_7f7c52ea07c641d3b1dbbcf43af76eef_bca49a3cc24f43a1bdb85ca93653dcb6
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_d65ae4e3a03b4953bcde184f00554831_3fe2175f3c044a889a0d2f379170ea98
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_de168c5178f7447886edbb781154aa29_2f12bfbbdc50434881f8ba9accb48657
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_bd065bf4145049ea9648b0f690a862fa_8f5a09b5007c47599b6958c9577f27c7
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,579:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_0a7ace3241d44f27aa935ea757eecdc9_4d5876e94cdb4659b82d6766efd7a934
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,580:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_35876a55ab254860b3aaf418ebfb030d_c6a9fd4e560c41b1a463b8c79488bf84
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,580:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_b245c71b39894e3b97a1f9acda600f1f_323ad54986984944982f4c8ca6b8d48c
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,580:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_e08807b18f2e4c0a95c5056b380d3869_3b5c68fb33a7424d96eb33988eaa989f
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,580:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_346c599b7cab433fa38675d248930854_bbeb9e1bee254f8b8b301b8f6fc0e3bc
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,583:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_d7dac48a87d746089397b2faf107c165_4f198db44d4041eeb62b642eb9f9caa0
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,583:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_2f668cabb0174b64a69b2acc37ee4e7d_595fa4308bbb492e847d1cdce2b64f96
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 01:39:57,583:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\medo2\AppData\Local\Temp\joblib_memmapping_folder_9268_dc6856ba9f034d0581d2d48b4073500d_7e24c1944db34378a9fbcf440a61fb63
  warnings.warn("Failed to delete temporary folder: {}"

2023-05-28 12:48:56,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 12:48:56,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 12:48:56,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 12:48:56,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-28 12:48:57,064:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-28 13:30:38,008:WARNING:C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py", line 325, in fit
    opt_res = optimize.minimize(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_minimize.py", line 696, in minimize
    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_lbfgsb_py.py", line 305, in _minimize_lbfgsb
    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 332, in _prepare_scalar_function
    sf = ScalarFunction(fun, x0, args, grad, hess,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 158, in __init__
    self._update_fun()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 251, in _update_fun
    self._update_fun_impl()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 155, in update_fun
    self.f = fun_wrapped(self.x)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 137, in fun_wrapped
    fx = fun(np.copy(x), *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 76, in __call__
    self._compute_if_needed(x, *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 70, in _compute_if_needed
    fg = self.fun(x, *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py", line 106, in _huber_loss_and_gradient
    X_outliers = axis0_safe_slice(X, outliers_mask, num_outliers)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\utils\__init__.py", line 175, in axis0_safe_slice
    return X[safe_mask(X, mask), :]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.32 GiB for an array with shape (18331, 16976) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py", line 325, in fit
    opt_res = optimize.minimize(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_minimize.py", line 696, in minimize
    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_lbfgsb_py.py", line 305, in _minimize_lbfgsb
    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 332, in _prepare_scalar_function
    sf = ScalarFunction(fun, x0, args, grad, hess,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 158, in __init__
    self._update_fun()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 251, in _update_fun
    self._update_fun_impl()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 155, in update_fun
    self.f = fun_wrapped(self.x)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 137, in fun_wrapped
    fx = fun(np.copy(x), *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 76, in __call__
    self._compute_if_needed(x, *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 70, in _compute_if_needed
    fg = self.fun(x, *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py", line 106, in _huber_loss_and_gradient
    X_outliers = axis0_safe_slice(X, outliers_mask, num_outliers)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\utils\__init__.py", line 175, in axis0_safe_slice
    return X[safe_mask(X, mask), :]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.32 GiB for an array with shape (18332, 16976) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py", line 325, in fit
    opt_res = optimize.minimize(
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_minimize.py", line 696, in minimize
    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_lbfgsb_py.py", line 305, in _minimize_lbfgsb
    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 332, in _prepare_scalar_function
    sf = ScalarFunction(fun, x0, args, grad, hess,
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 158, in __init__
    self._update_fun()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 251, in _update_fun
    self._update_fun_impl()
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 155, in update_fun
    self.f = fun_wrapped(self.x)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_differentiable_functions.py", line 137, in fun_wrapped
    fx = fun(np.copy(x), *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 76, in __call__
    self._compute_if_needed(x, *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\scipy\optimize\_optimize.py", line 70, in _compute_if_needed
    fg = self.fun(x, *args)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py", line 106, in _huber_loss_and_gradient
    X_outliers = axis0_safe_slice(X, outliers_mask, num_outliers)
  File "C:\Users\medo2\anaconda3\Lib\site-packages\sklearn\utils\__init__.py", line 175, in axis0_safe_slice
    return X[safe_mask(X, mask), :]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.32 GiB for an array with shape (18330, 16976) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

